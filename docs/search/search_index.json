{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation ZDZW","text":""},{"location":"#wp04","title":"WP04","text":"<p>The main purpose of WP04 - Integrity Inspection Solutions is to develop a catalogue of IoT-based non-destructive inspection technologies focused on part integrity. These technologies will follow the concept of Inspection as a Service, guaranteeing cost effectiveness and improved return of investment. Each individual solution will offer different types of subscription and pay-per-use models depending on the offered functionalities.</p> <p>Currently, most of the quality control methods to measure the quality properties obtained for the final component are destructive. The objective is to obtain equivalent quality by means of a variety of Non-destructive techniques (NDT) to reduce the waste generated during the process.</p> <p>ZDZW Integrity Inspections Solutions will: (i) develop inspection technique to monitor and control key processes as induction hardening to control mechanical properties affecting component durability; (ii) develop AE-based inspection services to ensure the quality of the internal component mechanical structure; (iii) make use of MIR-OCT techniques to detect sub-surface defects in a variety of materials; and (iv) perform automated inspection of the integrity of welded joints for critical applications.</p>"},{"location":"#wp05","title":"WP05","text":"<p>The main purpose of WP05 - Visual Inspection Suite is to develop a catalogue of non-destructive inspection technologies focused on the visual inspection part. These technologies will follow the concept of Inspection as a Service, guaranteeing cost effectiveness and an improved return on investment. Each solution will offer different types of subscription and pay-per-use models depending on the offered functionalities.</p> <p>Recognizing the importance of making defect detection information accessible and useful for line operators and workers, this WP places a strong emphasis on usability within the manufacturing environment. By employing standardized data formats, it is ensured that information regarding the location of defects is clearly conveyed. This is achieved, for instance, through the use of Artificial Vision (AV) and Augmented Reality (AR) inspection systems, which provide an intuitive and interactive way for manufacturers and operators to identify and understand defects, thereby streamlining the inspection process and enhancing overall productivity in manufacturing operations.</p>"},{"location":"#wp06","title":"WP06","text":"<p>The main purpose of WP06 - Thermal Inspection Suite is to develop a catalogue of thermal imaging, digital twin, AI and IoT based non-destructive inspection technologies focused on the thermal inspection part. These technologies will follow the concept of Inspection as a Service, guaranteeing cost effectiveness and an improved return on investment. Each solution will offer different types of subscription and pay-per-use models depending on the offered functionalities.</p> <p>ZDZW Thermal Inspection Solutions will: (i) develop Heat Transfer Digital Twin for monitoring and real-time closed-loop feedback control of Thermoforming machine; (ii) thermal imaging inspection solutions for thermoforming, heat-sealing and component surface monitoring processes to assure the real-time thermal imaging, 2D/3D thermal identification, enhanced defect detection by using AI approaches and in-line automated inspection; (iii) welding process inspector based on a real-time monitoring system adaptable for any metal welding process in order to predict the presence of defects during the welding process.</p>"},{"location":"#wp07","title":"WP07","text":"<p>The WP07 suite provides the core Integration, interoperability and key services for the ZDZW solutions developed in WP04-06. It also provides the Marketplace, key component in order to publish and further commercialize the solutions developed in the scope of the project.</p> <p>For integration, WP07 provides the Kubernetes based Platform, where all ZDZW applications will be deployed using a standard and homogenous package format, which will allow the Platform and applications to be deployed in multiple environments, on-premise, on-cloud and on-edge. A security layer will be added on top of this providing single sign on and RBAC management. </p> <p>For interoperability, WP07 provides several ways of communication and data transfer using tools like API Gateway, Message Bus and Complex Event Processor, that will be deployed on top of the platform.</p> <p>An interlinking component will also be provided that will enable communication of the ZDZW Platform with other platforms and systems.</p> <p>The Marketplace is another key component of WP07 and the ZDZW project, taking advantage of the great success of mobile Apps business models, will offer a similar store for the ZDZW apps, providing the usual features of payment, licensing, comments and ratings, but also advanced subscription-based models. The ZDZW Marketplace will integrate with the ValueChain Marketplace, an already existing and commercial marketplace, that will be extended and enhanced with ZDZW solutions and Marketplace integration.</p> <p>Finally the Usage Traceability for Monetisation Service will securely trace the usage of ZDZW\u2019s applications for monetisation using Blockchain technologies. </p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/","title":"Acoustic Emissions Integrity Assesment","text":""},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#general-description","title":"General Description","text":"<p>The app will allow end-users to monitor the internal changes of a component using acoustic emissions (AE) technology. Acoustic events are generated inside materials when damage, phase transformations or other changes occur. The analysis of the waves associated with these events can provide information about the nature and the severity of the changes. This app will allow the user to read, process and analyze AE data produced during the inspection of a component, and apply models to evaluate its integrity.</p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>Martensite estimation using AE-AI models: The amount of martensite generated on a sample subjected to heat treatment can be estimated using models based on acoustic emissions data. </li> <li>Specimen quality assessment: Trained models are leveraged to perform quality assessment of the samples and tag them as valid or not given a predefined criteria.</li> <li>AI model training from experimental data\u200b: AI models based on acoustic emissions experimental data can be trained using a set of algorithms.</li> <li>AI model loading/saving from experimental data: The trained models can be saved and loaded to and from storage.</li> <li>AE data loading\u200b: Acoustic emissions data files can be loaded from storage.</li> <li>AE feature graphical visualization: Acoustic emissions data can be displayed using different types of graphs.</li> <li>AE advanced transient wave spectral analysis: Analysis of acoustic emissions data can be performed using frequency domain algorithms.</li> <li>AE advanced transient wave time-domain analysis: Analysis of acoustic emissions data can be performed using time domain algorithms.</li> <li>Cloud based data management: Data is stored using cloud technology.</li> <li>AE data filtering tools: Multiple filter algorithms can be applied to discriminate valuable acoustic emissions data.</li> </ol>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#architecture-diagram","title":"Architecture Diagram","text":"<p>The high level Architecture diagram for the application:</p> <p></p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#image-overview","title":"Image Overview","text":""},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#computation-requirements","title":"Computation Requirements","text":"<p>Some minimum requirements must be ensured for the app usage: * 4 CPUs * 6-8 GB RAM * 32 GB Storage</p> <p>The amount of storage space needed will depend on the number of exported datasets.</p> <p>The recommended method to install and run the app is by building a Docker image and running the application as a Docker container. In that case, the software requirements are given by Docker:</p> <p>https://docs.docker.com/desktop/install/windows-install/</p> <p>https://docs.docker.com/desktop/install/mac-install/</p> <p>https://docs.docker.com/desktop/install/linux-install/</p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#installation-procedure","title":"Installation Procedure","text":"<p>The preferred way to install the software is by building a Docker image. Optionally the application can be installed manually.</p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#installation-using-docker","title":"Installation using Docker","text":"<ul> <li>Clone the repository or download the code as a zip file.</li> <li>Go to local repository folder or to the unzipped folder.</li> <li> <p>Modify the data about the smart contract, the API key, and the organization in the file orchestration/docker/docker-compose.yml.</p> <p><code>node-red: image: ghcr.io/zdzw-eu/ae_ae_ia_nodered:latest container_name: 'zdzw-node-red' environment:   - TZ=Europe/Madrid   - SmartContract=XXX   - Organization=XXX   - API_key=XXX</code> * Go to the orchestration folder and build the docker image.</p> <pre><code>cd orchestration\ndocker-compose up --build\n</code></pre> </li> </ul>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#manual-installation","title":"Manual installation","text":"<p>The application can also be installed by installing the backend and the frontend individually. * Backend</p> <pre><code>The backend is installed by issuing  the following commands on the app root directory:\n\n```bash\ncd subsystems/backend\npip install -r requirements.txt --no-cache-dir\n```\n</code></pre> <ul> <li> <p>Frontend</p> <p>The frontend is installed by issuing  the following commands on the app root directory:</p> <pre><code>cd subsystems/frontend\nnpm install --legacy-peer-deps\n</code></pre> </li> </ul>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#installation-on-kubernetes","title":"Installation on Kubernetes","text":"<ul> <li>In the Kubernetes platform using helm charts. In order to run the following command, the user must have previously installed k3s (Kubernetes) on their Linux system. Just like with Docker Compose, the user needs to configure the smart contract, the API key, and the organization in the command itself:</li> </ul> <pre><code>helm install ae-ia oci://ghcr.io/zdzw-eu/acoustic-emissions-integrity-assesment --version 0.1.0 --set frontend.service.nodePort=30084 --set SmartContract=\"XXX\" --set Organization=\"XXX\" --set Api_key=\"XXX\"\n</code></pre>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#how-to-use","title":"How To Use","text":"<p>The application has to be run differently based on the installation method used.</p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#running-the-app-using-docker","title":"Running the app using Docker","text":"<p>During the installation a docker image with the app was built. A container can be started by: <pre><code>docker run ae_ia\n</code></pre> On Windows, the docker desktop daemon must be running before the previous command could be issued. This command starts services for the backend and the frontend on the localhost.</p>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#running-the-app-manually","title":"Running the app manually","text":"<p>To run the app manualy the back end and the front end have to be instantiated as separate processes.</p> <ul> <li> <p>The backend is run locally by issuing the following commands. From the root directory of the app, execute:     <pre><code>cd ./subsystems/backend/\nflask run\n</code></pre>     The previous command runs the app on the default flask web server. For a production deployment a WSGI dedicated server should     be used instead. The application can be served on gunicorn (not compatible con windows) or waitress:</p> <ul> <li>Gunicorn <pre><code>cd ./subsystems/backend/\ngunicorn -b :5000 - ae_ia:app\n</code></pre></li> <li>Waitress <pre><code>cd ./subsystems/backend/\nwaitress-serve --host 127.0.0.1 --port 5000 ae_ia:app\n</code></pre> This procedures deploys the backend server on the port 5000 of the local host.</li> </ul> </li> <li> <p>To start the front end on the local host, run the following commands from the root directory of the app:     <pre><code>cd ./subsystems/frontend/\nnpm start\n</code></pre></p> </li> </ul>"},{"location":"WP04/Acoustic-Emissions-Integrity-Assesment/#user-manual","title":"User Manual","text":"<p>This app consists of 2 main windows: Data Loading and AE Analytics.</p> <p></p> <p>In the 'Data Loading' window, the databases for the inspections to be analyzed are loaded. Each inspection consists of two files: a .pridb file with the inspection data, and a .yaml file with the general information of the inspection such as the date, sample material, and the settings used in the hardware. </p> <p>Once the files are loaded, all the loaded inspections can be previewed, with the app displaying a summary table of relevant information about the inspection, as well as a couple of initial graphs showing the energy and accumulated energy of the events over time.</p> <p></p> <p>The 'AE Analytics' window has three tabs: 'AE Visualization', 'Martensite Estimation (Training)' and 'Martensite Estimation (Prediction)'. </p> <p>In the 'AE Visualization' tab, different inspections loaded in the previous window can be selected, and various relevant variables such as amplitude, duration, energy, RMS, threshold, rise time, counts, Trai, etc., can be graphed. Additionally, a summary table with the event features is always displayed, along with the graph of the accumulated energy of those events.</p> <p></p> <p>In the 'Martensite Estimation (Training)' tab, the training of hardening prediction models is carried out. To do this, the user must first select the inspections to be considered in the training, as well as choose the classification method and the variables used in the training. The user must also assign an identifying name to the model, specify the material, and provide a brief description. Once an appropriate score value is reached, the trained model can be saved in the application's database or exported as an external file.</p> <p></p> <p>In the 'Martensite Estimation (Prediction)' tab, the actual hardening prediction is performed. To do this, the user must first upload an inspection for which the prediction is to be made (as before, it is necessary to load the two previously mentioned files), as well as select one of the pre-trained models saved in the database (models can also be loaded from external files).</p> <p></p> <p>Once the prediction is completed, the results are displayed both in numerical format within a table and graphically. The graph presents the calculated hardening values along with the input variables used in the prediction, while the table shows the average probability of hardening occurring in each region.</p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/","title":"EMAT Ultrasonic Inspection","text":""},{"location":"WP04/EMAT-Ultrasonic-Inspection/#general-description","title":"General Description","text":"<p>EMAT-based solution for multi-pass weld inspection  will be integrated into two parts:</p> <ul> <li> <p>EMAT system: a group of components that integrates the inspection system. It is made from a hardware part (EMAT equipment, sensors, conditioning box, cables, etc.) and a software one (Innerspec Technologies Operative Platform that governs hardware components and the EMAT inspection).</p> </li> <li> <p>ZDZW EMAT Weld Inspection App: application developed in ZDZW to consult and analyse EMAT inspections and monitor the welding process' quality.</p> </li> </ul>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>In-line Multipass Weld Ultrasonic Inspection Solution: System performs non-destructive testing  to determine weld quality using Electromagnetic Acoustic Transducers (EMAT). The system detects different defects. For each weld inspected, the system  provides an immediate disposition of weld quality and archives a complete weld record for later post-analysis,  tracking, and process monitoring.</p> </li> <li> <p>Real-time autocalibration of the UT signal: Selfcalibrated sensor. No need for manual calibrations. The use of separate transmitters and receivers enables the self-calibration mechanism in which a controlled amount of energy is transmitted and received by the independent coils.</p> </li> <li> <p>Reflection and attenuation detection mode. Analysis algorithms make the most out of the captured data by providing insights based on reflected signals or the attenuations produced by anomalies in the weld.</p> </li> <li> <p>ASCAN, STRIP CHART, and BSCAN real-time visualization modes that enables real time visual analysis to expert operators.</p> </li> <li> <p>Configurable alarms for defect detection.</p> </li> <li> <p>Real-time data streaming.</p> </li> <li> <p>Integration with third-party systems.</p> </li> <li> <p>Digital and analog I/O.</p> </li> <li> <p>AI-based defects classification tool.</p> </li> <li> <p>Global production statistical analysis.</p> </li> </ol>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#architecture-diagram","title":"Architecture Diagram","text":"<p>The proposed architectural diagram is shown:</p> <p></p> <p>The ZDZW EMAT weld inspection app has the following components: * Weld Inspection Solution: the user interface of the app (frontend). * API 1: module that acts as a bridge between the user interface and the backend. * ZDZW Weld Inspection: this is the core component of the app and it manages all components. * API 2: module that acts as a bridge between the core component and the EMAT Inspection system to transmit the inspection results. * EMAT Inspection system: external module that manages hardware components and stores the raw data of EMAT inspections. * API 3: module that acts as a bridge between the core component and the Analysis module to transmit the result of EMAT inspection analysis. * Analysis module: module responsible for loading and applying trained AI models to EMAT inspections. * API 4: module that acts as a bridge between the EMAT Inspection system and the Analysis module to transmit the raw data of EMAT inspections.</p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#image-overview","title":"Image Overview","text":"<p>EMAT Software Images:</p> <ul> <li> <p>Main screen: </p> </li> <li> <p>ASCAN visualization: </p> </li> <li> <p>ASCAN visualization: </p> </li> </ul> <p>ZDZW EMAT Welding Inspection App Mockups:</p> <ul> <li>Main screen:</li> </ul> <p></p> <ul> <li>Factories:</li> </ul> <p></p> <ul> <li>Inspections:</li> </ul> <p></p> <ul> <li>Analysis:</li> </ul> <p></p> <ul> <li>Quality:</li> </ul> <p></p> <ul> <li>Operation of software/hardware during inspection:</li> </ul> <p></p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#hardware-components","title":"Hardware Components","text":"<p>For the application to work, the following hardware components are required: a rack-mounted electronics including a data acquisition computer, a 2-channel tone amplifier and other peripheral components. Two independent channels can be used in different ways, e.g. for detection and differentiation between two classes of defects. Alternatively, two different types of EMAT wave modes can be activated simultaneously.</p> <p>Emat inspection System Equipment:</p> <ul> <li>Sensor: The Sensors provided contain interchangeable coil circuits. Different EMAT coil circuits can be used in pitch&amp;catch arrangement or pulse-echo arrangement.</li> <li>Signal Conditioning Box: Signals are passed between the connector-less EMAT coil circuit and signal conditioning box.</li> <li>Data Acquisition Cabinet: Data Acquisition Cabinet The data acquisition cabinet is an industrial enclosure that contains the data  acquisition electronics. The electronics consist of EMAT electronics, factory interface, and a computer,  monitor, and keyboard.</li> <li>EMAT Electronics: The EMAT pulsing electronics reside in the data acquisition electronics enclosure. The FPGA data  acquisition card triggers and generates the frequency of the square pulse wave that is output to electronics  that drive and amplify a signal pulse to provide a high power, high frequency toneburst that is necessary to  drive the EMAT transmit coil.</li> <li>PRIMO DACH: The PRIMO Data Acquisition and Communication Hub (DACH) is a computer that is used to control the  inspection process through a software interface that will control system timing functions, collect and analyze  data, display, and store inspection results.</li> </ul>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#computation-requirements","title":"Computation Requirements","text":"<p>Self contained appliance with FPGA and RAID storage provided by Innerspec. No option to load the system in external PCs.</p> <p>Web-based monitoring interface works in all connected devices with a browser. </p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#installation-procedure","title":"Installation Procedure","text":"<p>Step by step on how to install the application: * In the Kubernetes platformm using helm charts: description of the different options will be provided when they become available.</p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#how-to-use","title":"How To Use","text":"<p>Step by step on how to use the application</p> <p>Application under development. This section will be updated at a later stage.</p>"},{"location":"WP04/EMAT-Ultrasonic-Inspection/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials or work from WP10</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/","title":"Mechanical Hardness Inspector","text":""},{"location":"WP04/Mechanical-Hardness-Inspector/#general-description","title":"General Description","text":"<p>The application will allow end-users to monitor in-line a hardening and/or tempering process of the workpieces. Based on machine sensors measurements, a Digital twin will estimate the case depth of the workpiece. Moreover, this application will enable to monitor the sensors signals, status information, and the estimated case depth during the process time. Finally, the application will allow the users to detect the potential anomalies, such as not enough hardened depth, during the inspection of workpieces in manufacturing line.</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>In-line monitoring of several process parameters (T\u00aa, Frequency, Current\u2026): the app is able to monitor several process parameters in real time.</li> <li>Data uploading to cloud: Machine sensor data will be automatically uploaded to the cloud for the app to read the data and perform inspections.</li> <li>Cloud based data management: the data uploaded to the cloud will be managed to suit the requirements from the app.</li> <li>In-line mechanical hardness estimation in Induction hardening: During induction hardening, the achieved hardness depth will be estimated with real time data.</li> <li>In-line mechanical hardness estimation in Induction tempering: During induction tempering, the achieved hardness will be estimated with real time data.</li> <li>Set an alarm to stop the process out of quality limits: The app will provide the user with the opportunity to define process limits that will raise an alarm to stop the process,</li> <li>Show the summary of the process results on interface: The app will show a summary of the most important achieved results (case depth, maximum hardness, hardness evolution) on the interface.</li> <li>Unitary reporting of process information and hardness results: The specific details for each manufactured component will be shown on the app interface.</li> <li>Export registered datasets for further studies: The user will be able to export the result datasets to analyse externally.</li> <li>Data acquisition for off-line retraining of the DT: the exported result datasets can be used to train further Digital Twins or improve the Digital Twin currently in use.</li> </ol>"},{"location":"WP04/Mechanical-Hardness-Inspector/#architecture-diagram","title":"Architecture Diagram","text":"<p>The high level Architecture diagram for the application:</p> <p></p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#image-overview","title":"Image Overview","text":""},{"location":"WP04/Mechanical-Hardness-Inspector/#computation-requirements","title":"Computation Requirements","text":"<p>Some minimum requirements must be ensured for the app usage: * 4 CPUs * 6-8 GB RAM * 32 GB Storage</p> <p>The amount of storage space needed will depend on the number of exported datasets.</p> <p>The recommended method to install and run the app is by building a Docker image and running the application as a Docker container. In that case, the software requirements are given by Docker:</p> <p>https://docs.docker.com/desktop/install/windows-install/</p> <p>https://docs.docker.com/desktop/install/mac-install/</p> <p>https://docs.docker.com/desktop/install/linux-install/</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#installation-procedure","title":"Installation Procedure","text":"<p>The preferred way to install the software is by building a Docker image. Optionally the application can be installed manually.</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#installation-using-docker","title":"Installation using Docker","text":"<ul> <li>Clone the repository or download the code as a zip file.</li> <li>Go to local repository folder or to the unzipped folder.</li> <li> <p>Modify the data about the smart contract, the API key, and the organization in the file orchestration/docker/docker-compose.yml.</p> <p><code>node-red: image: ghcr.io/zdzw-eu/ae_mhi_nodered:latest container_name: 'zdzw-node-red' environment:   - TZ=Europe/Madrid   - SmartContract=XXX   - Organization=XXX   - API_key=XXX</code> * Go to the orchestration folder and build the docker image.</p> <pre><code>cd orchestration\ndocker-compose up --build\n</code></pre> </li> </ul>"},{"location":"WP04/Mechanical-Hardness-Inspector/#manual-installation","title":"Manual installation","text":"<p>The application can also be installed by installing the backend and the frontend individually. * Backend</p> <pre><code>The backend is installed by issuing  the following commands on the app root directory:\n\n```bash\ncd subsystems/backend\npip install -r requirements.txt --no-cache-dir\n```\n</code></pre> <ul> <li> <p>Frontend</p> <p>The frontend is installed by issuing  the following commands on the app root directory:</p> <pre><code>cd subsystems/frontend\nnpm install --legacy-peer-deps\n</code></pre> </li> </ul>"},{"location":"WP04/Mechanical-Hardness-Inspector/#installation-on-kubernetes","title":"Installation on Kubernetes","text":"<ul> <li>In the Kubernetes platform using helm charts. In order to run the following command, the user must have previously installed k3s (Kubernetes) on their Linux system. Just like with Docker Compose, the user needs to configure the smart contract, the API key, and the organization in the command itself:</li> </ul> <pre><code>helm install ae-ia oci://ghcr.io/zdzw-eu/mechanical-hardness-inspector --version 0.1.0 --set frontend.service.nodePort=30084 --set SmartContract=\"XXX\" --set Organization=\"XXX\" --set Api_key=\"XXX\"\n</code></pre>"},{"location":"WP04/Mechanical-Hardness-Inspector/#how-to-use","title":"How To Use","text":"<p>The application has to be run differently based on the installation method used.</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#running-the-app-using-docker","title":"Running the app using Docker","text":"<p>During the installation a docker image with the app was built. A container can be started by: <pre><code>docker run mhi\n</code></pre> On Windows, the docker desktop daemon must be running before the previous command could be issued. This command starts services for the backend and the frontend on the localhost.</p>"},{"location":"WP04/Mechanical-Hardness-Inspector/#running-the-app-manually","title":"Running the app manually","text":"<p>To run the app manualy the back end and the front end have to be instantiated as separate processes.</p> <ul> <li> <p>The backend is run locally by issuing the following commands. From the root directory of the app, execute:     <pre><code>cd ./subsystems/backend/\nflask run\n</code></pre>     The previous command runs the app on the default flask web server. For a production deployment a WSGI dedicated server should     be used instead. The application can be served on gunicorn (not compatible con windows) or waitress:</p> <ul> <li>Gunicorn <pre><code>cd ./subsystems/backend/\ngunicorn -b :5000 - mhi:app\n</code></pre></li> <li>Waitress <pre><code>cd ./subsystems/backend/\nwaitress-serve --host 127.0.0.1 --port 5000 mhi:app\n</code></pre> This procedures deploys the backend server on the port 5000 of the local host.</li> </ul> </li> <li> <p>To start the front end on the local host, run the following commands from the root directory of the app:     <pre><code>cd ./subsystems/frontend/\nnpm start\n</code></pre></p> </li> </ul>"},{"location":"WP04/Mechanical-Hardness-Inspector/#user-manual","title":"User Manual","text":"<p>This app consists of 2 main windows: Model loading and Model Simulation.</p> <p></p> <p>In the 'Model loading' tab, the user can load a specific Digital Twin into the application in .pt format. Once the model is loaded, it must be selected in the 'Model Database' table. </p> <p>There are two types of simulation: the individual upload of a single file (Upload file) and the streaming simulation of files sent via MQTT protocol to the app (Streaming). Once the desired simulation type is selected, the necessary additional information must be completed: upload the file in the case of 'Upload File' and configure the broker parameters to send messages via MQTT in 'Streaming'. </p> <p>In both cases, it is also possible to specify a target for the Hardened Depth, to later evaluate how long it takes to reach it according to the simulation.</p> <p></p> <p>In the 'Model simulation' window, all that\u2019s needed is to click the 'Run simulation' button. For both types of simulation, two graphs will be displayed: one with the sensor input values and another with the value of the hardened layer obtained, all of them over time. Additionally, in each case, the time taken to reach the specified hardened layer, according to the simulation, will also be shown. The app allows exporting this data to a .txt file.</p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/","title":"Mid Infra Red OCT-2D","text":""},{"location":"WP04/Mid-Infra-Red-OCT-2D/#general-description","title":"General Description","text":"<p>This app is based on MIR-OCT inspection. The app will allow end-users to monitor a material or a component condition. This monitoring is based on the following:  i. Surface and sub-surface visualization  ii. Automatic defect detection based on AI.</p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>OCT Visualization: It allows the loading of images obtained by Optical Coherence Tomography (OCT), offering a detailed graphical representation.</li> <li>CNN defect localization: Using Convolutional Neural Networks (CNN), this feature locates and highlights areas of potential defects or anomalies in OCT images, making it easier to identify and analyse problem areas.</li> <li>Contrast-Brightness: Allows you to adjust the contrast and brightness of OCT images to improve clarity and readability, aiding more accurate detection of subtle details and important features.</li> <li>Speckle Reduction/Smoothing: This feature reduces speckle noise present in OCT images, improving image quality and providing a clearer and sharper visual representation of internal structures.</li> <li>Transparency: Allows you to adjust the transparency of overlay images or viewing layers, making it easier to compare and overlay images for more detailed analysis.</li> <li>XY Slice Inspection: Facilitates detailed inspection of OCT images in the XY plane.</li> <li>YZ Slice Inspection: Enables inspection of OCT images in the YZ plane, providing a lateral view that aids in the three-dimensional understanding of structures.</li> <li>XZ Slice Inspection: This function offers the possibility of inspecting OCT images in the XZ plane, allowing the visualisation of the XZ plane.</li> <li>Scale bars: Adds scale bars to OCT images to provide a visual reference of the actual dimensions of observed structures, aiding in the accurate assessment of size and distance.</li> <li>Volume Scrolling: Allows you to scroll through volumes of OCT image data to explore different sections and layers, facilitating a comprehensive and systematic analysis of structures and anomalies present in volumetric data.</li> </ol>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#architecture-diagram","title":"Architecture Diagram","text":"<p>The architecture diagram is shown in the figure. Through the GUI and its various screens, the actor communicates with the 'Defect Inspector' module, uploading the images in PNG format obtained by the MIR-OCT system. This module communicates with the preprocessing module to adjust the parameters of the images, which are sent to the AI module for defect detection and classification. The results are produced and analyzed in the Defect Inspector module, and the AI model for defect detection and classification and the results are kept in the storage. </p> <p></p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#image-overview","title":"Image Overview","text":"<p>The App comprises a graphical user interface (GUI) composed of three windows or panels that allow interaction with the files and functionalities of the application. These windows are divided into \u2018Login\u2019, \u2018Projects\u2019,  and \u2018Visualization and Analysis\u2019. The \u2018Projects\u2019 window will allow the user: - Create a new project and load the PNG images to be analyzed. - Access a previous project - Delete a project</p> <p></p> <p>The \u2018Visualization and Analysis\u2019 window consists of visualization tools that comprises:  - XY, YZ and XZ slices -- to search specific dimensions for interfaces and objects in the volume. - Image Selector -- to choose the plane (XY, YZ, XZ) as the main view to be inspected. - Slider bars -- To scroll the slices and visualize them along the volume. - Brightness, Contrast, Speckle reduction and Transparency \u2013- to manipulate voxels values and suppress speckle noise for increasing local structure contrast in volume.  </p> <p>The \u2018Visualization and Analysis\u2019 panel also allows to assess the defect detection of the OCT samples. Below the display tools there is a \u201cPredict\u201d button to start the object detection model which, after a few seconds, displays the bounding boxes of each frame in which it is able to find defects. The view for defect detection must be set in the XY plane.</p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#hardware-components","title":"Hardware Components","text":"<p>Edge processing unit based on GPUs: AI inference optimized on available GPU hardware with 100% high-rate inspection. </p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#computation-requirements","title":"Computation Requirements","text":"<ul> <li>Classification of images to detect defects can rely on cloud services</li> <li>Possibility to store acquired data locally or in shared/cloud space</li> </ul>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#installation-procedure","title":"Installation Procedure","text":"<p>(To be developed) Step by step on how to install the application: * Standalone * In the Kubernetes platformm using helm charts: description of the different options</p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#how-to-use","title":"How To Use","text":"<p>The instructions to follow for the use of the app will be defined once the application has been developed. The following can be established as a provisional guideline: 1. Open the web app. 2. Enter the registered user and password. 3. The 'Projects' window will open where you can add a new project, access a previously created project or delete a project. 4. Create a new project by pressing the '+' button and name it. 5. Click on the 'Select Images' button to load the set of images to be analyzed. 5. In the 'Visualization and Analysis' window, scroll through the slices and edit the settings (brightness, contrast, transparency, mottling reduction) of the volume/slices. 6. Use the 'Predict' button to evaluate the OCT defect detection. </p>"},{"location":"WP04/Mid-Infra-Red-OCT-2D/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials or work from WP10</p>"},{"location":"WP05/2D-Surface-Inspector/","title":"2D Surface Inspector","text":""},{"location":"WP05/2D-Surface-Inspector/#general-description","title":"General Description","text":"<p>The 2D Surface Inspector (2DSI) is an app that enables acquisition and analysis of 2D camera images to assess the quality and conformity of products in high throughput industrial production lines, controlling dimensional shapes of extracted features, and/or detecting anomalies in the product surface.  </p> <p>To comply with high inspection rates, high-speed frame rate acquisition cameras are used, and the image analysis algorithms can be optimized and deployed on edge processing units based on GPUs, which allow the exploitation of Artificial Intelligence models for run-time quality inspection.  </p> <p>Linked to this, a suite of web-based services, eventually offered with in-cloud flavour (SaaS), covers from the design and test of use case-based processing flows down to the (re-)training of AI neural networks for classification, defect detection, image generation, based on the acquired and annotated datasets, eventually extended with artificially generated ones.  </p> <p>Video Systems (VSYS) is the only partner responsible of the app.</p>"},{"location":"WP05/2D-Surface-Inspector/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>High speed camera acquisition: Possibility to acquire images of more than 1000 parts/minute, to cope with high-throughput production lines. This is a crucial requirement in many manufacturing scenarios, to be able to inspect in-line 100% parts for ZD production.</li> <li>Edge processing unit based on GPUs, and AI optimization (inference, generation) based on it: Development of new (with respect to Video Systems' background) edge processing units integrating with nVidia Jetson platform GPUs: the goal is to host into a compact embedded system the possibility to run AI trained models in an optimized acceleration framework, so to be able to inspect with AI-based technology (object detection, classification, ...) 100% parts of high-throughput production lines.</li> <li>Edge devices industrial protocols capabilities (OPCUA, MODBUS IP) and automation signals: To facilitate in-plant integration, the vision inspection system needs to support not only I/O signals but also most common industrial communication standards and protocols, like MODBSU TCP/IP and OPC UA.</li> <li>IIoT edge devices communication (MQTT, AMQP) and acquired image streaming: To extend industrial communication capabilities in the frame of IIoT, messaging protocols like MQTT and AMQP are mandatory to facilitate integration between devices and cloud services. High-rate acquired images are also available as a network stream service.</li> <li>Contours/features extraction and visualization for dimensional conformity and shape controls: Libraries and functionalities to extract contours or specific features from the image of the product are the core of the application as they allow dimensional analysis and conformity and/or detection of anomalies.</li> <li>Cloud based annotating and AI training tools (classification, annotation, generation): A suite of AI tools for classification, annotation and generation will be built based on separation of frontend (React based web interfaces) and backend (Restful http based open API). This will facilitate the deployment and integration of services into ZDZW platform, in particular once the transfer from docker technology to Kubernetes will take place. The whole workflow will be covered for each type of AI service, starting from classification/annotation, managing the training phase, ending with inference/generation of batched data to test the trained networks.  </li> <li>GAN based anomaly detection and data augmentation: GAN (Generative Adversarial Networks) will also be part of AI services ecosystem, as they can be naturally exploited for anomaly detection but also for data augmentation when the number of defected parts is low and augmentation is welcome to improve the training phase.</li> <li>Supervised and semi-supervised anomaly detection AI techniques: Supervised AI techniques deal with classification, object detection and segmentation to extract features and/or defects: they request an annotation/classification phase, where defects/classes should be confirmed/annotated by inspection experts using a web-based service. Semi-supervised techniques for anomaly detection involve the use of networks trained only on non-defective parts (representing normal operating conditions), so that anomalous conditions can also be identified in newly inspected images.</li> <li>Ease to deploy AI trained models in a SaaS scheme: Once AI models have been properly trained and tested, they can be saved/exported and furtherly deployed for final inspection. The deployment of models can be optimized to be on an edge unit (see functionality 2) for in-line and real time high speed inspection, but can also be exploited as a cloud service in an SaaS (Software-as-a-Service) scheme: in the latter case, the AI web-based inference service can be used or its backend can be interrogated through open API end points, or as an alternative, the model can be included in a more complex algorithm flow design through the utilization of the so-called inference blocks in the AV Designer service (functionality 10)</li> <li>Ease to design and deploy Artificial Vision algorithms in a SaaS scheme: Last functionality deals with the possibility to design and test AV algorithm using a web interface, by connecting inputs and outputs of processing functions represented as blocks in a diagram canvas, in order to graphically prepare a complete processing flow: once saved as an algorithm, it can be re-used to run inspections through RESTful calls to the runtime backend of this service, which acts as a cloud processing engine. Also, AI models once trained can be exported and used in this schema through so-called inference blocks (see functionality 9).</li> </ol>"},{"location":"WP05/2D-Surface-Inspector/#architecture-diagram","title":"Architecture Diagram","text":"<p>The Figure represents the high level architecture diagram of the 2D Surface Inspector application. </p> <p>The solution has been divided in two macro-areas:  </p> <ul> <li>2DSI Vision SaaS suite: it covers all the software design services, which can run on-cloud and are handled by web-based frontend interfaces, including AI services of classification, annotation, generation of images and training of related models</li> <li>z2DSI App: it is the in-line surface inspecting system, an edge acquisition and processing unit, where optimized inspecting algorithms and AI models are finally deployed  </li> </ul> <p>2DSI Vision SaaS suite is composed of the following modules:  </p> <ul> <li> <p>Runtime Designer: The Designer is a user interface used by users to develop and debug Computer Vision algorithms. The Designer displays the list of Runtime Modules\u2019 functions as building blocks, and a flow can be created from these blocks; this flow can be tested with offline images/data through the Runtime Backend and saved as a recipe in the Internal Filesystem Storage.</p> </li> <li> <p>Runtime Backend: this component receives the processing requests from the Runtime Designer and/or the Non-Destructive Inspection APIs and orchestrates the flow to sequentially call the Runtime Modules\u2019 functions. It also accesses the Internal Filesystem Storage to access recipes, trained models, and images, and it forwards them to the correct functions.</p> </li> <li> <p>Internal Filesystem Storage: private high-speed space to store images, trained models, and recipes; it is accessible from user interface. It builds upon the system level Storage based on persistent volumes data.</p> </li> <li> <p>persistent volumes Storage: low level storage area reserved at deployment.</p> </li> <li> <p>Runtime Modules: this box in the diagram encapsulates a set of Computer Vision standalone modules; a module is a package that contains a list of processing functions in a common subdomain, like Artificial Intelligence, Silhouette analysis, and Traditional Machine Vision. These modules are managed by the Runtime Backend. New modules can be developed with the use of the Module Creator. Follows a list of some Runtime Modules (divided in AI modules and \u201cClassic\u201d modules) that are used to build quality inspection applications:  </p> <ol> <li> <p>Silhouette Extractor / Comparator: to extract significant product contours from digital images as a function of search processing input; to make a parametrised comparison of two contours, one usually extracted from in-field and another typically coming from a reference image or an ideal shape (circle, rectangle, \u2026).</p> </li> <li> <p>Traditional Machine Vision: this module includes classical machine vision techniques for image pre-processing and features extraction, like contour analysis, blob analysis, histogram analysis, morphological and geometric transformations, thresholding, etc.</p> </li> <li> <p>AI Image Classifier Inference: this module runs the inference using classification models trained through the AI Image Classifier service.</p> </li> <li> <p>AI Image Labeller Inference: this module runs the inference using annotation models trained through the AI Image Labeller service.</p> </li> <li> <p>AI Image GAN generation: this module runs the image generation using GAN models trained through the AI Image GAN Generator service.</p> </li> </ol> </li> <li> <p>Module Creator: this user interface is used to develop new modules to be added to the Runtime Modules. New modules can be developed when new Computer Vision techniques are published by the community.</p> </li> <li> <p>Builder: this user interface is used to deploy an instance of the Runtime with the selected modules. It communicates with the Application Runtime APIs to deploy the new Runtime.</p> </li> <li> <p>Non-Destructive 2DSI Inspection APIs: this interface is used by zApps or other applications/solutions to run Computer Vision algorithms with runtime or historic data.</p> </li> <li> <p>Application Runtime APIs: an integration with the Application Runtime (Kubernetes) of the ZDZW platform is implemented to allow the dynamic provisioning of a selection of available modules or newly developed (through the Module Creator) ones resulting into a dynamic (size-controlled) installation of a Runtime instance (via the Builder).  </p> </li> </ul> <p>z2DSI App is more focused on the functionalities of the edge processing unit; it is composed of the following modules:  </p> <ul> <li> <p>z2DSI UI: this web-based interface allows to configure image acquisition parameters (acquisition trigger mode, capture exposure time, programmable illuminator, \u2026) as well as processing parameters and communication settings; it allows to control basic operation of the system, also visualizing raw images and results.</p> </li> <li> <p>z2DSI Processing Manager: it is the core of the embedded system, orchestrating the main data flow, firstly the image processing (two processing schemas: through GPUs-optimized AI model deployment or exploiting the SaaS interface of the 2DSI), secondly the external communication of results/alerts, through industrial standard protocols, automation signals and IIoT message publishing and listening.</p> </li> <li> <p>Edge-optimized Processing Engine: it processes captured images, exploiting GPUs acceleration for inference/generation of previously trained AI models.</p> </li> <li> <p>Inspection Hardware: this block comprises the in-field hardware, mainly the image sensor head, and the illumination device; captured images can be configured to be saved externally (shared space) or internally.</p> </li> <li> <p>Internal Image Storage: an internal area for image storage, accessible from outside.</p> </li> <li> <p>Industrial Protocols / Automation / IIoT: this deals with possible data exchange with external systems, mainly communication with PLCs, PCs, and IIoT messages.  </p> </li> </ul>"},{"location":"WP05/2D-Surface-Inspector/#image-overview","title":"Image Overview","text":"<p>The typical flow of preparing a supervised AI model includes the phase of classifying images, or annotating and classifying features inside them using an annotation tool, the training phase, and finally the phase of using the model on a test dataset to validate its performance: the 2DSI suite of web-based tools covers all these operations. The graphical design tool to build machine vision algorithms is also shown.</p>"},{"location":"WP05/2D-Surface-Inspector/#hardware-components","title":"Hardware Components","text":"<p>Referring to the z2DSI App block of the architectural diagram, the in-field hardware components required to realise a complete inline inspection application are mainly the Video Systems image sensor and the Video Systems edge unit: the latter is an embedded server, called Ingenium\u00ae, based on a real-time Linux OS, to manage image acquisition and processing. A new redesign of the edge unit involves the hardware integration with NVIDIA\u00ae Jetson\u2122 GPU platform, to optimize the execution of AI models, ultimately increasing the frequency of images that can be processed to enable 100% inspection on high production lines.  </p> <p>Full archiving of captured images can be supported by saving images on a shared network space of an appropriate size. </p>"},{"location":"WP05/2D-Surface-Inspector/#computation-requirements","title":"Computation Requirements","text":"<p>Here follow details about typical recommended requirements for the standalone installation and operation of on-line services, the ones under 2DSI Vision SaaS suite in the architectural diagram, having in mind the computational needs of the trainig phase of the AI services.</p> <ul> <li>OS: XUbuntu 23.x</li> <li>CPU: 2.30GHz \u00d7 16 (i7 11G)</li> <li>RAM: 32 GB</li> <li>Storage: &gt; 512 GB</li> <li>GPU: NVIDIA RTX A2000</li> </ul>"},{"location":"WP05/2D-Surface-Inspector/#installation-procedure","title":"Installation Procedure","text":"<p>The web applications of the 2DSI Vision SaaS suite, like the VSYS AI Suite - Trainer and the VSYS AI Suite - Inference services are available on Video Systems' on-line servers to be used once the relative usage license is bougth from the ZDZW marketplace; in this sense no installation is needed to be managed by the final user of the services. The plan is also to give the option to let the serivces run on in-premises (internet separated network) servers of the customer: for such option a docker installation package can be provided or most realistically the installation includes an active commissioning (and maintenance) phase.</p> <p>The edge solutions need a customization of the analysis and hardware to integrate with the specific production line and existing automation. In this sense there is no pre-defined installation procedure, but the final solution is rather commissioned at customer\u2019s premises.</p>"},{"location":"WP05/2D-Surface-Inspector/#how-to-use","title":"How To Use","text":"<p>The whole framework of the web tools for vision algorithm design, including also the AI suite for building AI models, is accessible from a landing page available at this https://zdzw.videosystems.it/. The page is divided in two, describing on top the content and purpose of the Algorithm Designer, which is a free-access tool at the moment, while on the bottom the AI suite services are presented, with the AI Image Annotator separated from the AI Training and Inference services. </p>"},{"location":"WP05/2D-Surface-Inspector/#designer","title":"Designer","text":"<p>Through the related link of the landing page, it is possible to use the Designer to build and test machine vision algorithms based on a graphical \u201cno-code\u201d approach, where building blocks representing most common image processing functions can be linked together to build a complete processing flow to be used and saved as an algorithm (recipe). To do that, the available blocks are grouped under specific modules, that can be selected from the entry dialogue pressing the Choose Modules button.  All available modules are then listed (more modules or updated versions of the existing ones can be added in the future) to be loaded, and the documentation of each can also be browsed at this point when clicking on the Documentation button.  Description of each function available in each module is presented, including all the input and output parameters of the corresponding block.  Once all the modules are loaded, their content including the description becomes browsable on the left side of the page and it is finally possible to select the function block to be added (Add button) on the main canvas (Info button again opens a more complete and accessible description of the function; same from the \u201ci\u201d icon present on the loaded block).  Blocks are supposed to be linked together, connecting the output parameters of one block with the input ones of the following, so to design a processing flow. We report here some examples of designed algorithms while focusing on the content of the different modules. Once designed and tested (use Process button for execution) with the support of visualization tools, the processing flow can be saved as a recipe from the Export button on top right of the page; similarly, a saved recipe can be loaded with Import to be used/modified. * Traditional Machine Vision module: these functions represent an exhaustive list of typical machine vision operations (reshape, thresholding, conversion, concatenation, blob counting, \u2026)  * Silhouette Suite module: these functions allow extraction, measurement and comparison of contours with reference ones or typical geometrical shapes  * Video Systems AI Suite module: these functions allow to import AI models trained and saved with the AI training service, to include them in a processing flow. The example below shows the use of the AI models prepared to handle one of the industrial case study of ZDZW project: a segmentation model is used first to identify the circular septum on the bottom of coffee capsule (produced by Illycaff\u00e8), then the cropped part of the image circumscribing the identified septum is analysed with a detection model trained to identify the hole, so to finally measure its relative distance from the septum centre </p>"},{"location":"WP05/2D-Surface-Inspector/#annotator","title":"Annotator","text":"<p>Through the related link of the landing page, it is possible to enter the AI image annotator tool, which allows to annotate dataset of images, mainly in terms of classification, object detection and segmentation. Once logged in, the entering page shows all projects previously created by a user.   To work with a new set of images that need to be annotated, a new project needs to be created (New project button) and then the images uploaded inside (UPLOAD button): more images can be added as well as some can be removed at any time, updating the list of images within a project.  Once a project has been created, the list of uploaded images or previews of them appear in the main section, and a new dataset can be created (New dataset button) to proceed with the classification or annotation of the images available within the project. All images, or just a selection of them, can be associated to one dataset to be then annotated: more datasets can be associated to the same project, with the idea to explore different annotation approaches and/or use only a selected subset of the full set of images.  When clicking on ANNOTATE or CLASSIFY on one of the datasets created and listed on the right of the page, a new page opens where the annotation or classification work is done by selecting one by one all the images previously associated for such dataset.  Features of interest on each image can be annotated with various shapes selectable on the bottom right - rectangles (valuable for object detection networks), ellipses, polygons with vertexes, \u201cfreehand\u201d polygons (more appropriate for segmentation networks) - and each annotation can be assigned to a specific class on the top right, where classes can be created and named at will. There is also a SAM (Segment Anything Model) engine that can be used in a separate page for semi-automatic segmentation of the image.  The classification page is even simpler than the annotation one, as the whole image is to be assigned to a single class. Filtering functionalities are available to search and select images for name, class, already annotated images or still to be, so to facilitate the often-tedious annotation procedure. All annotations done are automatically saved and the prepared dataset can be finally used for the next step of training (or re-training) the AI model.</p>"},{"location":"WP05/2D-Surface-Inspector/#training","title":"Training","text":"<p>Through the related link of the landing page, but also from anchors available on the Annotator pages, it is possible to enter the AI Training and Inference tools, which allow to launch trainings on annotated images or perform inferences with already trained models on additional images used for testing. Once logged, the user chooses which service to proceed with.  If training is selected, the list of previously run training processes is provided, with the name, date and status of completion; when selecting one, additional related information is visualized on the right, mainly regarding the parameters used to run the training, and the possibility to explore more with the Continue button.  Once Continue is pressed the page with the metrics of the training process and their graph along the training epochs is shown. From this page the last or the best model of the training can be downloaded.  While pressing New training button from the page containing the list of historic trainings, the choice is given about the type of neural networks to be trained, finally depending upon the type of annotated dataset to be used for training.  Once selected the appropriate type, the list of projects available for the user is presented and when selecting one of them, also the list of the associated database is shown.  Once selected the desired dataset, it is possible to continue moving to a review page showing the related images and the annotations done on them, with the possibility to return to the Annotator for modification of the dataset if needed.  Otherwise by pressing the Continue button, the last page for training launch preparation is presented, including the selection of the training network and some typical training parameters, proposed with default but adjustable values.  When Train button is pressed, the training is launched and the page with the metrics and their graph is shown and updated for each concluded epoch while the process is running, with the possibility to stop it at any time. From this page, when the training has been completed or stopped, it is also possible to press the Inference button, which allows to enter the AI Inference service to be used with the trained model in question.</p>"},{"location":"WP05/2D-Surface-Inspector/#inference","title":"Inference","text":"<p>The other possibility to use this service is to start with the Inference option from the main page of the AI training and Inference tools, selecting Inference: the list of previously run inferences is then proposed.  By selecting one historic inference, one can see related information, including the training process from which the trained model was obtained to run the inference: by pressing Continue, the results previously obtained are presented, and can be re-examined for each image that has been analysed.  Also, more images can be uploaded, to run an inference on each of them using the same trained model.  While pressing New Inference button from the page containing the list of historic inferences, first a page is proposed with the list of historic training processes and by selecting one of them, the Inference button can be pressed to be able to run inferences with that specific trained model.  The last step before uploading the images to be analysed is a page proposing some parameters to run the inference. </p>"},{"location":"WP05/2D-Surface-Inspector/#2dsi-edge-application","title":"2DSI edge application","text":"<p>The typical layout of a customized edge application deployed to inspect in-line quality of manufactured parts contains more web pages for representation of live and historical inspection results. A live page is continuously refreshed with the last processed image and the results of the analysis, and possible recent alerts if some alarm thresholds defined on the quality parameters have been overcome. In the example below, always taken from the industrial case study of the control of the hole in the coffee capsule assembly in Illycaff\u00e8, the results are grouped as a function of the needle ID that just punched the hole in the analysed capsule.  In the Data page, statistics of historical results and trends reported exploiting Grafana dashboard technology, allowing to select the time window of interest.  Finally, a Review page is thought to recover for re-check purposes the stored images, filtering on time and analysis results. </p>"},{"location":"WP05/2D-Surface-Inspector/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>https://www.youtube.com/watch?v=aR1dsZW2PuQ</p>"},{"location":"WP05/3D-Surface-Inspector/","title":"3D Surface Inspector","text":""},{"location":"WP05/3D-Surface-Inspector/#general-description","title":"General Description","text":"<p>The 3D Surface Inspector (3DSi) is an app that enables monitoring and control of a  multicamera quality assurance device. Equipped with advanced Artificial Intelligence (AI)  algorithms and state-of-the-art technology, 3DSi perform 3D reconstruction using images  of the object from multiple angles. It empowers users to perform accurate volumetric  analysis and conduct precise surface quality checks, detecting extra or missing material  as well as scratches or any other texture defect. Ideal for industries that require  meticulous measurements and assessments, 3DSi provides comprehensive data for  informed decision-making.</p> <p>ITI is the only partner responsible of the app.</p>"},{"location":"WP05/3D-Surface-Inspector/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>3D Alignment based on geometry and texture: Matching geometry and texture for accurate spacial correspondence with the reference model.</p> </li> <li> <p>Global and local thresholding: Define total amount and localized defects in order to reject the inspected part.</p> </li> <li> <p>Automatic measure drift detection: Store and analyze the measurements in order to detect a drift in the production quality.</p> </li> <li> <p>3D Visualization of defects: Representation of detected defects located on the 3D reconstruction of the inspected object.</p> </li> <li> <p>Global volume difference: Volumetric difference between the reconstructed object and the expected 3D shape of it, measuring extra and missing volume.</p> </li> <li> <p>Colour drift detection: Calibrated colour difference between real object and expected.</p> </li> <li> <p>Generation of 3D localized texture model: Generate a texture model related to the 3D space of the expected object.</p> </li> <li> <p>Object classification based on 3D characteristics: Reference identification using 3D attributes of the obtained reconstruction.</p> </li> <li> <p>Region of interest specification: Specify which regions of the 3D space will be analyzed with different quality thresholds.</p> </li> <li> <p>Texture difference from expected texture: Comparison of the expected texture with that obtained in the images and located in the 3D reference.</p> </li> </ol>"},{"location":"WP05/3D-Surface-Inspector/#architecture-diagram","title":"Architecture Diagram","text":"<ul> <li>3DSi UI: This user interface facilitates interaction with the Volumetric Inspector  and the Surface Anomaly Detection solution.</li> <li>3DSi API: This module establishes connections with other components through  the web-based user interface.</li> <li>Defect detection suite: As the core component of the application, it orchestrates  the operation of all other components in response to external client requests.</li> <li>Defect detection processor: This component performs quality analysis using the  provided data.</li> <li>Model manager: Responsible for receiving models, generating necessary analysis  files, and serving them back as required.</li> <li>Storage: This component ensures persistent data storage for the solution,  including 3D models, texture models, images, and results.</li> <li>Hardware API: It serves as the interface for connecting with the physical devices  involved in the capture process.</li> <li>Inspection Hardware: This external hardware is dedicated to capturing images of  the inspected objects.</li> </ul>"},{"location":"WP05/3D-Surface-Inspector/#image-overview","title":"Image Overview","text":""},{"location":"WP05/3D-Surface-Inspector/#hardware-components","title":"Hardware Components","text":"<ul> <li>Calibrated multicamera device</li> <li>Lighting system</li> <li>Industrial PLC</li> </ul>"},{"location":"WP05/3D-Surface-Inspector/#computation-requirements","title":"Computation Requirements","text":"<ul> <li>OS Required: Ubuntu 20.04</li> <li>CPU: 32 cores, 3.5GHz (intel i7 or Ryzen 9)</li> <li>RAM: 32GB</li> <li>Storage: 1TB NVME</li> </ul>"},{"location":"WP05/3D-Surface-Inspector/#installation-procedure","title":"Installation Procedure","text":"<p>Once you purchase the zApp, a docker image in a tar format is provided. Load it with</p> <pre><code>docker load -i 3dsi.tar\n</code></pre> <p>The application is also available together with the associated inspection equipment.</p>"},{"location":"WP05/3D-Surface-Inspector/#how-to-use","title":"How To Use","text":"<p>The 3D Surface Inspector (3DSi) application features a user-friendly interface designed to streamline the inspection process. This section provides an overview of the main components of the application, including the Home, Production Inspector, and Surface Tool sections. Each section is tailored to facilitate efficient management and analysis of quality inspections, ensuring users can easily navigate and utilize the application's capabilities.</p>"},{"location":"WP05/3D-Surface-Inspector/#home","title":"Home","text":"<p>   In this section, users can start and stop inspection processes.   - Task Selection: Users can select a task from a dropdown menu. Each task includes:     - Expected References: A set of references to be analyzed.     - Analysis Types: Types of analyses to be performed, including:       - Volumetric: Analysis of the volume of surfaces.       - GDNT (Geometric Dimensioning and Tolerancing): Analysis of geometric tolerances.       - Surface: Analysis of surface quality.   - Event and Error Viewer: Access to a panel that notifies users of any errors or issues that may arise during inspection processes, allowing for efficient problem identification and resolution.   - START/STOP button: This button will start/stop the adquisition of images for the quality analisis.</p>"},{"location":"WP05/3D-Surface-Inspector/#production-inspector","title":"Production Inspector","text":"<p>   - In this section, users can inspect the individual results of each analyzed piece.   - Trend Graphs: Visualization of graphs showing trends for the measurements configured in the task.   - Result Details:      - By clicking on the magnifying glass icon, users can access the \"Result Details\" tab, where tables with numerical values of the results can be viewed.   - Part Viewer:      - The eye icon leads to the \"Part Viewer\" section, where users can observe the 3D reconstruction created by the system, as well as the original images taken by the cameras.</p>"},{"location":"WP05/3D-Surface-Inspector/#surface-tool","title":"Surface Tool","text":"<p> In this section, users can select a list of pieces from a batch of correct pieces captured earlier.   - Model Training: These pieces are used to train a model for detecting surface defects.   - Model Evaluation and Application: Once the model is trained, it can be evaluated and applied to future tasks to enhance defect detection. To use this tool, the user need to have a valid license for this functionality.</p>"},{"location":"WP05/3D-Surface-Inspector/#license-manager","title":"License Manager","text":"<p> In this view, users can see the available smart contracts. By selecting one of these contracts, it displays its current status.</p>"},{"location":"WP05/3D-Surface-Inspector/#additional-learning-materials","title":"Additional Learning Materials","text":""},{"location":"WP05/AI-Enhanced-Painting-Inspector/","title":"AI-Enhanced Painting Inspector","text":""},{"location":"WP05/AI-Enhanced-Painting-Inspector/#general-description","title":"General Description","text":"<p>Typically, computer vision systems used for production quality control are fixed in position, and products pass through the cameras\u2019 field of view on a conveyor belt. However, this approach is not feasible in cases where the objects to be inspected have very large dimensions, such as windmill towers. Moving these products through a factory presents a complex problem in itself. To avoid this problem, the ZDZW AI-Enhanced Painting Inspector relies on moving the inspection system to avoid moving the product as much as possible. </p> <p>The AI Enhanced Painting Inspector app, developed as part of the ZDZW project, is focused on this specific type of environment.</p>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>AI Inference on the Edge. Capability of performing AI inference in the edge device deployed at the factory.</p> </li> <li> <p>Semi-autonomous Inspection Platform. Possibility of having a platform that can be guided through the factory to inspect large objects.</p> </li> <li> <p>Compatibility with any GeniCam compliant camera.Capability of connecting with any Industrial camera which uses the GeniCam standard.</p> </li> <li> <p>Facility to deploy Artificial Vision models. Facility of improving or adapting the computer vision model to the specific problem.</p> </li> <li> <p>Screen visualization of defects. Ability to monitor the system while performing the inspection.</p> </li> <li> <p>Collect samples for fine-tuning the model. The possibility of acquiring additional images once the AI model has bee deployed. Thanks to that, novel versions of the AI model could be developing in parallel.</p> </li> <li> <p>Flexible camera-illumination setup. The ability of having adjustability of the camera-illumination setup.</p> </li> <li> <p>Provide high-speed and low latency quality feedback. Having the possibility of receive real-time feedback for the operator of the region of the object inspected.</p> </li> <li> <p>Obtain metrics to evaluate the inference accuracy of the model. Visualise and analyse statistics of the defects detected and the accuracy of the model.</p> </li> <li> <p>Industry standard communications (e.g., OPCUA).Capability to communicate with the inspection system through OPCUA.</p> </li> </ol>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#architecture-diagram","title":"Architecture Diagram","text":"<p>The high level Architecture diagram from the Sofware Specification document</p> <p></p> <ul> <li>Cameras: GenICam compliant cameras.</li> <li>Inspection Pipeline: Software unit that performes the machine learning inferences and coordinates the image acquisition with physical movement.</li> <li>Movement Control: The hardware that controls the movement of the inspections system.</li> <li>Positioning: The hardware that provides the position of the inpection hardware.</li> <li>Encoder. Retrieves the rotational position of an large object.</li> <li>.... Other devices necessary for the specific application.</li> <li>Monitoring Client: GUI that connects through OPC-UA to the edge device, to monitor the system and visualize a live-view.</li> <li>Defect Database: Database that stores the defective patchs detected by the system, with their positioning and image.</li> <li>WP7 components: The modules associated with cloud infrastructure of ZDZW.</li> </ul>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#image-overview","title":"Image Overview","text":""},{"location":"WP05/AI-Enhanced-Painting-Inspector/#hardware-components","title":"Hardware Components","text":"<ul> <li>AMD64 or ARM64 PC </li> <li>Cameras</li> <li>Illumination bars</li> <li>Robotic or manual ancillary</li> <li>Positioning hardware </li> </ul>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#computation-requirements","title":"Computation Requirements","text":"<ul> <li>OS Required: Ubuntu 22.04</li> <li>CPU: Intel i5-12600K, Jetson AGX Orin</li> <li>GPU: nvidia A2000 12 GB, nvidia RTX3060, Jetson AGX Orin</li> <li>Storage: 500GB SSD</li> </ul>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#installation-procedure","title":"Installation Procedure","text":"<p>The installation must be carried out by qualified personnel during the consultancy services associated with the solution.</p>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#how-to-use","title":"How to Use","text":"<p>The inspection software initializes together with the robot. To interact with the system, the operator must use the application\u2019s Monitoring Client, which can be run on any laptop with network access. The graphical user interface (GUI) of this tool is shown in the figure below:</p> <p></p> <p>To perform an inspection, follow these steps:</p> <ol> <li>Connect the PC to the same network as the robot.</li> <li>Enter the robot\u2019s IP address and click Connect. If the connection is successful, the Connection Status will update to \"Connected\".</li> <li>Enter the organization name, the Smart Contract obtained through the Marketplace, and the API token. This step activates the application and enables the traceability module. Once completed, the application will be ready to perform inspections.</li> <li>Enter the product reference and tower dimensions, then click Start to begin the inspection. The robot will move along the tower\u2019s longitudinal axis while capturing images. The Positioning &amp; Control section displays the status of the process. Once the scan is complete for the current angle, the robot will stop and prompt the operator to rotate the tower. After adjusting the angle, click Next Scan to proceed.</li> <li>The inspection process can be paused and resumed using the Pause and Continue buttons.</li> <li>The Liveview and Last Image sections display the camera feed with real-time inference and the most recent image captured. The camera source for each section can be selected from the dropdown menu beneath it.</li> <li>When the entire surface of the tower has been inspected, click the Finish button. To start a new inspection (beginning from step 4), repeat the procedure with the next tower.</li> </ol>"},{"location":"WP05/AI-Enhanced-Painting-Inspector/#additional-learning-materials","title":"Additional Learning Materials","text":""},{"location":"WP05/AR-Enhanced-Inspection/","title":"AR Enhanced Inspection","text":""},{"location":"WP05/AR-Enhanced-Inspection/#general-description","title":"General Description","text":"<p>The application allows users to navigate to previously recognized defects to verify and document the automatically found issues. In order to achieve this, the application understands its own position in relation to the inspected object. This task is divided in two parts: tracking the device position in the environment and recognizing the objects pose in this environment. Defect data from the automatic defect recognition step is imported into a backend service or provided via an API. The app\u2019s spatial understanding allows the user to be guided to the defect spots. The defect information is then superimposed on the defect site, and the user can proceed with further actions, like fixing the defect or documenting it with images or textual information.</p>"},{"location":"WP05/AR-Enhanced-Inspection/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>Device tracking in the environment: In order to have a consistent environment for virtual information, the device is keeping track of its on position and orientation in the real environment. Based on this, the examined objects position can be followed as well, after aligning it to the AR environment.</p> </li> <li> <p>Geometry import to generate reference structures: In order to visualize defects on an object's surface, its geometry needs to be known. The simplest approach is to import mesh data into the application. In the pilot, this information available as a parametric modell, which needs additional work to translate it into mesh-data. This step will most likely be developed as an external (out of the application) service.</p> </li> <li> <p>Defect data import: Data is provided to the mobile application via a Restful API. This API is either provided by the data producing application, or by a data server developed for this purpose. For this, an API for defect and associated Information was created and implemented in the Client application. A data server and import tools were developed.</p> </li> <li> <p>Robot arm pose import: Further analysis of the on-site workflow revealed that the robotic arm is not available while the application is in use, requiring a different way to locate the object in the AR space.</p> </li> <li> <p>Superimposition of found defect in AR: Defect information is superimposed on to the object's surface in the AR devices 3d view. This includes markings to identify the location as well as text information to identify the defect type and ID. Color can be used to identify the defects \"State\".</p> </li> <li> <p>Navigation to defect sites: The application shall guide the user through the physical environment, in order to find the next defect location. This either is done by visually highlighting all (relevant) locations in the devices field of view, or, by actively guiding the user to a specific defect (with visual hints).</p> </li> <li> <p>User guidance: The application shall guide the user through the applications workflow - give the user hints to go through all necessary steps for usage.</p> </li> <li> <p>Documentation support: A user shall be able to leave textual information on each defect (comment). A comment can be accompanied by an image taken on the mobile device. The user can change the \"Rating\" of the Defect (eg from \"recognized\" to \"needs rework\", \"cosmetic\", \"dirt\" or similar).</p> </li> </ol>"},{"location":"WP05/AR-Enhanced-Inspection/#architecture","title":"Architecture","text":"<ul> <li>AREI Controller: This Core module orchestrates the inspection session. It loads all needed data from the corresponding services as indicated by the session service and acts as a data backend for the UI. </li> <li>AREI UI: This module combines the tracking information (spatial relation between device and tracked object) and the defect information provided via the controller to superimpose the information onto the object in the cameras field of view. It also provides the user with an interface to add additional information to recognized defects. </li> <li>Model Tracking Module: The Model Tracking Module is responsible for recognizing the inspected object in the camera images and determine an exact enough position to superimpose content on the object. For this, the user sets a coarse alignment which will be refined by the algorithm. </li> <li>Scenario Controller: Contains information about which data belongs to the (current) session. Mainly data, tracking support data and CAD Models. </li> <li>Defect Store: This module provides access to the defect data, which either can be a service holding this data, or an API to directly access it in its original location. </li> <li>Ref Object Position Information Service: This module provides access to real time information on the pose of the inspected object and support machinery. Possible data include angle of the object (roll) or pose of the support robot arm. </li> <li>Model Manager: This module provides access to the object CAD data, which either can be a service holding this data, or an API to directly access it in its original location. Depending on the Data format, an integrated conversion step might be necessary. </li> </ul>"},{"location":"WP05/AR-Enhanced-Inspection/#image-overview","title":"Image Overview","text":"<p>The Slideshow shows three scenes from the application:</p> <ul> <li>A mockup of the defect overview.</li> <li>The app showing a virtual wind-tower segment with a defect indicator in Augmented Reality.</li> <li>The app showing a virtual wind-tower segment with a recorded defect image and input for textual annotations.</li> </ul>"},{"location":"WP05/AR-Enhanced-Inspection/#hardware-components","title":"Hardware Components","text":""},{"location":"WP05/AR-Enhanced-Inspection/#mobile-device","title":"Mobile Device","text":"<p>The handhelt mobile device in this application is the Apple iPad pro, with its integrated lidar sensor. With this hardware, the necessary accuracy can be reached. After Development, lower performnace devices can be tested and might be suitable as well.</p>"},{"location":"WP05/AR-Enhanced-Inspection/#backend-service","title":"Backend Service","text":"<p>If not directly connected to an Data Source Application via the documented API, the mobile applications connects to a Backend service, which only has to handle and manage data, without huge performance requirements. The Service is delivered as a Docker Image</p>"},{"location":"WP05/AR-Enhanced-Inspection/#computation-requirements","title":"Computation Requirements","text":""},{"location":"WP05/AR-Enhanced-Inspection/#mobile-application","title":"Mobile Application","text":"<p>M1 or A12Z iPad Pro</p>"},{"location":"WP05/AR-Enhanced-Inspection/#backend-service_1","title":"Backend Service","text":"<p>Docker host with 2GB RAM + 30GB Storage. Storage has to be scaled with the data to be held in the backend.</p>"},{"location":"WP05/AR-Enhanced-Inspection/#installation-procedure","title":"Installation Procedure","text":"<p>The instructions for installing the app will be defined once the application has been completed.</p>"},{"location":"WP05/AR-Enhanced-Inspection/#how-to-use","title":"How To Use","text":"<p>The instructions for using the app will be defined once the application has been completed.</p>"},{"location":"WP05/AR-Enhanced-Inspection/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials will be added once the application has been completed.</p>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/","title":"MIR-OCT Volumetric Inspection","text":""},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#general-description","title":"General Description","text":"<p>This app is based on MIR-OCT inspection. The app will allow end-users to monitor a material or a component condition. Among the options available, the user will be able to upload images, reduce their speckle noise and understand the internal structure of the analysed material. This tool mainly allows the detection, localisation, reconstruction and characterisation of the defects of the analysed part. This monitoring is based on the following: </p> <ul> <li>Surface and sub-surface visualization </li> <li>Automatic defect detection based on AI</li> </ul>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>OCT speckle noise reduction: The user will be able to upload images and preprocess them, reducing their speckle noise.</li> <li>Volume reconstruction from OCT slices: The pre-processing features allow for proper reconstruction, that comprise brightness and others to manipulate voxels values and suppress speckle noise for increasing local structure contrast in volume.</li> <li>Material layer segmentation from OCT images: The app identifies and separates distinct material layers for material diagnosis.</li> <li>Internal microstructure composition: Understanding the internal distribution of microscopic elements within a material.</li> <li>OCT depth estimation for characterization: Involves determining the precise position of features,  enabling detailed analysis.</li> <li>Refraction index estimation from OCT volumes: The app calculates automatically the refraction index.</li> <li>3D defect localization: Pinpointing the exact position within a three-dimensional space for precise identification and analysis.</li> <li>3D defect reconstruction: Creating a three-dimensional representation of defects for comprehensive visualization. </li> <li>3D defect characterization: Assessing and describing the nature and properties of defects within a three-dimensional context.</li> <li>3D visualization of defects: Presenting defects in a three-dimensional format for enhanced comprehension and accurate representation.</li> </ol>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#architecture-diagram","title":"Architecture Diagram","text":"<p>The solution is composed of several blocks: </p> <ul> <li> <p>GUI: The user interface facilitates interaction with the Defect Inspector and the Volumetric Inspection solution. </p> </li> <li> <p>Preprocessing: Features including brightness, contrast, speckle reduction, and transparency, to manipulate voxels values and suppress speckle noise to increase local structure contrast in volume. </p> </li> <li> <p>AI module: This module has the task to run inferences on the provided images using the model according to the chosen settings.  </p> </li> <li> <p>Storage: It will store the information of the defects detected. </p> </li> </ul>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#image-overview","title":"Image Overview","text":"<p>The App comprises a graphical user interface (GUI) composed of three windows or panels that allow interaction with the files and functionalities of the application. These windows are divided into \u2018Login\u2019, \u2018Projects\u2019, and \u2018Visualization and Analysis\u2019. The \u2018Projects\u2019 window will allow the user create a new project and load the volume to be analyzed, access a previous project and delete a project.</p> <p></p> <p>The \u2018Visualization and Analysis\u2019 window consists of visualization tools that comprises:</p> <ul> <li>XY, YZ and XZ slices -- to search specific dimensions for interfaces and objects in the volume.</li> <li>Image Selector -- to choose the plane (XY, YZ, XZ) as the main view to be inspected.</li> <li>Slider bars -- To scroll the slices and visualize them along the volume.</li> <li>Brightness, Contrast, Speckle reduction and Transparency \u2013- to manipulate voxels values and suppress speckle noise for increasing local structure contrast in volume.</li> </ul> <p>The \u2018Visualization and Analysis\u2019 panel also allows to assess the defect detection of the OCT samples. Below the display tools there is a \u201cPredict\u201d button to start the object detection model which, after a few seconds, displays the bounding boxes of each frame in which it is able to find defects. The view for defect detection must be set in the XY plane.</p>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#hardware-components","title":"Hardware Components","text":"<p>Edge processing unit based on GPUs: AI inference optimized on available GPU hardware with 100% high-rate inspection. </p>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#computation-requirements","title":"Computation Requirements","text":"<ul> <li>Classification of images to detect defects can rely on cloud services</li> <li>Possibility to store acquired data locally or in shared/cloud space</li> <li>Having in mind the computational needs of the trainig and inference phase of the AI services we recommended GPU with RAM  24 GB</li> </ul>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#installation-procedure","title":"Installation Procedure","text":"<p>(To be developed) Step by step on how to install the application:</p> <ul> <li>Standalone</li> <li>In the Kubernetes platformm using helm charts: description of the different options</li> </ul>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#how-to-use","title":"How To Use","text":"<p>The instructions to follow for the use of the app will be defined once the application has been developed. The following can be established as a provisional guideline:</p> <ol> <li>Open the web app.</li> <li>Enter the registered user and password.</li> <li>The 'Projects' window will open where you can add a new project, access a previously created project or delete a project.</li> <li>Create a new project by pressing the '+' button and name it.</li> <li>Click on the 'Select Images' button to load the set of images to be analyzed.</li> <li>In the 'Visualization and Analysis' window, scroll through the slices and edit the settings (brightness, contrast, transparency, mottling reduction) of the volume/slices.</li> <li>Use the 'Predict' button to evaluate the OCT defect detection.</li> </ol>"},{"location":"WP05/MIR-OCT-Volumetric-Inspection/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials will be added once the application has been completed.</p>"},{"location":"WP05/Plastic-Molding-Inspection/","title":"Plastic Molding Inspection","text":""},{"location":"WP05/Plastic-Molding-Inspection/#general-description","title":"General Description","text":"<p>The app will automatically monitor the quality of the production using 3D reconstruction of manufactured goods regarding geometric correctness. The object is digitally reconstructed by an array of 3D-cameras. The 3D reconstruction of the object will be aligned and compared with the object\u2019s CAD-model to determine its quality.</p> <p>Based on the automatically provided model data, the app detects the errors and can visualize the results of the comparison as a false-colour image and point to the locations of individual defects by annotating the recorded images. Detected defects are classified and stored in a history, in order to be able to monitor production quality over time.</p>"},{"location":"WP05/Plastic-Molding-Inspection/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>Multi Camera Setup: A generic multi camera setup should be build which involves calibrating the cameras to ensure accurate and synchronized data collection. This calibration process involves determining the intrinsic and extrinsic parameters of each camera (if not provided by the camera itself). Once calibrated, the cameras should simultaneously capture data from different perspectives.</li> <li>3D-Reconstruction from multiple images: The provided depth data from different calibrated cameras should merge into a single 3D reconstruction (for example pointcloud or mesh). The aligning process can be supported by using local alignment methods like ICP to perform even better, especially to provide a more robust setup for industrial environments.</li> <li>Defect Localization: We need to localize defects in a local area and position them onto the given 3D object in a deformable object context<ul> <li>Identify the local area where the defects are located. Use a localization technique algorithms (image processing or 3D feature based like normal-maps) to precisely determine the position of the defects within the local area.</li> <li>Map the position of the defects onto the 3D object by aligning the coordinate systems of the local area and the 3D object.</li> </ul> </li> <li>Defect Characterization: Defects can be classified into various categories based on their characteristics or attributes. The most important defects must be clarified and categorized.</li> <li>Defect Visualization: This visual representation aids in quickly identifying and addressing the most critical defects. The detected defects should be visualized in a way, a human can understand. To enhance comprehension, the detected defects can be visualized using techniques such as a false color gradient or highlighting the area of the defect in the image.</li> <li>Automatic Target-/Actual-Comparison: By utilizing the provided CAD data and the scanned object data (pointcloud or mesh), an automated comparison should be performed between the target design and the actual object. This enables the identification of any deviations or variances that may exist.</li> <li>Statistical Defect Detection: Analyze the distribution of the defects in a collected dataset (per session, per month, per year...) to identify any significant differences between the detected defects and visualize them.</li> <li>Automatic Segmentation of Defect Categories: Defects can be classified into various categories based on their characteristics or attributes. The goal is to develop an automated system that can identify and segment defects, and then assign them to the appropriate category based on their characteristics. This categorization process helps in organizing and addressing defects efficiently.</li> </ol>"},{"location":"WP05/Plastic-Molding-Inspection/#architecture-diagram","title":"Architecture Diagram","text":"<p>The system consists of six distinct components:</p> <ul> <li>Defect Detection Controller: is the central component of the application. It creates and manages instances of all other components and controls all data-flow. In particular it opens a HTTP-server to serve the Volumetric Inspection UI and a websocket-server for subsequent communication with the UI.</li> <li>Volumetric Inspection UI: is a web-GUI deployed by the Defect Detection Controller it allows a user to configure the defect detection, see current detection results or view historical detection data.</li> <li>Defect Detector: is the component responsible for defect detection and classification. It will be realized as a class in the main application.</li> <li>Model Manager: is the component responsible for loading and managing all model- (i.e. CAD-) data. It loads this data from the file-system. It will be realized as a class in the main application.</li> <li>Camera Controller: is the interface to the camera. This includes the camera driver and respective libraries.</li> <li>Inspection Hardware: comprises one or more depth-cameras. Currently supported cameras are Ensenso X36.</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#image-overview","title":"Image Overview","text":"<p>The Slideshow shows three scenes from the application:</p> <ul> <li>A mockup of the target web-UI.</li> <li>The setup at the development laboratory.</li> <li>The current prototype in action.</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#hardware-components","title":"Hardware Components","text":"<p>The minimum requirements are:</p> <ul> <li>An array of depth-cameras. The system has been tested with Ensenso X36 and Ensenso C-57M cameras. The specific requirements for the cameras depend on the use-case.</li> <li>A framework for mounting the cameras.</li> <li>A PC for running the application (see Computation Requirements).</li> <li>A monitor for displaying the results.</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#computation-requirements","title":"Computation Requirements","text":"<p>Plastic Molding Inspection requires at least the following hardware:</p> <ul> <li>CPU: 8 Core, 3000MHz</li> <li>RAM: 16 GB</li> <li>Space: 2 GB</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#installation-procedure","title":"Installation Procedure","text":"<p>The instructions for installing the app will be defined once the application has been completed.</p>"},{"location":"WP05/Plastic-Molding-Inspection/#camera-setup","title":"Camera Setup","text":"<p>The following refers to the pilot use-case in which termoformed inner bodies of fridges are inspected. However, the information herein can be extrapolated to other use-cases as well. Besides general advice given in Ensenso's documentation, camera placement is determined by the following requirements:</p> <ol> <li>The size of defects to detect. The camera has to be close enough to be able to capture the defects to look for according to its accuracy. In the pilot application defects can be as small as 0.5mm.</li> <li>The poistion of expected defects on the target object. In the pilot application defects can occur anywhere, so every point of the object is equally important.</li> </ol> <p>The camera used in the pilot application is an Ensenso C57-6-M, which has the following specifications:</p> <ul> <li>A field of view of about 45\u00b0.</li> <li>A baseline of 455mm.</li> <li>An accuracy of 0.26mm in z- and 0.37mm in xy-direction at 1m distance from the target object (see our evaluation for more details).</li> </ul> <p>This leads to these conclusions for placement:</p> <ol> <li>The camera should be placed as close as possible to the target application, to get the highest accuracy.</li> <li>The camera should be placed so that the whole fridge body is in its field of view, so we see as much as possible. To account for inaccuracies due to handling, </li> <li>The camera should be placed so that all three visible sides of the fridge body have the same angle to the image plane, in order to be able to inspect every side with the same accuracy.</li> </ol> <p>Figure 1 shows optimal placements of Ensenso C57-6-M-cameras under these conclusions for a 1000mm- and 1800mm-fridge body respectively. We recommend focussing on the simpler case of 1000mm-fridge-bodies first, optimizing the inspection process and algorithm and then, based on the knowledge gained, think about how to incorporate the inspection of larger fridge bodies.</p> Figure 1: Technical drawing of the optimal setups for fridge-bodies of 1000mm and 1800mm length respectively. Figure 2: Sample setup for small fridge bodies in IGDs laboratory."},{"location":"WP05/Plastic-Molding-Inspection/#limitations","title":"Limitations","text":"<ul> <li>The size of the individual objects can vary, therefore the largest volume to be captured is decisive for the distance calculation. For this, Arcelik must define the capture space (largest volume in all 3 directions).</li> <li>If the objects have indentations on the top or indentations and/or elevations on the side surfaces, they may not be captured correctly because using only one static camera can lead to occlusions.</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#mounting","title":"Mounting","text":"<p>We recommend placing the camera with an at least semi-mobile setup, in order to be able to easily change the camera placement, if the need occurs. This would for instance be modular systems based on aluminium profiles. A long-term mounting-solution probably requires the mounting-kit, altough one could probably also build a custom-solution. The cameras thread-specifcations and placements are documented here. We do not have experience with using the mounting kit, as we are using the solutions presented below.</p>"},{"location":"WP05/Plastic-Molding-Inspection/#igds-mobile-setup","title":"IGD's Mobile Setup","text":"<p>A simple and highly mobile solution for experementation is using a tripod and a manfrotto superclamp, as shown in figure 2. This can, however, only be a short-term-solution, as it is prone to being moved or even toppled due to accidents and it is susceptible to vibrations.</p> <p>The setup above consists of the following parts:</p> <ul> <li>A Manfrotto superclamp.</li> <li>A tripod. We have a Cullmann Primax 390 tripod, which has a maximum height of 1.69m, so it is not suitable for recording at the production line, as we require 2.4m. If you decide to build a similar setup, buy a tripod with a maximum height of at least 2.4m. To attach the superclamp without any adapter, you need a screw with an M6-thread (a.k.a. 1/4\") and to tilt down the camera watch out to buy a tripod with a tiltable head. This one looks like it could fulfull all requirements.</li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#igds-fixed-setup","title":"IGD's Fixed Setup","text":"<p>The older X36-cameras we have are also attached with Super Clamps, but these clamp to the framework, hold 3-way-joints (tripod-heads), which in turn have the camera attached (see figure 3). The 3-way-joints are very convenient, as they can easily be brought to the desired orientation.</p> <p>This setup requires the following parts:</p> <ul> <li>A Manfrotto superclamp.</li> <li>A Manfrotto 3D Junior tripod head</li> <li>As one side of the tripod head has a 3/8\"-thread, a stud like this to fix it to the superclamp.</li> <li>For the C57 the Ensenso mounting kit or another solution that allows attaching the camera with an M6-thread (a.k.a. 1/4\").</li> </ul> Figure 3: IGD's mounting solution for X36 cameras."},{"location":"WP05/Plastic-Molding-Inspection/#connection-and-software-setup","title":"Connection and Software Setup","text":"<ul> <li>Connect the camera to the same network the PC to be used with the camera is in. In the simplest case plug it into the LAN-port of your PC. At IGD we use a PC with two network-adapters (on-board and PCI), one to connect to our company-network and one to connect the camera.</li> <li>Download and install the Ensenso SDK. Note that you need to register, in order to be able to download it.</li> <li>Open nxView.</li> <li> <p>Select the camera with the correct serial. In case of the C57-M two cameras appear, one for the 3D-stereo-camera and one for the colour-camera. Both are automatically selected, which is correct. Click \"Open\". </p> <ul> <li>If any network settings are not correct (i.e. IP-settings of camera and or PC have not been set yet or are incorrect), nxView will offer you a wizard you can follow to fix this. </li> </ul> </li> <li> <p>You should be able to see the images and the 3D-reconstruction now and interact with it. Note that this shows a virtual camera recording a virtual scene, what you see will probably differ. </p> </li> </ul>"},{"location":"WP05/Plastic-Molding-Inspection/#intrinsic-calibration","title":"Intrinsic calibration","text":"<p>The cameras are calibrated by default. To check the quality of the calibration you can use the calibration pattern. Don't open the camera as seen in 1. but start \"Calibrate..\". Place the pattern in front of the camera and select \"control results\". You will check the current calibration </p> <p>If you need to recalibrate the camera, you can follow the calibration steps as provided. Be aware that the calculation of the calibration will be calculated in the background after collecting all data. Therefore do not close the application of select \"Control results\", this may lead to reloading of the old calibration and will overwrite your current work.</p>"},{"location":"WP05/Plastic-Molding-Inspection/#how-to-use","title":"How To Use","text":"<p>The instructions for using the app will be defined once the application has been completed.</p>"},{"location":"WP05/Plastic-Molding-Inspection/#additional-learning-materials","title":"Additional Learning Materials","text":"<ul> <li>Ensenso mechanical specifications for C-57M: https://www.ensenso.com/manual/3.6/hardware/mechanics/cx.html#c5x-m</li> <li>Ensenso camera setup considerations: https://www.ensenso.com/manual/3.6/about/camera-setup-considerations.html</li> <li>Ensenso instructions on camera calibration: https://www.ensenso.com/manual/3.6/guides/calibration/patterns.html</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/","title":"Heat Transfer Digital Twin","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#general-description","title":"General Description","text":"<p>Heat Transfer Digital Twin (HTDT) is a software package specifically designed for manufacturing operations that are based on heating and cooling processes. The system has simulation capabilities based on Finite Element Analysis on top of integrating real time Thermocouple (TC) as well as Infrared (IR) Camera readings. Specifically in ZDZW project, this package will be utilized to create a Digital Twin of Thermoforming process. </p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#top-ten-functionalities","title":"Top Ten Functionalities","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#1-heat-transfer-simulation","title":"1. Heat Transfer Simulation","text":"<p>This functionallity is the related to the base module where thermal calculations are performed with given material, geometric settings and boundary conditions. This function can handle all three mode of heat transfer, namely conduction, convection (forced or free) and radiative. In thermoforming setting, mainly conduction and radiative modes are dominant. Finite Element Method is used to discretize partial differential equations.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids","title":"Associated Function IDs:","text":"<ul> <li>HTINIT, HTSOLVE, HTDT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#2-steady-state-and-transient-formulation","title":"2. Steady State and Transient Formulation","text":"<p>This is where the temporal behaviour of the solver is set. Both steady and unsteady (i.e transient) simulations can be performed. For Steady State formulations, the material properties are not important, only the geometric setup and boundary conditions are needed. In transient formulation, time increment, material properties (density, conductivity, specific heat) and start-end time values are needed. Depending on the discretization approach, both explicit and implicit formulations can be applied.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_1","title":"Associated Function IDs:","text":"<ul> <li>HTTIME</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#3-parameteric-geometry-definition","title":"3. Parameteric Geometry Definition","text":"<p>HTDT has the ability to create fundamental shapes that are frequently used in engineering, including boxes, parallelpiped geometris, cylinder and their variations. In thermoforming, base shape is always a rectangular prism with a thickness around 2-8 mm and width and depth ranging from 1m to 3m's. To simplfy the setup of the digital model, data can be received from factory database and reflected onto the digital model.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_2","title":"Associated Function IDs:","text":"<ul> <li>HTINIT, HTCONNECT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#4-parameter-tuning-for-radiative-and-material-constants","title":"4. Parameter Tuning for radiative and material constants","text":"<p>Even if raw materials are pure and delivered with pre-measured material properties, depending on the nature of the operations, changes on the equipment (aging, different season,) more realistic estimations on parametric settings are needed. This functionality is useful to approximate required parameters for HTINIT. Further, view factor estimations are also needed to perform Radiative heat transfer calculations. This function also enables the tuning for vf's.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_3","title":"Associated Function IDs:","text":"<ul> <li>HTFIT, VFCALC</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#5-calibration-with-thermocouple-sensor-data","title":"5. Calibration with Thermocouple Sensor data","text":"<p>Numerical results achieved out of the finite model is generally for a perfect model. To capture realistic effects on the machine, a feedback system is required to collect sensor data and use it to improve the prediction. This functionality is focused in calibrating the numerical model, by measuring the temperature on a known location where the numerical value is compared to real measurement. Using this information, an information is passed to parameter settings so that it can be updated to minimize the error between the sensor data and numerical approximation.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_4","title":"Associated Function IDs:","text":"<ul> <li>HTFIT, HTCONNECT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#6-thermal-camera-input-for-enhanced-approximation","title":"6. Thermal Camera Input for enhanced approximation","text":"<p>Similar to TC calibration, this functionality is also focused on getting external data and using it to improve the prediction of the Digital Twin. Using IR data, instead of getting just one point data, a map of temperature readings will be received which can be used to offer a more optimized and even improvement of the thermal map.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_5","title":"Associated Function IDs:","text":"<ul> <li>HTFIT, HTCONNECT, SIE_FUNCTIONS</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#7-optimization-based-on-temperature-target","title":"7. Optimization based on temperature target","text":"<p>This function can create a pre-defined temperature maps on the plastic sheet. Optimization is applied on the machine parameters through heater array so that the changes can be used to modify the distribution on the thermal sheet.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_6","title":"Associated Function IDs:","text":"<ul> <li>HTOPT, HTCONNECT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#8-optimization-based-on-cycle-time-target","title":"8. Optimization based on cycle time target","text":"<p>This function is focused to keeping the temperature map on the plastic sheet fixed but creating a setup on the machine where the cycle time can be modified depending on the target of the factory operators/engineers while changing the temporal parameters. Using this functionality, throughput on the machine can be increased.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_7","title":"Associated Function IDs:","text":"<ul> <li>HTOPT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#9-heater-map-tuning","title":"9. Heater Map Tuning","text":"<p>To focus on energy related KPIs, heater map array can also be tuned automatically. This is also valid for new product introduction, where a new type mold will be used on the thermoforming machine. Using this function, heat map array can be created before initiating the operation and can be updated on the fly why the system starts running.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_8","title":"Associated Function IDs:","text":"<ul> <li>HTOPT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#10-failed-heater-compensation","title":"10. Failed Heater Compensation","text":"<p>In cases where one or more heaters on heater-array is defective - i.e. either does not function or underperforms, then the Digital Twin stars offering an automated heater compensation where the defective heater is removed from the setup by adjusting the PLC while fixing the neighbouring heaters around the problematic element so that the targer temperature map can still be achieved while avoiding down-time for maintanance.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#associated-function-ids_9","title":"Associated Function IDs:","text":"<ul> <li>HTOPT, HTCONNECT</li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#image-overview","title":"Image Overview","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#current-application-interface","title":"Current Application Interface","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#real-application-in-progress","title":"Real Application (In Progress)","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#dashboard","title":"Dashboard","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#auth","title":"Auth","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#configuration","title":"Configuration","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#main-heaters","title":"Main Heaters","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#adding-machine","title":"Adding Machine","text":""},{"location":"WP06/Heat-Transfer-Digital-Twin/#hardware-components","title":"Hardware Components","text":"<p>The Digital Twin only requires a cloud/on-prem server to run. Hardware requirement related to TC or IR data could be delivered from external libraries or services.</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#computation-requirements","title":"Computation Requirements","text":"<p>8-core Processor with 16 GB RAM and 1TB SSD with ethernet connection is required to run the system. The OS of the server should a linux, preferabble a Ubuntu Release 20+</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#installation-procedure","title":"Installation Procedure","text":"<p>Step by step on how to install the application: * Standalone dockerized system. * Manual Installation</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#manual-installation-requirements","title":"Manual Installation Requirements","text":"<p>Vue.js, Quasar, Python, NumPy, CalculiX, PostgreSQL, Flask</p>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#how-to-use","title":"How To Use","text":"<ul> <li>BI (Business Intelligence) Dashboard highlights critical KPIs of the thermoforming process.</li> <li>Configuration page set the dimension and the material of the working material, i.e. the sheet. Default material is HIPS.</li> <li>Cycle time, Heater Array scaling ratio can also be set on this menu.</li> <li>Switch between pre-heater and main-heater menus to monitor sensor data on top of prediction of the thermal profile of the sheet. </li> </ul>"},{"location":"WP06/Heat-Transfer-Digital-Twin/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>A Walkthrough YouTube video will be added</p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/","title":"Thermal Inspection for Component Surface Monitoring","text":""},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#general-description","title":"General Description","text":"<p>IR Thermal Imaging Inspection for Component Surface Monitoring (IRTI-CSM) is an application that can analyze the state of induction motors based on thermal information and images of the visible spectrum. To do this, an automatic inspection has been designed that emulates the procedure carried out by experts in thermographic analysis.  The application has the following modules:</p> <ul> <li>Qualitative inspection by displaying images of motors in the thermal spectrum and the visual spectrum. </li> <li>Induction motor segmentation module.</li> <li>Content-based image retrieval module to return images of the most similar healthy motors.</li> <li>Rules-based classification module based on temperature information only present in the pixels identified as motors in both the motor to be analyzed and in similar motors.</li> </ul> <p>In the developed zApp it is possible to analyze a batch of samples and at the end it is possible to generate a report with the classification made for each motor (healthy or defective), being able to visualize which rules have been fulfilled and which rules have not been fulfilled in the classifier.</p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>Surface quality inspection from Thermal images:    This functionality allows to load one or multiple thermal images for visualization and to perform a first preliminary evaluation.</p> </li> <li> <p>Preprocess acquired Thermal Images for noise reduction:    This functionality allows to reduce the noise in the thermal images for their subsequent analysis by means of artificial intelligence from a preprocessing of the images.</p> </li> <li> <p>Model Training with Thermal images databases    This functionality is based on the training of the automatic classification module. To do this, it is necessary to design and train three submodules: a segmentation model, a content-based image retrieval model and a rule-based classifier. This module is only fed images from healthy motors.</p> </li> <li> <p>Use the trained model to infer from images acquired on production line    This functionality consists of executing the inference of the classification module on new samples where there are healthy motors and faulty motors. With the classifications made by the model, its performance is evaluated in the detection and classification of faulty motors based on their temperatures.</p> </li> <li> <p>Provide high-speed and low latency quality feedback    This functionality is based on the analysis of inference times by the model. In case these inference times are too long, the model should be optimized to improve the prediction speed without compromising the prediction performance.</p> </li> <li> <p>Generate output data for anomaly detection purposes (classification, localization)    This functionality is used to analyze the outputs returned by the model. Thus, not only is the classification according to the rules returned, but also the healthy motors with which the new motor's samples have been compared. Likewise, the output of each rule is also returned, making it possible to evaluate and understand the cause of the model's performance. </p> </li> <li> <p>2D visualization of Thermal image defects    This functionality consists of displaying the defects detected by the model. To do this, a display is made of the engine temperatures once the mask has been applied, making it possible to locate where the areas with the highest temperature are.</p> </li> <li> <p>Obtain metrics to evaluate the inference accuracy of the model    This functionality is based on the evaluation of model performance. To this end, objective metrics must be established to ensure that the model performance is good enough in the test set to be extrapolated to new motor\u2019s samples.</p> </li> <li> <p>Reconsider if the model must be retrained to fine-tune    This functionality is based on the analysis of the predictions obtained. Thus, in case the model is not performing as expected, it is necessary to apply a retraining with new images to adjust it to the new samples to be predicted.</p> </li> <li> <p>Optimize the process for on-edge retraining    This functionality refers to the retraining optimization process. For this purpose, if retraining is necessary, an optimized methodology must be established to make such retraining efficient.</p> </li> </ol>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#architecture-diagram","title":"Architecture Diagram","text":"<p>The high-level diagram of the IR Thermal Imaging Inspector architecture is depicted below.</p> <p></p> <p>The solution consists of the following components:</p> <ul> <li> <p>Input Data: Data to be analyzed. It consists of the images obtained by the thermal imaging camera of the visible spectrum (.jpeg), the images of the thermal spectrum (.jpeg) and the temperature matrices (.csv).</p> </li> <li> <p>GUI: This is the graphic interface with which the user interacts. It is where all the requests to the thermal inspector module are made, which returns the responses to the requests received.</p> </li> <li> <p>IR Thermal Inspector: This is the main module of the application's backend. It manages requests to the other modules in order to be able to display user requests in the different tabs of the application.</p> </li> <li> <p>Processing modules: These are the modules where processes that do not involve artificial intelligence are carried out. These processes are the visualization of the images in the visible and thermal spectrum, the filtering of the temperatures according to the engine masks and the report that is generated with the classification information.</p> </li> <li> <p>AI modules: These are the modules that involve the use of artificial intelligence. In this section of modules are the segmentation module, the content-based image retrieval module and the rule-based classifier module.</p> </li> <li> <p>Storage: It is where the weights of the artificial intelligence models, the images, masks and embeddings used in content-based image retrieval and the classification and new predictions that are generated are stored.</p> </li> </ul>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#image-overview","title":"Image Overview","text":"<p>The typical workflow is shown in the image sequence of the image overview. First the images of the visible spectrum, the images of the thermal spectrum and the temperature matrices are loaded. Then you go to the tab where the pairs of images in both spectra are displayed. Next, you go to the content-based image retrieval display, where you can analyze the similarity metrics and the images of engines returned (the most similar and the most similar of the same month). Finally, in the last tab it is possible to see the segmentation of temperatures performed by the segmentation module and the classification performed by the classification module.</p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#hardware-components","title":"Hardware Components","text":"<p>Edge processing unit based on GPUs: AI inference optimized on available GPU hardware with 100% high-rate inspection. </p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#computation-requirements","title":"Computation Requirements","text":"<ul> <li>Classification of images to detect defects can rely on cloud services</li> <li>Possibility to store acquired data locally or in shared/cloud space</li> <li>Having in mind the computational needs of the trainig and inference phase of the AI services we recommended GPU with RAM 24 GB</li> </ul>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#installation-procedure","title":"Installation Procedure","text":"<p>The instructions for installing the app will be defined once the application has been completed.</p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#how-to-use","title":"How To Use","text":"<p>The instructions for using the app will be defined once the application has been completed.</p>"},{"location":"WP06/Thermal-Inspection-Component-Surface-Monitoring/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials will be added once the application has been completed.</p>"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/","title":"Thermal Inspection for Heat Sealing","text":""},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#general-description","title":"General Description","text":"<p>The application allows end-users to monitor the heat-sealing process with a real-time QA in the production line. 2D Thermal profile information of the produced parts will be generated and the thermal profile of the heat-sealing will be analyzed using specifically designed algorithms. An unusual process will be automatically detected in real-time and throw a trend with visual and audio alerts via end-user's definition. The real-time data can be viewed on the machine itself. The data is collected from the production line and a decision is automatically concludded about the quality of the process and product with relevance to the known nominal process. The information can be visualized and analyzed further using in-built SPC tools. </p>"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>Advanced thermal cameras tuned for the application </p> </li> <li> <p>Image processing algorithms to monitor the sealing integrity of capsules </p> </li> <li> <p>Image processing algorithms to monitor the sealing integrity of pouches </p> </li> <li> <p>PLC based system which will connect to the PLC of the customer's machinery </p> </li> <li> <p>Analytical tools for data analysis </p> </li> <li> <p>AI for big data analysis </p> </li> <li> <p>Operating software and GUI </p> </li> <li> <p>Calibration tools for new products </p> </li> <li> <p>Connection to MES  </p> </li> <li> <p>Connectivity to IOT networks </p> </li> </ol>"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#image-overview","title":"Image Overview","text":"<p>Main screen mockup</p> <p></p> <p>Dashboards mockup</p> <p></p>"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#hardware-components","title":"Hardware Components","text":"Hardware Component Count Description Thermal camera 1-2 Thermal image aquisition Edge Device 1 PC or tablet, shows the running application and results IO module 1 Gets and sets dry contacts/sensors inputs Inference Server 1 PC for calculations, image processing and inferences"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#computation-requirements","title":"Computation Requirements","text":"Required OS Windows 10/Windows server 2019 or higher CPU Intel Core i5-10th Gen or higher RAM 32 GB DDR4 3000MHz Memory or higher STORAGE 1TB PCIe M.2 NVMe SSD for OS"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#installation-procedure","title":"Installation Procedure","text":"<p>The hardware components are stored in a cabin. The system is plug and play. From the machine PLC or the sensor, connect a dry contact to the cabin.</p>"},{"location":"WP06/Thermal-Inspection-Heat-Sealing/#how-to-use","title":"How To Use","text":"<p>As described in Yoran user guide.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/","title":"Thermal Inspection for Thermoforming","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#general-description","title":"General Description","text":"<p>Thermal Inspection for Thermoforming is an edge-based application to allow end-users to monitor and process the thermal images of the heated and formed plastic sheets in the thermoforming process. 2D and 3D Thermal profile information of the produced parts will be generated. By analyzing the thermal profile information of the plastic parts by using AI/ML techniques, the anomaly such as thinning, tearing on the produced parts will be detected when it occurs. </p> <p>The architecture of Thermal Inspection for Thermoforming application is designed by adopting the microservice based approach which allows to create the independently deployable services working in communication with each other. Overall architecture consists of the multiple services such as 2D Processing service, 3D Processing and Reconstruction service, AI/ML service, Communication service, Management service, Calibration service and Data Handling service. This application is also an interoperable application that is capable of communicating with Digital Twin application. The thermal data of the plastic parts which is generated by 2D and 3D processing services of the application will be sent to Digital Twin application to provide the information regarding to the thermal profile distribution of the relevant plastic sheet. Moreover, this application will enable to monitor the camera parameters such as extrinsic and intrinsic parameters, status information, and images from both the stereo and thermal cameras that will contribute to the composition of the image data. Finally, this application will allow the end-users to monitor and identify 2D/3D thermal profile of the produced plastic parts and to detect the defects such as tearing, thinning during in-line inspection of the plastic sheets in thermoforming manufacturing line. </p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#top-ten-functionalities","title":"Top Ten Functionalities","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#1-computer-vision-pipeline-for-thermal-image-streaming","title":"1. Computer vision pipeline for thermal image streaming","text":"<p>This part will provide to establish a pipeline for the connection with thermal cameras and thermal data flow for image processing operations.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids","title":"Associated Function IDs:","text":"<ul> <li>CONSUME_THERMAL_DATA</li> <li>CONSUME_STEREO_DATA</li> <li>START_2D_PROCESSING</li> <li>START_3D_PROCESSING</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#2-data-handling-service-for-data-analysis","title":"2. Data handling service for data analysis","text":"<p>This service will enable to process the real-time thermal images and raw data gathered from the thermal cameras.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_1","title":"Associated Function IDs:","text":"<ul> <li>INITIATE_THERMAL_CAMERA</li> <li>INITIATE_STEREO_CAMERA</li> <li>SHUTTER_CONTROLLING_THERMAL_CAMERA</li> <li>STOP_THERMAL_CAMERA</li> <li>STOP_STEREO_CAMERA</li> <li>START_IMAGE_STREAMING</li> <li>STOP_IMAGE_STREAMING</li> <li>GET_DEPTH_STEREO_CAMERA</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#3-2d-thermal-profile-identification-from-thermal-images","title":"3. 2D Thermal profile identification from thermal images","text":"<p>This service will enable to process the streaming thermal data (thermal image and raw data) to identify two-dimensional thermal profile distribution of the plastic sheets.  </p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_2","title":"Associated Function IDs:","text":"<ul> <li>START_IMAGE_STITCHING</li> <li>STOP_IMAGE_STITCHING</li> <li>EXTRACT_2D_ROI_THERMAL</li> <li>STORE_2D_OUTPUT_DATA</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#4-3d-processing-and-surface-reconstruction-from-point-cloud","title":"4. 3D Processing and Surface reconstruction from point cloud","text":"<p>3D processing and surface reconstruction service will integrate the data obtained from both the depth camera and thermal camera to construct the three-dimensional object view that incorporates the thermal information. 3D processing and surface reconstruction service will facilitate the generation of three-dimensional objects using point clouds acquired from a depth camera.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_3","title":"Associated Function IDs:","text":"<ul> <li>START_3D_RECONSTRUCTION</li> <li>FUSION_3D_AND_THERMAL_DATA</li> <li>STORE_3D_OUTPUT_DATA</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#5-ai-model-training-using-thermal-image-datasets","title":"5. AI model training using thermal image datasets","text":"<p>This part will provide ai and machine learning models training and dataset generation for thermal image processing.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_4","title":"Associated Function IDs:","text":"<ul> <li>TRAIN_2D_ANOMALY_DETECTION_MODEL</li> <li>TRAIN_3D_ANOMALY_DETECTION_MODEL</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#6-edge-based-thermal-inspection-on-the-heated-and-formed-plastic-sheets","title":"6. Edge based thermal inspection on the heated and formed plastic sheets","text":"<p>The application of IRTI Thermoforming will perform as an edge-based system to facilitate in-plant integration. </p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_5","title":"Associated Function IDs:","text":"<ul> <li>INITIATE_TRITON_INFERENCE_SERVER</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#7-aiml-service-development-for-anomaly-detection","title":"7. AI/ML service development for anomaly detection","text":"<p>AI/ML service will provide ai and machine learning operations regarding to defect detection of the heated and formed plastic parts.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_6","title":"Associated Function IDs:","text":"<ul> <li>START_2D_ANOMALY_PROCESS</li> <li>START_3D_ANOMALY_PROCESS</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#8-ui-design-for-simulation-and-monitoring","title":"8. UI design for simulation and monitoring","text":"<p>This part will handle the development of web-based UI interface for the application.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_7","title":"Associated Function IDs:","text":"<ul> <li>SHOW_THERMAL_IMAGES</li> <li>ACTIVATE_2D_PROCESSING</li> <li>ACTIVATE_3D_PROCESSING</li> <li>DEACTIVATE_2D_PROCESSING</li> <li>DEACTIVATE_3D_PROCESSING</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#9-calibration-service-for-thermal-and-stereo-cameras","title":"9. Calibration service for thermal and stereo cameras","text":"<p>This service will perform the calibration process to establish the relative position alignment between thermal and depth cameras.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_8","title":"Associated Function IDs:","text":"<ul> <li>DOWNLOAD_AUTO_CALIBRATION_FOR_THERMAL_CAMERA</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#10-development-of-closed-loop-communication-service-with-digital-twin-application","title":"10. Development of closed-loop communication service with digital twin application","text":"<p>This service will enable to establish the bi-directional communication with Digital Twin application for the notification the thermal profile distribution and detected defects on the plastic sheets to Digital Twin App.</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#associated-function-ids_9","title":"Associated Function IDs:","text":"<ul> <li>FETCHING_THERMAL_PROCESS_ID_FROM_DT</li> <li>SENDING_THERMAL_PROCESS_STATUS_TO_DT</li> <li>HEARTBEAT_SEND_TO_DT</li> <li>HEARTBEAT_RECEIVE_FROM_DT</li> <li>RAISE_ALARM</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#the-application-consists-of-several-services-and-components","title":"The application consists of several services and components:","text":"<ul> <li>Thermal Inspection GUI: Graphical user interface for the application (front end).</li> <li>Thermal Camera Service: This service handles to receive the thermal raw data from thermal cameras and to transmit the thermal data to the corresponding services.</li> <li>Stereo Camera Service: This service is responsible for receiving data from the stereo camera and transmitting the received data between services.</li> <li>Management Service: This service aims to achieve efficient coordination of the application and management tasks within authentication, authorization, communication, and calibration to provide smooth operations of the application.</li> <li>2D Processing Service: This service enables to process the thermal images obtained from thermal cameras to generate 2D thermal profile identification. It performs advanced image processing techniques such as filtering and image fusion to gather valuable qualities and improve thermal imaging results.</li> <li>3D Processing Service: This service integrates data from both the depth camera and the thermal camera to construct a 3D object that incorporates thermal information. </li> <li>3D Reconstruction Service: This service facilitates the generation of three-dimensional objects using point clouds acquired from a depth camera.</li> <li>System Calibration Service: This service performs the calibration process to establish the relative position alignment between thermal and depth cameras.</li> <li>AI/ML Service: This service provides ai and machine learning operations.</li> <li>Communication Service: This service enables the communication with DT App.</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#image-overview","title":"Image Overview","text":"<p>Add here real screen shots from the apps or mockups from the Software Specification document</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#app-activation-page","title":"App Activation Page","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#configuration-page","title":"Configuration Page","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#thermal-camera-status","title":"Thermal Camera Status","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#depth-camera-configuration","title":"Depth Camera Configuration","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#thermal-profile-analysis-and-visualization-page","title":"Thermal Profile Analysis and Visualization Page","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#real-time-production-info","title":"Real-Time Production Info","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#service-status-info","title":"Service Status Info","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#hardware-components","title":"Hardware Components","text":"Hardware Component Count Thermal Camera 3 Stereo Camera 1 Edge Device 2 Training/Inference Server 1 <ul> <li>Thermal Camera : Thermal cameras are used to capture thermal data from the thermoforming line during 2D/3D thermal inspection.</li> <li>Stereo Camera : Stereo cameras are used to capture point cloud data from 3D Reconstruction Phase.</li> <li>Edge Device : Edge device is used to execute specific microservices which are running custom algorithms.</li> <li>Training/Inference Server : The training/inference server is used to serve the APIs that perform the training / inference on the AI models.</li> </ul>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#computation-requirements","title":"Computation Requirements","text":""},{"location":"WP06/Thermal-Inspection-Thermoforming/#computational-requirements-for-edge-device-edge-box","title":"Computational Requirements for Edge Device / Edge Box:","text":"Recommended OS Ubuntu Linux 22.04 LTS, x86_64 architecture CPU Intel Core i5-10th Gen or higher RAM 64 GB DDR4 3000MHz Memory or higher STORAGE 1TB PCIe M.2 NVMe SSD for OS GPU NVIDIA GeForce RTX 3090 384-bit 24GB GDDR6X (Ampere) PERIPHERALS USB 2.0 Bus x2, USB 3.2 x1"},{"location":"WP06/Thermal-Inspection-Thermoforming/#computational-requirements-for-training-and-inference-server","title":"Computational Requirements for Training and Inference Server:","text":"Recommended OS Ubuntu Linux 22.04 LTS, x86_64 architecture CPU Intel Core i7-10th Gen or higher RAM 128 GB DDR4 3000MHz Memory or higher STORAGE 1TB PCIe M.2 NVMe SSD for OS GPU 4 x NVIDIA RTX A5000 24GB GDDR6 with ECC memory (Ampere) PERIPHERALS USB 2.0 Bus x2, USB 3.2 x1"},{"location":"WP06/Thermal-Inspection-Thermoforming/#installation-procedure","title":"Installation Procedure","text":"<p>Step by step on how to install the application: * Standalone * In the Kubernetes platformm using helm charts: description of the different options</p>"},{"location":"WP06/Thermal-Inspection-Thermoforming/#how-to-use","title":"How To Use","text":"<p>Step by step on how to use the application</p>"},{"location":"WP06/Welding-Process-Inspector/","title":"Welding Process Inspector","text":""},{"location":"WP06/Welding-Process-Inspector/#general-description","title":"General Description","text":"<p>This solution aims to predict and detect defects during the welding process by continuously monitoring key process parameters in real time. Its main goal is to reduce production time and minimize material waste caused by defective welds.</p> <p>The system is deployed in two stages. In the first stage, depending on the welding process and the equipment used, a set of sensors is selected and integrated directly on the torch to enable comprehensive process monitoring. These sensors capture parameters such as welding speed, wire feed rate, electrical signals, and thermal data from both the weld bead and the base material. All this data is synchronized to generate high-quality datasets that can be analyzed and linked to common welding defects.</p> <p>In the second stage, the collected data is combined with Non-Destructive Testing (NDT) results to train models capable of detecting and alerting in real time when there is a high probability of a defect occurring. These models are deployed using an edge computing approach, meaning they run locally, close to the monitoring system for fast response.</p> <p>The solution includes specific hardware where both the data acquisition software and the defect detection models are embedded. Users interact with the system through two interfaces: one for configuring and managing the hardware, and another for offline access to detailed visualizations of the recorded data.</p>"},{"location":"WP06/Welding-Process-Inspector/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li> <p>Welding process monitoring system: Main feature of the Welding Process Inspector. It provides the technical means (HW &amp; SW) to monitorize all relevant parameters of a welding processassutring a good synchroniztion.</p> </li> <li> <p>Flexibility: The monitoring system covers a great variety of sensors and communication protocols (e.g., TCP/IP or Profibus).</p> </li> <li> <p>Adaptability: The monitoring system is adaptable to any metallic welding process. The sensors and protocols used to monitoring the welding process can be selected for each specific case (i.e. different welding proccesses, different welding stations...)</p> </li> <li> <p>Scalability: The system eases to add new sensors. The monitoring HW and SW can be updated and configured to handle a great number of sensors.</p> </li> <li> <p>Contribution to the digitalization of the industry: Process variables are digitally acquired and stored. The monitored data can be seen as a kind of digital twin of the welding process, enabling a digital traceability of each welded bead.</p> </li> <li> <p>Early detection of defects: The monitoring system collects welding data, which can be used to develop a data-driven model of the welding process. This model is designed to detect when the process deviates from the optimal parameter window and to provide a real-time probability of defect occurrence.</p> </li> <li> <p>Enables implementation of AI-based quality assurance algorithms: Both the HW and the SW are designed to implement quality control algorithms, feeding them with real-time processs data.</p> </li> <li> <p>Possibility to set alarms when out of quality limits: The Welding Process Inpector provides the data processing and the interface required to implement alarms when abnormal process behaviours are being produced.</p> </li> <li> <p>Enables process control: The Welding Process Inpector furnishes further data to understand reality of the welding process and provides the interfaces with the process to test/implement closed-loop control strategies.</p> </li> <li> <p>Thermal info from welding bead and base plates: The system can record images from IR cameras using GeniCam standard. Also, punctual pyrometers contribute to gather thermal information.</p> </li> </ol>"},{"location":"WP06/Welding-Process-Inspector/#architecture-diagram","title":"Architecture Diagram","text":"<ul> <li>Internal modules:<ul> <li>Main: Synchronizes data acquisition from the different internal modules (sensors, data storage and defect detection algorithms).</li> <li>GigE IR cam: This module enables connection to cameras following GigE/genie cam protocols/standards.</li> <li>DAQ board: Data Acquisition Board. Acquire digital and analogue signals, e.g., pyrometers.</li> <li>Oscilloscope: Acquires analogue signals at a high sampling frequency, i.e., voltage and current of each welding torches.</li> <li>Defect Detection Algorithm: Analises data stream from sensors and warns when anomalies are identified.</li> <li>Storage: Data is saved locally in a custom data format.</li> </ul> </li> <li>GUI: Graphical User Interface. Allows the user to configure the monitoring system and to check the correct operation of the system during welding.</li> <li>Traceability Gateway: The system uses the ZDZW Traceability Gateway to comunicate with the ZDZW platform (WP07)</li> </ul>"},{"location":"WP06/Welding-Process-Inspector/#image-overview","title":"Image Overview","text":"<p>The present section addresses the user interfaces envisioned to interact with the Welding Process Monitoring solution. Two GUIs are defined, one for configuring all devices involved in the data acquisition which also provides some features for online visualization and another one for offline analysis of the recorded data.</p> <p></p> <p>Above figure shows the GUI in charge of the HW configuration of ZDZW Welding Process Inspector and a subsampled online visualization of the welding process (a.k.a. capturer app). On the left side you can see the 3 different formats for the visualization of the data that is being recorded, while the right side is reserved for the configuration of the system and to start/stop the recording. The online visualization includes an image viewer for the IR camera and graph and scalar viewers which allow the user to plot desired parameters. The \u201cconfiguring input/output interfaces\u201d contains the settings of the sensors that are being used for monitoring the welding process. The \u201cRecorded params\u201d section links the process parameters with the sensor that is being used to get their values. The \u201cmetadata\u201d section contains relevant logistic information. The GUI allows the user to enable/disable a defect detection model and to load different models. Finally, the GUI offers a couple of buttons to start and stop the recording manually.</p> <p></p> <p>Above figure shows the mockup of the GUI for the offline visualization (a.k.a. visualizer app). While the capturer app offers a restricted, but online, visualization of the monitored data from the welding process, the visualizer app allows skilled personnel to analise the recorded data and visualize it in different formats. The capturer app allows the operator to detect disturbances on the welding process or possible mistakes in the configuration of the monitored system, while the visualizer app allows a deeper analysis of the recorded data. In addition to the image and graph viewers already available in the capturer app, the visualizer app also provides a 3D representation of the process parameters.</p>"},{"location":"WP06/Welding-Process-Inspector/#hardware-components","title":"Hardware Components","text":"<p>The Welding Process Inspector relies on a combination of some specific HW and custom SW. The HW is divided into a CPU, some middle HW for signal processing and the sensors.</p> <p></p> <p>A small factor CPU is chosen for the sake of space economy, but guaranteeing minimum requirements to handle the data acquisition SW and capability to deploy data models based on Deep Learning techniques.</p> <p>To capture the detailed waveform of welding currents and voltages we opted for a PicoScope USB oscilloscope. When selecting this device, it is vital to ensure the proper number of channels to cover all welding current and voltage signals and a propper bandwidth to guarantee a right sample rate. These parameters may vary depending on the specific welding technique being monitored.</p> <p>The welding voltage must be pre-processed at the input of the oscilloscope to adapt the voltage amplitude and to isolate the signal to avoid any electromagnetic interference. To that purpose, a differential voltage probe must be selected for each welding voltage signal. The input range must cover the welding voltage range and the differential output range must fit in the oscilloscope input range.</p> <p>A DAQ (digital acquisition board) processes analog and digital signals to be read by a CPU. In our app we use a labjack T7 which handle fairly high resolution analog I/O and digital I/O. This particular device has some useful funtionalities as frequency inputs, high speed counters or support to protocols like SPI or I2C among others. The great variety of options of this DAQ contributes to several functionalities of the solution, like the flexibility, adaptability, scalability or the ability to set alarms to stop the welding process when it's out of quality limits, for example.</p> <p></p> <p>CPU and intermediate signal processing HW is enclosed in a cabinet alongside other components as power sources or wifi/4G router. The cabinet can be easily installed next to or onto the welding station. Different connectors provide HW interfaces to connect the sensors allocated in the different areas of the welding station by convenient wire hoses.</p> <p></p> <p>The sensors must be placed on the welding torch, welding power wire hose and positioning system to acquire the relevant information. Above picture show some typical sensors placed in a Sumerged Arc Welding torch: encoders for wire feed rate (green), pyrometers (red), laser-line profilometer (yellow) and GigE camera (blue).</p>"},{"location":"WP06/Welding-Process-Inspector/#computation-requirements","title":"Computation Requirements","text":"<p>Below we detail the computation requirements for the user interfaces depicted in Image Overview section.</p> minimum recommended cpu 2.60GHz \u00d7 6 (i5 11G) 2.30GHz \u00d7 16 (i7 11G) ram 16 Gb 32 Gb storage 512 Gb &gt; 1 Tb"},{"location":"WP06/Welding-Process-Inspector/#installation-procedure","title":"Installation Procedure","text":"<p>One important point of the present solution is that is highly adpatable to the welding process and welding equipment of the client. Backend SW would be provided to the client pre-installed in the HW selected for the specific use case. The SW interfaces (capturer app and visualizer app) to interact with the system are provided as standalone program files.</p>"},{"location":"WP06/Welding-Process-Inspector/#how-to-use","title":"How To Use","text":"<p>The welding operator should have access to a tablet or touch screen with capturer app. From this GUI, they can connect with the Welding Process Inspector and check the configuration of all sensors. Defect detection models are preloaded by manufacturer. From the GUI, operator can start and stop the welding monitoring and configure wich welding parameters and alerts visualize. When high probability of defects appearance is detected, alarmas are displayed to operator.</p> <p></p> <p>Offline visualizer app would be only used by specialized personnel to deep analysis of recorded data, in case needed. </p>"},{"location":"WP06/Welding-Process-Inspector/#links","title":"Links","text":"<ul> <li>Introduction 1</li> <li>Introduction 2</li> <li>Demo</li> <li>webinar: AI-Supported Monitoring System for Defect Detection in Submerged Arc Welding</li> </ul>"},{"location":"WP07/Interlinking/","title":"Interlinking","text":""},{"location":"WP07/Interlinking/#general-description","title":"General Description","text":"<p>The Interlinking subcomponent provides an alternative way to integrate ZDZW Assets and other components into the ZDZW Platform that could not be directly connected via a REST API and/or the message bus, eg because of proprietary protocols or missing service interfaces. This is achieved by implementing custom connectors that connect these sources to the Services API Management and/or the Message Bus via the Interlinking subcomponent.</p>"},{"location":"WP07/Interlinking/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>    HTTP(S) Proxying (APIGW)    </li> <li>    Web UI for the administration and configuration of platform interlinks </li> <li>    Interconnection and interoperability of multiple ZDZW instances running on different machines </li> <li>    Interlinking with other external (commercial) platforms </li> <li>    Interlinking to Marketplaces </li> </ol>"},{"location":"WP07/Interlinking/#architecture-diagram","title":"Architecture Diagram","text":"<p>The architecture diagram here displayed is the same as the Interoperability solution, since it is tightly coupled with it.</p> <p></p>"},{"location":"WP07/Interlinking/#image-overview","title":"Image Overview","text":"<p>The Inter-platform Interoperability component\u2019s aim is to link the ZDZW platform with other external platforms. This will, for example, include a layer to link data sources from different platforms and integrates security between the platforms to ensure appropriate access procedures across the platforms including connections to other instances of ZDZW. </p> <p> </p>"},{"location":"WP07/Interlinking/#hardware-components","title":"Hardware Components","text":"<p>None</p>"},{"location":"WP07/Interlinking/#computation-requirements","title":"Computation Requirements","text":"Requirement minimal recommended CPU 0.5 vCPU 1 vCPU RAM 256 MiB 512 MiB Storage 32 MiB 128 MiB"},{"location":"WP07/Interlinking/#installation-procedure","title":"Installation Procedure","text":"<p>This component will be provided for installation as Kubernetes Helm Chart. Option descriptions and further instructions will be provided here once the chart is finished.</p>"},{"location":"WP07/Interlinking/#how-to-use","title":"How To Use","text":"<p>The component provides a Web UI for configuration. The steps and functionalities vary by platform, but can be generalized as the following:</p> <ol> <li>Click the \"Create Interlink\" Button in the menu bar.</li> <li>Select the platform type.</li> <li>Enter a name for the interlink. This cannot be changed later.</li> <li>Confirm and switch to the newly created interlink by clicking on its name in the sidebar on the left.</li> <li>Enter the required information to configure the interlink and click save.</li> <li>Navigate to the interlinking functions using the tab menu.</li> </ol>"},{"location":"WP07/Interlinking/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>None</p>"},{"location":"WP07/Interoperability/","title":"Interoperability","text":""},{"location":"WP07/Interoperability/#general-description","title":"General Description","text":"<p>The Interoperability solution is composed of various components to enable standard and secure communication and data transfer among ZDMP Solutions and with external systems. The components of the interoperability solution are the API Gateway, the Message Bus and the Complex Event Processing (CEP). The APIGW enables ZDZW Assets to use other ZDZW Assets in a standardized and secure way. This is achieved through manageable REST APIs provided by a Services API Management (APIGW) which exposes specific services offered by the connected ZDZW Assets. These APIs can be fully customized, eg to only expose certain functions or to restrict the API access to specific entities. This component also will be available as developer version for local purposes. The component interacts with the Message Bus, which is also part of the Interoperability Platform. The component provides ZDZW Assets with a message bus \u2013 a standardized communication interface to exchange messages, events, and data. This message bus implements a publish/subscribe messaging concept, which allows the connected ZDZW Assets to broadcast (publish) information on specific topics and to listen for certain events on these topics(subscribe) and to support real time analytics. The component interacts with the Message Bus component. It implements a concept, which allows the information send by any ZDZW assets to the message bus being analysed in real-time and thus creating higher level events out of low level information.</p>"},{"location":"WP07/Interoperability/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>    HTTP(S) Proxying (APIGW)    </li> <li>    Secure APIs with OpenID Connect (APIGW) </li> <li>    Request/Response transformation (APIGW) </li> <li>    Emulation of endpoints (APIGW)  </li> <li>    Register/deregister APIs (APIGW)    </li> <li>    API Management (MessageBus) </li> <li>    Message Bus (MessageBus)    </li> <li>    Streaming Analytics (MessageBus)    </li> <li>    Interlinking (MessageBus)   </li> <li>    Event Monitoring (CEP)  </li> <li>    Connectivity to several Message Bus topics (CEP)    </li> <li>    Graphical development tolos (CEP)   </li> <li>    Sophisticated analytics (CEP)   </li> </ol>"},{"location":"WP07/Interoperability/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"WP07/Interoperability/#image-overview","title":"Image Overview","text":"<p>These solution does not provide a User Interface, so no mock-ups are displayed. The ApiGW is a backend component, that allows ZDZW Platform and zApp developers to define and configure REST APIs to expose services provided by their ZDMP Assets. It is a component running centrally on the reference platform or locally for developer purposes.  The component is a developer tool running in the background that works locally without a specific user interface, based on Java Spring Web Flow. Instead, it can be used by directly executing API calls by using Postman or a similar tool make POST requests. This interface provides the API to interact with the Message Bus. It allows the connected components to broadcast information such as events or data by publishing messages on certain topics. Similarly, it enables the connected components to receive messages by subscribing to specific topics. The Message Bus of ZDZW will be based on RabbitMQ. Due to this reason, there will not be a huge demand for a specific ZDZW user interface as of now. This component listens for specific low-level events on the Message Bus such as sensor data to analyse and process them in real-time. The analysis results in the form of high-level events are subsequently published via the Message Bus.  It is also a backend component without specific user interface. Rules for real time can be programmed in a development environment and then deployed and used server side.</p>"},{"location":"WP07/Interoperability/#hardware-components","title":"Hardware Components","text":"<p>None</p>"},{"location":"WP07/Interoperability/#computation-requirements","title":"Computation Requirements","text":"Component min CPU rec CPU min RAM rec RAM min Storage rec Storage Message Bus 0.25 vCPU 1 vCPU 1 GiB 4 GiB 1 GiB 5 GiB API Gateway 0.25 vCPU 1 vCPU 256 MiB 512 MiB 32 MiB 128 MiB Complex Event Processing 2 vCPU 2 vCPU 4 GiB 4 GiB 2.5 GiB 3.5 GiB Total 2.5 vCPU 4 vCPU 5.25 GiB 8.5 GiB 3.5 GiB 8.6 GiB"},{"location":"WP07/Interoperability/#installation-procedure","title":"Installation Procedure","text":"<p>All components will be provided for installation as a Kubnetes Helm Chart. Option descriptions and further instructions are contained in the chart questions. These questions are only displayed if Rancher UI is used for deployment. If a CLI-based deployment is required, refer to the necessary variables and their descriptions in the questions.yml file of the chart.</p>"},{"location":"WP07/Interoperability/#how-to-use","title":"How To Use","text":""},{"location":"WP07/Interoperability/#message-bus","title":"Message Bus","text":"<p>The Message Bus component is based on the RabbitMQ open-source message broker. For instructions on how to use this software, please refer to the official documentation at https://www.rabbitmq.com/documentation.html.</p>"},{"location":"WP07/Interoperability/#api-gateway","title":"API Gateway","text":"<p>The API Gateway component is an HTTP(S) proxy server with a graphical user-interface. It can also be configured using a RESTful HTTP API. The documentation of this API can be accessed via the running component at \\&lt;Gateway URL&gt;/swagger-ui.html . The main functions include: * Access management: OpenID Connect compatible authorization/authentication servers can be configured to restrict access to the gateway to valid tokens from these servers. By default, the gateway can be accessed using HTTP Basic authentication using the credentials admin:admin . * Route management: A route is a gateway endpoint that proxies requests to an external HTTP(S) API. Routes can only be accessed by using valid tokens configured in the access management interface. Also, filters can be added to routes, which allow for additional functionalities like authorization at the external API or setting headers in outgoing requests. Routes can also proxy traffic to other Kubernetes services that do not expose a public endpoint. * Global Filters: Global Filters can be applied to multiple routes at the same time and updated once for all affected routes, for example to configure external authorization for multiple routes that use the same credentials.</p>"},{"location":"WP07/Interoperability/#adding-an-api-to-the-gateway","title":"Adding an API to the gateway","text":"<ol> <li>Open the API Gateway Webinterface. The ZDZW Cloud instance is accessible at https://apigw-zdzw.cloud.zdzw-project.com/ui/</li> <li>Change to the Routes tab and click on the \"+\"-Button in the lower-right corner.</li> <li>Specify a name and version for your API.</li> <li>Choose between entering the HTTP(S) endpoint of your API and pasting or uploading the OpenAPI specification of your API.</li> <li>Click Create to finish the basic setup. You will be redirected to the details page of the newly created route.</li> <li>Click Activate in the upper-right corner to allow gateway users to access the API. A new field containing the gateway endpoint of your API will appear.</li> <li>Optionally, add one or more (global) filters to your API e.g. to supply access credentials if your API requires them.</li> </ol>"},{"location":"WP07/Interoperability/#creating-and-applying-global-filters","title":"Creating and applying (global) filters","text":"<ol> <li>Choose between adding filters to a single API or creating a global filter that can be applied to multiple APIs:<ol> <li>For single API, switch to the Routes tab and click on the edit action button (pencil icon). Then switch to the filters tab.</li> <li>To create a global filter, switch to the Global filters tab and click on the \"+\"-Button in the lower-right corner.</li> </ol> </li> <li>Choose the type of filter on the left side. Refer to the filter table below for an explanation of the different filters. For single APIs it is possible to define multiple filters, while a global filter is a single instance of a filter type.</li> <li>Once done, click on \"Save changes\" in the upper-right corner.</li> <li>If you specified a global filter, you will then need to referecee it in all routes that should use it.<ol> <li>For that, switch to the Routes tab and click on the edit action button (pencil icon) of the respective API.</li> <li>Switch to the Global Filters tab of the API editor.</li> <li>Drag the name of the global filter from the list of available filters on the left to the list of applied filters on the right.</li> <li>Click on \"Save changes\" in the upper-right corner. Repeat for all routes that should use the global filter.</li> </ol> </li> </ol>"},{"location":"WP07/Interoperability/#filter-reference","title":"Filter reference","text":"Category Filter name Filter description Pre-Request Action External Call Call an HTTP(S) endpoint from the API Gateway before the request to the API is made. The response can be used in the API request through Response Variable Mapping. Example: To use an returned token from a JSON response, set the Target Variable / Mapping to request.headers.Authorization and the Source Variable / Value to ${externalCallResponse.payload.token}. This extracts the token from the JSON field \"token\" from the External Call Response and copies it into the \"Authorization\" header of the API request. Request Transformation Set Headers This filter allows setting custom HTTP headers for the request to the original endpoint. This can be used for example to supply access credentials for the original endpoint or tenant information that your API requires. OAuth 2.0 Client Authorization This filter automatically aquires an access token from the specified OAuth 2.0 compliant token issuer and uses it in the \"Authorization\" header when forwarding the request to the original endpoint. Remove Incoming Headers Removes the specified HTTP headers from the incoming request before the API request forwards it. This can be used for example, if your API is controlled by a third party and should not get access to the ZDZW Access Token. In this case add the \"Authorization\" header to the list of excluded headers. !Note: The order of filters is important in this case. If this filter is combined with other filters setting or reading the value of the specified headers, this filter must be first in list, otherwise it will delete the newly set values. Request Validation ZDZW License Verification Verifies that the calling user has a valid license for the specified ZDZW Marketplace Product. ZDZW Blockchain This filter must only be used when configuring the ZDZW Blockchain API, not for any other API."},{"location":"WP07/Interoperability/#complex-event-processing-cep","title":"Complex Event Processing (CEP)","text":"<p>The Complex Event Processing component is based on the APAMA Community Edition, a freemium version of Apama that can be used to learn about, develop and put streaming analytics applications into production. For instructions on how to use this software, please refer to the official documentation at https://techcommunity.softwareag.com/en_en/products/iot---analytics/apama.html#apama-documentation</p>"},{"location":"WP07/Interoperability/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>RabbitMQ Documentation</p>"},{"location":"WP07/Kubernetes-Platform/","title":"Kubernetes Platform","text":""},{"location":"WP07/Kubernetes-Platform/#general-description","title":"General Description","text":"<p>This solution provides the key infrastructure where the ZDZW solutions are deployed and integrated. The Kubernetes Platform as per its descriptive name, is based on Kubernetes and Containers technologies.</p> <p>Containers have quickly become the standard for application deployment. Containers are units of software that package up code and all dependencies so that an application is able to run quickly and reliably in various computing environments, from OnPremise to OnCloud to Edge deployments.</p> <p>Kubernetes is the leading container orchestration technology and has become the de facto standard for container orchestration. Kubernetes is a portable, extensible, open-source platform for managing containerized workloads. It facilitates declarative configuration and automation, takes care of scaling and failing over applications, provides deployment patterns, and more. </p> <p>The Kubernetes Platform is a pre-packaged Kubernetes bundle, based on Kubernetes K3s, with several other tools to provide a fully featured production ready Kubernetes environment, such as:</p> <ul> <li>K3s: the lightweight Kubernetes, is a fully compliant Kubernetes distribution, easy to install, half the memory, all in a binary of less than 100 MB among other enhancements</li> <li>Rancher: Kubernetes cluster management tool with a user friendly UI</li> <li>Helm: the package manager for Kubernetes. The ZDZW solutions will be packaged using Helm charts</li> <li>Ingress Controller: the entry point for the cluster through the applications URLs using HTTP/HTTPS or TCP</li> <li>Service Mesh: transparent layer for enhanced connectivity, security, control and observability in the cluster</li> <li>Kubernetes Storage: provide the Kubernetes native storage for the stateful applications</li> </ul> <p>The Platform can be installed on-Cloud, on-Prem and on the Edge, providing great flexibility for the different ZDZW solutions needs. Within the scope of the project, there is the possibility to create a prototype of a Hardware box for Edge and on-Prem installation and connectivity with the cloud platform.</p>"},{"location":"WP07/Kubernetes-Platform/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>Installation Process: The Platform provides a user friendly installation process for easy installation to non-experienced users.    In any case, management of the platform itself, will require some expertise.</li> <li>Flexibitlity of installation modes: supports different installation modes from on-cloud to on-prem and edge</li> <li>Development installation: The suite provides a development version of the platform so-called miniZDZW for ZDZW solutions developers to be able to test deployment of the apps in a development environment</li> <li>Platform Scalability: grows in resources as needed, i.e. add additional nodes</li> <li>Management Interface: provides a user friendly UI for cluster management. Management of the platform itself will require some expertise</li> <li>Management of Apps: provides the interface and API to manage apps in the platform : deployment, deletion, upgrade</li> <li>Monitoring of Platfom and Apps: provides the interface and API to monitor the platform itself and the apps running in the platform</li> <li>App Packaging \u2013 Helm Charts: provides the app packaging in the form of Helm charts for repeatable deployments. Provides platform side configuration to be applied during deployment of the apps</li> <li>Base Charts Engine: provides a cli to automatically create the application Helm chart based on base charts defined by operations or devops teams</li> <li>Networking-Connectivity: provides secure networking and connectivity among the installed apps and to and from outside the cluster</li> <li>Log management: ability to retrieve application logs for troubleshooting and debugging</li> <li>Native Storage: provide Kubernetes native storage for stateful applications</li> </ol>"},{"location":"WP07/Kubernetes-Platform/#architecture-diagram","title":"Architecture Diagram","text":"<p>This Figure represents a high level architecture diagram of the ZDZW Kubernetes Platform. </p> <p>The ZDZW Platform solution has the following components:</p> <ul> <li> <p>Kubernetes: leading technology in container orchestration, key component that manages the deployment and integration of ZDZW applications. The current distribution used is K3s, which is a lightweight version of Kubernetes as described above. One of the main advantages of using the K3s distribution is that the same technology can be used to install a large OnCloud Kubernetes cluster, or a single node cluster deployed on the edge. The current Kubernetes version installed is 1.26 which is the most up to date version compatible with Rancher</p> </li> <li> <p>Management UI - API: open source software mainly based on Rancher that allows to deploy and manage Kubernetes clusters in a more user-friendly way both on-premise and on-cloud. The Rancher application will provide not only the management interface for platform administrators but also the app installation interface and API integration for ZDZW users. The current Rancher version being used is 2.7.9</p> </li> <li> <p>ServiceMesh \u2013 Ingress Controller: allows to add transparently a layer to provide the platform with enhanced connectivity, security, control and observability. It uses a sidecar container deployed along the application container to provide the service mesh features. This service mesh also allows for connectivity between distributed clusters, such as on-prem to on-cloud. The Service Mesh is not yet installed in the current ZDZW Platform, and nginx ingress controller version is being used, but will be installed in the next iteration of the platform</p> </li> <li> <p>Gateway - Ingress: provides the entry point to the cluster and the service mesh for all network traffic. It exposes the applications through the internet. The current ingress resource is based on nginx ingress controller, and will likely evolve to ServiceMesh Gateway when the ServiceMesh is installed </p> </li> <li> <p>Monitoring UI-API: open source software mainly based on Prometheus + Grafana, provides the monitoring interface for the cluster and the ZDZW applications. It may provide also an interaction with the ZDZW usage traceability. Prometheus and Grafana have not beeen installed yet in the platform and the Rancher monitoring capabilities are being used</p> </li> <li> <p>Storage Management: provides the interface between Kubernetes and the physical storage, i.e. NFS controller, EBS controller \u2026 At the moment, the current setup is using local storage for apps but this will change in future iterations of the platform where NFS and/or Kubernetes native storage will be used </p> </li> <li> <p>CertManager: provides management of SSL certificates for secure connectivity ie. HTTPS, with verified signed certificates using Let\u2019s Encrypt. Cert-manager version is being used. The current certificates are self-signed since in this iteration no application is being exposed to internet. This will change in the next iteration of the platform, where Let's Encrypt signed certificates will be created for the applications</p> </li> </ul>"},{"location":"WP07/Kubernetes-Platform/#image-overview","title":"Image Overview","text":""},{"location":"WP07/Kubernetes-Platform/#hardware-components","title":"Hardware Components","text":"<p>The current ZDZW Cloud platform is runing in Ascens cloud vendor using three Ubuntu 20 VMs with the requirements detailed in the next section. The Hardware details in this case are not required since provided by cloud vendor.</p>"},{"location":"WP07/Kubernetes-Platform/#computation-requirements","title":"Computation Requirements","text":"<p>For the development installation of the platform or edge deployment (minizdzw), these are the minimum requirements. This can be increased depending on the number of ZDZW solutions to be deployed:</p> <ul> <li>4 CPUs</li> <li>6-8 GB RAM</li> <li>32 GB Storage</li> </ul> <p>For a private OnCloud/OnPrem deployment of the platform a minimum of three nodes cluster is recomended with requirements similar to the ones in the current ZDZW Cloud Platform:</p> <ol> <li> <p>Master Node</p> <ul> <li>8 CPUs</li> <li>8 GB RAM</li> <li>64 GB Storage</li> </ul> </li> <li> <p>Two Worker Nodes each with</p> <ul> <li>8 CPUs</li> <li>16 GB RAM</li> <li>256 GB Storage</li> </ul> </li> </ol>"},{"location":"WP07/Kubernetes-Platform/#installation-procedure","title":"Installation Procedure","text":"<p>There are two different setups, one for development or edge deployment named after miniZDZW which is just a single node cluster version of the actual platform, and fully featured Kubernetes Platform.</p>"},{"location":"WP07/Kubernetes-Platform/#minizdzw","title":"miniZDZW","text":"This is a tool to install a single node cluster version of ZDZW Kubernetes Platform. The user just needs to run a single script and this will install and configure all the required tools.<ol> <li> <p>Clone the repository</p> <pre><code>git clone https://github.com/zdzw-eu/Kubernetes-Platform.git\n</code></pre> </li> <li> <p>Navigate to minizdzw folder</p> <pre><code>cd minizdzw2.0\n</code></pre> </li> <li> <p>Run minizdzw</p> <pre><code>./minizdzw.sh ip iface\n</code></pre> <p>where ip is the ip of the node where running the script and iface is the network interface of the ip. The script will install and configure all the required tools for miniZDZW platform to run. That is:</p> <ul> <li>Docker</li> <li>K3s (Kubernetes)</li> <li>Helm</li> <li>Cert-manager</li> <li>Rancher</li> <li>Creates a self signed certificate to use by the ingress controller</li> <li>Nginx Ingress Controller</li> <li>nginx docker (load balancer)</li> </ul> </li> <li> <p>Once the script has successfully installed miniZDZW, access the Rancher URL at https://rancher.$nodeip.zdzw.sslip.io, which is the default domain used during the installation. Enter the default admin password set by default to \"admin\" and create a new admin password. Start managing the Kubernetes cluster and apps using the Rancher UI. In the \"How To Use\" section there will be detailed instructions on how to use and perform the key management actions of the Kubernetes platform</p> </li> </ol>"},{"location":"WP07/Kubernetes-Platform/#kubernetes-platform-installation-kit","title":"Kubernetes Platform Installation Kit","text":"<p>An installer for the Kubernetes Platform called Installation Kit has been developed.   The idea is to allow non experienced users to deploy the platform along with a fully featured Kubernetes cluster, with all tools installed and configured.   The ZDZW Installation Kit will run as a docker container on an installation node or even on a local laptop and will install the platform in the remote nodes.   The Installation Kit allows the user to configure and customize the installation process using some forms via browser and will run Ansible playbooks on the backend in order to effectively install the platform.</p> <p>The main steps to install the Kubernetes Platform are:</p> <ol> <li> <p>Clone the repository</p> <p><pre><code>git clone https://github.com/zdzw-eu/Kubernetes-Platform.git\n</code></pre>     2. Navigate to the project directory</p> <p><pre><code>cd zdzwprem-installer\n</code></pre>     3. Build the image</p> <p><pre><code>docker build -t &lt;image_name&gt; .\n</code></pre>     4. Run the image</p> <p><pre><code>docker run -it -p 80:80 -p 9090:9090 &lt;image_name&gt;\n</code></pre>     5. Navigate to your local browser at http://127.0.0.1     6. Enter the user to be used for installation, by default icedrancher      7. Download the create_user.sh script and run it manually on the nodes where the platform will be installed. This script will create the installation user in each platform node and distribute the ssh keys in order to be able to run the commands from the installation node. Clik the \"Next\" button once the script has been run in all nodes      8. Fill in all the forms with the required cluster info * 1 Basic Options: enter the cluster name * 2 Load Balancer Options: enable an external nginx load balancer option if you don't have a load balancer. Enter the ip of the node where the nginx loadbalancer will be installed. * 3 K3s Options: enter the details of the nodes where the cluster will be installed.        Click on add in order to add a new node. In the pop up dialogue enter the Node Type (master or worker), the IP and the network interface. You have to create at least one master node and an odd number of them. * 4 Rancher options: select whether to use the same domain for Rancher than the applications one * 5 Confirmation: review the options selected and click on the Install button. The installation will start. Once installation is successfull click on Done button and the cluster is installed. You can now navigate to the Rancher UI. </p> </li> </ol>"},{"location":"WP07/Kubernetes-Platform/#how-to-use","title":"How To Use","text":"<p>This section provides the steps not only on how to use the Kubernetes Platform and the Rancher UI but also instructions on how to prepare the Helm Charts for the platform.</p>"},{"location":"WP07/Kubernetes-Platform/#kubernetes-platform_1","title":"Kubernetes Platform","text":"<p>Once the ZDZW Kubernetes Platform has been installed and the Rancher UI can be accessed as show in section \"Installation Procedure\", these key management actions can be performed:</p> <ul> <li> <p>Inspect the cluster and check number of nodes, resources, etc   </p> </li> <li> <p>A user can register a catalog or repository in order to be able to deploy apps from that catalog. A catalog is just a repository, git or helm, where helm charts are stored. Rancher has already some default catalogs registered. In order to create the new one, navigate to the cluster, apps, repositories, and click on the \"Add Catalog\" button. Fill in the form with the credentials for a private repository and click \"Create\". The Catalog is added to Rancher and the apps will be displayed in the Apps view   </p> </li> <li> <p>Applications can be deployed from the registered Catalog. Navigate to Apps, Charts and the list of available charts (apps) is displayed. Select the chart to be deployed, click on Install, select the Namespace and Name for the instance of the chart and select whether to customize the Helm options before install. If customization is selected, fill in the configuration form and or yaml. Click Next then click Install. The application will be deployed to the platform.   </p> </li> <li> <p>Application logs can be monitored. Navigate to Apps, Installed Apps, and the list of installed apps is displayed. Select the app to be monitored and the list of resources of that application are displayed. Select the Deployment and the Pod is displayed. Click on the three dots on the right and select View Logs. The logs of the application are displayed.    </p> </li> <li> <p>Applications can be deleted by navigating to Apps, Installed apps and clicking on the three dots on the right and click on Delete.   </p> </li> </ul> <p>For more detailed description on these steps, refer to Additional Learning Materials, the Rancher documentation.</p>"},{"location":"WP07/Kubernetes-Platform/#helm-charts","title":"Helm Charts","text":"<p>Helm is the package manager for Kubernetes. It helps you manage Kubernetes applications by combining the different Kubernetes resources an application is composed of in a single package, the Helm Chart, that you can create, share, version, publish, install, upgrade and delete. It also provides templating functionality so that different values can be configured for an application.</p> <p>But creating a Helm Chart and the Kubernetes resources is not an easy task since it requires some Kubernetes knowledge. For that reason the Kubernetes Platform provides a base or template Helm Chart to be imported as a subchart in an application chart.</p> <p>The idea is that developers creating zwApps can re-use this base chart as many times as per the number of modules in their zwApp, i.e. frontend, backend, without any knowledge of Kubernetes related stuff, and only having to override a set of values.</p> <p>The base chart includes the following resources pre-configured to be re-used out of the box:</p> <ul> <li>A deployment</li> <li>A service</li> <li>An ingress</li> <li>A persistent volume and persistent volume claim</li> <li>A service account</li> <li>A registry secret</li> <li>A pre-configured set of values in values.yaml</li> </ul> <p>With this, developers just need to include the base chart in their chart folder, and override some values depending on apps needs, that is just having to update a single yaml file vs creating all Kubernetes related resources yaml files, thus simplifying developers integration with Kubernetes and the Kubernetes learning curve.</p> <p>These are the detailed step by step instructions in order to use the base Helm Chart. We will refer to the base chart as zapp-base and to the zwapp chart as zwapp:</p> <ul> <li> <p>Clone the integration repository</p> <p><pre><code>git clone https://github.com/zdzw-eu/integration.git\n</code></pre>        this repository contains the basechart for ZDZW platform in the /apps/zapp-base2 folder   </p> </li> <li> <p>Create a helm chart using helm cli </p> <pre><code>helm create zwapp\n</code></pre> </li> </ul> <p>where zwapp is the name of the chart to be created</p> <ul> <li> <p>Remove non-required folders and files</p> <pre><code>rm -rf zwapp/templates/*\nrm zwapp/values.yaml\n</code></pre> </li> <li> <p>Copy the base helm chart to the zwapp charts subfolder with a different name i.e. zmodule1, and replace the Chart.yaml name accordingly. Copy the base helm chart values.yaml to the zwapp values</p> <pre><code>cp -r integration/apps/zapp-base2/ zwapp/charts/zmodule1  \nsed -i 's/zapp-base/zmodule1/' zwapp/charts/zmodule1/Chart.yaml  \ncp zwapp/charts/zmodule1/values.yaml zwapp/\n</code></pre> </li> <li> <p>Edit the zwapp values in order to leave only the variables you need to override. Add the reference to the subchart name (the base chart) and ident all related values to the right. This is an example of a values file in order to override the app related values</p> <pre><code>zmodule1:  \n  app:  \n    name: myname  \n    port: 80\n</code></pre> </li> <li> <p>Add an optional configmap if you need to include zwapp related env variables to be set. For this, you can set the values app.env to true (default). Then add in the zwapp/templates folder a configmap with the name $appname-configmap.yaml, where $appname is the name of the app in the values variable app.name. This is an example of a configmap</p> <pre><code>apiVersion: v1  \nkind: ConfigMap  \nmetadata:  \n  name: {{ .Values.zmodule1.app.name }}-configmap  \n  namespace: {{ .Release.Namespace }}  \ndata:  \n  WELCOME_MESSAGE: {{ .Values.welcome_message }}\n</code></pre> </li> <li> <p>Platform Configuration</p> <p>The latest version of the Helm template includes a brand new platform based configuration to remove the need from users to enter the platform configuration part when deploying an application on the platform.</p> <p>That is mainly the git repository, user and password for the image pull secret needed to pull the images from the zdzw GitHub repositories.</p> <p>In addition other configuration is also added such as the domain, so that users deploying applications on the platform don't need to change the url of the applications.</p> <p>All this configuration is automatically obtained from a platform level ConfigMap and Secret that contain that information and are created during installation time of the platform.</p> </li> </ul> <p>For additional instructions and examples see ZDZW Integration and Helm Chart links at Additional Learning Materials section.</p>"},{"location":"WP07/Kubernetes-Platform/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Kubernetes https://v1-26.docs.kubernetes.io/docs/home/</p> <p>Helm https://helm.sh/</p> <p>K3s https://k3s.io/</p> <p>Rancher https://ranchermanager.docs.rancher.com/v2.7/getting-started/quick-start-guides</p> <p>Kubernetes-Platform https://github.com/zdzw-eu/Kubernetes-Platform.git</p> <p>Integration https://github.com/zdzw-eu/integration/tree/main</p>"},{"location":"WP07/Marketplace/","title":"Marketplace","text":""},{"location":"WP07/Marketplace/#general-description","title":"General Description","text":"<p>The Marketplace is a central repository for manufacturing sector applications, allowing users to search, purchase, and license applications. It provides a collaborative system for users to make requests, rate, and review zApps. Developers can access licenses for testing their own products. The backend offers content management, metadata organization, license management, and affiliate marketing. This is an App for: Manufacturers: Manufacturers benefit from the Marketplace by easily finding and obtaining licenses for specialized applications tailored to their specific needs in the manufacturing sector. They can search for applications based on various characteristics such as category, price, and payment type, streamlining the process of deploying applications across their infrastructure. Developers: The Marketplace provides developers with a centralized platform to showcase and distribute their applications. They can easily manage and update metadata, organize different licenses, and set pricing for their products through the backend content management system. This streamlines the process of reaching a wider user base and simplifies licensing management.</p>"},{"location":"WP07/Marketplace/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>Intuitive Application Discovery: The marketplace offers a user-friendly interface that simplifies the process of discovering specialized applications (zApps) for manufacturers. Users can easily explore and find relevant solutions based on categories, pricing, and licensing models.</li> <li>User Feedback and Ratings: Manufacturers can benefit from the feedback and ratings provided by other users. This feature allows them to make informed decisions by considering the experiences and opinions of their peers.</li> <li>Flexible Licensing Models: The marketplace supports a variety of licensing models to cater to different manufacturing needs. From one-time fees to advanced subscription options like pay-as-you-go and pay-per-use, manufacturers have the flexibility to choose the most suitable licensing model for their requirements.</li> <li>Advanced Subscription Options: In addition to traditional licensing models, the marketplace introduces innovative subscription-based options. Manufacturers can opt for pay-per-zero-waste saved or other customized subscription plans that align with their sustainability goals and usage patterns.</li> <li>Transparent Cost Visualization: The marketplace provides manufacturers with visibility into ongoing costs per application. This feature allows them to track and manage their expenses effectively, making budgeting and resource allocation more efficient.</li> <li>Secure Payment Gateway Integration: Seamless integration with trusted third-party secure payment gateways ensures secure and convenient payment transactions. Manufacturers can make payments for the acquired applications with confidence, knowing that their financial information is protected.</li> <li>Seamless Interlinking with ZDZW Traceability: The marketplace seamlessly integrates with the ZDZW secure usage traceability for monetization service. This feature guarantees reliable and transparent tracking of usage data, enabling manufacturers to make data-driven decisions and optimize resource allocation based on accurate insights.</li> <li>Robust Application Management: The marketplace offers comprehensive application management capabilities. Manufacturers can easily access and manage their purchased zApps, including license renewal, deployment requests, and updates.</li> <li>Customized Categories and Search: Manufacturers can further refine their search for applications by utilizing customized categories set up in the marketplace. This feature allows them to narrow down their options and find the most relevant solutions for their specific needs.</li> <li>Streamlined User Experience: The marketplace prioritizes user experience by providing a seamless and efficient interface. With streamlined processes, intuitive navigation, and responsive design, manufacturers can easily navigate the marketplace, explore applications, and carry out transactions without unnecessary friction</li> </ol>"},{"location":"WP07/Marketplace/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"WP07/Marketplace/#image-overview","title":"Image Overview","text":""},{"location":"WP07/Marketplace/#hardware-components","title":"Hardware Components","text":"<p>The code will run on a basic laptop, with docker.</p>"},{"location":"WP07/Marketplace/#computation-requirements","title":"Computation Requirements","text":"<p>Minimum 1 VCPU, 1 Gb RAM, 5Gb storage Recommended 4 VCPU, 4 Gb RAM, 80 Gb Storage Docker version 19 minimum</p>"},{"location":"WP07/Marketplace/#installation-procedure","title":"Installation Procedure","text":"<p>Step by step on how to install the application:</p>"},{"location":"WP07/Marketplace/#docker-installation","title":"Docker installation","text":"<p>Git clone this repository: SSH: <pre><code>git clone git@github.com:zdzw-eu/Marketplace.git\n</code></pre> HTTPS: <pre><code>git clone https://github.com/zdzw-eu/Marketplace.git\n</code></pre> * Standalone using docker compose Navigate to the orchestration folder using cmd or similar. <pre><code>cd orchestration\n</code></pre> Execute the command: <pre><code>docker compose up\n</code></pre> The Marketplace front end will be available at: http://localhost:8002/ The Product license manager will be available at: http://localhost:8000/</p> <p>If you are a developer and want to edit some of the code and see your changes in real time, here is how you can do that. Both the PLM and the Marketplace containers work in a way that it's looking at the directory and re-building automatically whenever you update the code.  If you want to run the Marketplace on a different port for example, you navigate to: <pre><code>cd subsystems\\marketplace\n</code></pre> You can then run the marketplace using: <pre><code>ng serve --port 4401\n</code></pre> As an example if you want to run it on port 4401</p> <p>Each system also has it's own environment variables and these are placed inside of a .env file inside of each subsystem/software's name The Marketplace has the following environment variables and here is an example of them in a .env file: <pre><code>PORTAL_FRONTEND_URL=http://localhost:4200\nPORTAL_API_URL=http://localhost:5100\nKEYCLOAK_URL=http://keycloak:8080/auth\nKEYCLOAK_CLIENT_ID=ZDMP_Portal\nKEYCLOAK_REALM=zdzw\nPRODUCT_LICENSE_MANAGER_API=http://localhost:8000/api\nPRODUCT_LICENSE_MANAGER_URL=http://localhost:8000\nCART_MEDIATOR_URL=http://localhost:8081\nTHEME=zdzw\n</code></pre> Cart mediator has the following .env env variables: <pre><code>ZDMP_MARKETPLACE_UI_URL=http://localhost:8082/\nZDMP_PRODUCT_LICENSE_MANAGER_URL=http://localhost:8000/\nZDMP_CART_MEDIATOR_URL=http://localhost:8081/\nZDMP_CART_MEDIATOR_JWT_KEY=de2d3f3892ecf7000fe8cddb2ce0c801217ec0f31079ba56beff62f20a0b982f\nZDMP_CART_MEDIATOR_ORDER_SECRET=ozsl6h662Jf5r+1rGU44sg==\nZDMP_CART_MEDIATOR_MONGODB_CONNECTION_STRING=mongodb://admin:admin@host.docker.internal:27018/?authSource=admin&amp;readPreference=primary&amp;ssl=false\nZDMP_CART_MEDIATOR_MONGODB_DATABASE=zdmpCart\nZDMP_KEYCLOAK_URL=http://host.docker.internal:8080/\nZDMP_KEYCLOAK_PLM_CLIENT_ID=ZDMP_Portal\nZDMP_KEYCLOAK_PLM_CLIENT_USERNAME=xxx\nZDMP_KEYCLOAK_PLM_CLIENT_PASSWORD=xxx\nZDMP_KEYCLOAK_PLM_CLIENT_REALM=i4fs\nZDMP_CART_MEDIATOR_MAIL_HOST=xxx\nZDMP_CART_MEDIATOR_MAIL_PORT=xxx\nZDMP_CART_MEDIATOR_MAIL_ENCRYPTION=xxx\nZDMP_CART_MEDIATOR_MAIL_USERNAME=xxx\nZDMP_CART_MEDIATOR_MAIL_PASSWORD=xxx\nZDMP_CART_MEDIATOR_FROM=xxx\nZDMP_CART_MEDIATOR_STRIPE_KEY=xxx\nZDMP_CART_MEDIATOR_STRIPE_WEBHOOK_ENDPOINT_SECRET=xxx\nENVIRONMENT=development\n</code></pre> Replacing the xxx's with values for Stripe and also a mail server.</p> <p>Finally the Product license manager has the following .env file variables: <pre><code>APP_NAME=ZDMP\nAPP_ENV=local\nAPP_KEY=base64:O+AXgu3+EAXTs7npuOkmvBWbn4lpbsPYXaV2DDRAz18=\nAPP_DEBUG=true\nAPP_URL=localhost:8000\nQUERY_DETECTOR_ENABLED=false\n\nKEYCLOAK_BASE_URL=http://host.docker.internal:8080/auth\n\nKEYCLOAK_REALM=i4fs\nKEYCLOAK_CLIENT_ID=admin-cli\nKEYCLOAK_REALM_PUBLIC_KEY=2caf5527-892f-4ad3-a5d7-420155762130\nMASTER_KEYCLOAK_REALM=master\nMASTER_KEYCLOAK_CLIENT_ID=admin-cli\nMASTER_KEYCLOAK_USER=admin\nMASTER_KEYCLOAK_PASSWORD=Pa55w0rd\n\nDASH_BUTTON_LOGIN=http://localhost:4200/auth/login\nPORTAL_URL=http://localhost:5100\n\nKEYCLOAK_PRODUCT_OWNER_ROLE=ZDMP_Marketplace_Product_Owner\n#KEYCLOAK_MODERATOR_ROLE=ZDMP_Marketplace_Moderator\nKEYCLOAK_ADMIN_ROLE=ZDMP_Marketplace_i4FS_admin\n\nSECURE_INSTALLATION_URL=https://secure-installation-api-zdmp.platform.zdmp.eu/zdmp/api/v_0_1\nMONITORING_AND_ALERTING_URL=https://monitoring-and-alerting-api-zdmp.platform.zdmp.eu/\n\nMARKETPLACE_URL=http://host.docker.internal:8082/\n\nLOG_CHANNEL=daily\n\nDB_CONNECTION=mysql\nDB_HOST=mysql-db\nDB_PORT=3306\nDB_DATABASE=db\nDB_USERNAME=dbuser\nDB_PASSWORD=secret\n\nBROADCAST_DRIVER=log\nCACHE_DRIVER=file\nQUEUE_CONNECTION=database\nSESSION_DRIVER=file\nSESSION_LIFETIME=120\n\nREDIS_HOST=127.0.0.1\nREDIS_PASSWORD=null\nREDIS_PORT=6379\n\n#MAIL_MAILER=smtp\nMAIL_MAILER=xxx\nMAIL_HOST=xxx\nMAIL_PORT=2525\nMAIL_USERNAME=xxx\nMAIL_PASSWORD=xxx\nMAIL_ENCRYPTION=tls\nMAIL_FROM_ADDRESS=noreply@zdmp.com\n\nAWS_ACCESS_KEY_ID=minio\nAWS_SECRET_ACCESS_KEY=minio123\nAWS_DEFAULT_REGION=us-east-1\nAWS_BUCKET=test\nMINIO_ENDPOINT=xxx\n\nPUSHER_APP_ID=\nPUSHER_APP_KEY=\nPUSHER_APP_SECRET=\nPUSHER_APP_CLUSTER=mt1\n\nMIX_PUSHER_APP_KEY=\"${PUSHER_APP_KEY}\"\nMIX_PUSHER_APP_CLUSTER=\"${PUSHER_APP_CLUSTER}\"\nFILESYSTEM_CLOUD=minio\n#MEDIA_DISK=minio\nMEDIA_DISK=local\n\nGITHUB_CLIENT_ID=\nGITHUB_ORG=zdzw-marketplace\nGITHUB_CLIENT_SECRET=\n\nSTRIPE_KEY=\n\nTHEME=zdzw\n</code></pre></p> <p>Some further help can be found inside of the readme file's of each subsystem also.</p>"},{"location":"WP07/Marketplace/#helm-chart-installation","title":"Helm chart installation","text":"<p>If you don't need certain developer features, you can simply start the Marketplace application using the prebuilt Helm chart.</p> <p>First, clone the ZDZW Catalog repository by running the following command:</p> <p><pre><code>git clone https://github.com/zdzw-eu/zdzwcatalog.git\n</code></pre> Next, navigate to the /charts/marketplace directory. In this directory, you will find the latest Helm chart version for the Marketplace application.</p> <p>Before starting the Marketplace application, configure the environment variables.</p> <p>To do this, open the values.yaml file in the selected chart version. You will see various configuration options while setting up the local installation, so configure the values as you wish.</p> <p>Finally, run the Helm chart using the following command:</p> <pre><code>helm install marketplace .\n</code></pre> <p>Finally, you can access the application using your configured settings.</p> <p>NOTE:  You can use the same Helm chart to run the application via Rancher. In this case, you don't need to manually configure the options.</p>"},{"location":"WP07/Marketplace/#how-to-use","title":"How To Use","text":""},{"location":"WP07/Marketplace/#marketplace_1","title":"Marketplace","text":""},{"location":"WP07/Marketplace/#marketplace-user-interface-and-payment-system","title":"Marketplace User Interface and Payment System","text":"<p>The frontend for users focuses on findability of the created zApps. For this, the following tools are implemented:</p> <ul> <li>A sorter allows the sorting of the shown list by Category, Price, Name or Rating.</li> <li>The categories on the left-hand menu let the user quickly filter by Category. The discover mode lets the user search for a flat list of all categories of zApps. These categories are obtained from the Product License Manager and can be configured by the administrator</li> <li>The search bar allows filtering the results shown by title, dynamically updating as necessary. It also includes search suggestions based on matching product titles</li> <li>The tags allows filtering based on a number of tags, this is similar to the categories but more diverse. </li> </ul>"},{"location":"WP07/Marketplace/#product-details","title":"Product Details","text":"<p>The single items are now comprised of a title, version information and details, links to any documentation/information, categories, screenshots, a screenshot gallery, a description, a list of dependencies, a ratings widget displaying the aggregated ratings for the product and a paginated list of reviews.  This detail page also shows combinations of license and currencies in which the zApp is available.</p> <ul> <li>Product View Details Page </li> </ul>"},{"location":"WP07/Marketplace/#product-licenses","title":"Product licenses","text":"<p>If the user clicks the \u201cBuy\u201d button, they will be presented with licenses including their durations. This list only includes the licenses which are available for the currently selected currency. After selecting the desired license, the zApp will be added to the cart. If the zApp is not available in the current currency, the buy button is disabled. If the current user of the Marketplace User Interface is the developer of the opened product, the detail screen also provides a \u201cDeveloper Access\u201d functionality. If the user clicks on this button, they will be presented with the same license selection dialog as if they would try adding the product to the cart. The difference is that upon selecting a license, the developer obtains the license for their product directly. This allows the developer to test their product without having to buy their product.</p> <ul> <li>Product License Selection </li> </ul>"},{"location":"WP07/Marketplace/#cart","title":"Cart","text":"<p>After adding the desired zApps to the cart, the user can use the \u201cGo to checkout\u201d button to initiate the payment process. The payment process in place currently puts the software items in the shopping cart with the selected license. The next step is gathering or confirming the shipment address as this is necessary for tax accounting. After sending the order, the user will be redirected to the integrated payment provider Stripe, where they will enter their payment details. After entering the payment details was successful, the user is redirected back to the order confirmation screen. In the background, the payment provider processes the payment and notifies the payment backend of the Marketplace if it was successful or not. If the payment was valid, the payment backend notifies the Product License Manager to store new licenses according to the placed order. In the final step, the summary containing the ordered licenses is displayed in a result screen. After purchasing the licenses, there is a purchases menu item on the lower left-hand side. It leads to a page displaying all currently confirmed licenses for the user\u2019s account. This may not yet contain the ordered licenses, as this depends on the payment provider confirming the payment.</p> <ul> <li>Cart  </li> </ul>"},{"location":"WP07/Marketplace/#renew-smart-contract","title":"Renew smart contract","text":"<p>Users can now renew purchased product contracts directly from the Marketplace Purchases page. By selecting the relevant product\u2019s smart contract ID, users are able to renew the contract before its expiration. This feature is currently supported only for pay-per-period and pay-per-volume based license products.</p> <p></p>"},{"location":"WP07/Marketplace/#product-license-manager","title":"Product License Manager","text":""},{"location":"WP07/Marketplace/#dashboard","title":"Dashboard","text":"<p>The dashboard contains various widgets which display information based on the current user's roles(developer/admin).</p> <p>At the top of the dashboard are four counters: total sales, products, licenses and the last for the affiliates. The next widget is a chart that displays the license selling evolution in time and monthly and yearly totals. The graph widget displays the spreading across the world of the users that bought the licenses(see images above). There is one section for the count and a duplicated section for the total value in euros.</p> <p>Products list This screen contains the product list with some of its information such as ID, name, languages, etc. Each product has a status based on its current situation. The list has some additional buttons which allows the user to export that list in CSV, Excel, and PDF file. Also, it has two other buttons that allow the user to copy to clipboard the list or to print it. * Admin Dashboard  * User Dashboard </p>"},{"location":"WP07/Marketplace/#github","title":"GitHub","text":"<p>We are using GitHub to store the products and any assets that the customer whom purchases the product can download. We have an organization set up inside of GitHub and when a user wishes to sell a product on the PLM they create a private GitHub repository from this component. Here is an example of a user who has already made the repository, if they hadn't already made it, then there would be a button displayed saying to create a repository. We have a GitHub application which creates their repository for them and then invites them to it and also to the organization. </p>"},{"location":"WP07/Marketplace/#add-a-new-product","title":"Add a new product","text":"<p>Before adding a product, the developer should read and agree the developer agreement, then select a type of product (Product or Consultancy asset) and then start to complete the product information.</p> <p>Adding a new product is a process that can be performed in the following ways: Using the Product Manager UI or using the Product Manager REST API.</p> <p>Every time a product is created, it receives the \u201cReady for review\u201d status and an email is sent to designated moderators to check if the product has the right information. While the product is reviewed, it gets the status \u201cReviewing\u201d so it cannot be processed by another reviewer at the same time. After reviewing, the moderator sets the next status, either they will accept the product or they will reject it and send it back to the owner to do the necessary changes. Only the accepted products can be displayed in the Marketplace frontend.</p> <p>Within the UI can be found three tabs, each has a set of fields with a common purpose. The Info tab contains the main product information such: Product id, name, version, category, download file, dependencies, associated hardware/services etc. The primary language is English, and the main currency is Euro.</p> <p>The Licensing tab adds the possibility to add different licenses based on the duration, license type such as a one time purchase or subscription or pay per use or pay per volume, price and currency, each license has license link and description.</p> <p>The Asset Links tab allows users to add different links to their product which are then displayed on to the frontend for the user to view, these could be things such as videos, licensing links and more information for example.</p> <ul> <li>User Products </li> <li>User Adding new product  </li> </ul>"},{"location":"WP07/Marketplace/#categories","title":"Categories","text":"<p>Admins can edit the categories from this tab. These are the categories that can be selected when a user is adding their new product, or editing their existing one. It also changes how the Marketplace displays the products and categories.</p> <ul> <li>Admin Categories </li> </ul>"},{"location":"WP07/Marketplace/#license-list","title":"License list","text":"<p>The license list can be seen via the Product License Manager UI. After each new license is purchased from the Marketplace that license is added to this table (see image above) and the owner is notified via email.</p>"},{"location":"WP07/Marketplace/#admin-settings","title":"Admin Settings","text":""},{"location":"WP07/Marketplace/#supported-platforms","title":"Supported Platforms","text":"<p>Each product is created for certain platforms. The product form has a select box with multiple options from which the user can choose the supported platforms. That list is manageable in the Supported Platforms screen where they can be added or edited.</p>"},{"location":"WP07/Marketplace/#license-types","title":"License Types","text":"<p>Each license has a type which is required for the notification system and the license management system. These types are manageable in the License Type screen</p>"},{"location":"WP07/Marketplace/#currencies","title":"Currencies","text":"<p>Each product has at least a price with a currency. This screen allows the user to edit the currency names and symbols at this point.</p>"},{"location":"WP07/Marketplace/#file-formats","title":"File Formats","text":"<p>This page allows the admin user to add supported file types to be uploaded during the adding of a new product. It displays how many files of each type currently exists in the system also.</p>"},{"location":"WP07/Marketplace/#payment-settings","title":"Payment Settings","text":"<ul> <li>Admin Payment Settings </li> </ul>"},{"location":"WP07/Marketplace/#user-bank-account","title":"User Bank Account","text":"<p>This page set's up the connection between the Product License Manager with a Stripe account. Once this connection is in place any payments made for products and sent to this Stripe account.</p> <ul> <li>User Bank Account </li> </ul>"},{"location":"WP07/Marketplace/#deployment-type","title":"Deployment Type","text":"<p>When creating a new product, users can select from predefined deployment types. Currently, the supported options are Deployable, Downloadable, Local Licensed, and Cloud Licensed. Based on the product, users can choose the appropriate deployment type.</p>"},{"location":"WP07/Marketplace/#additional-learning-materials","title":"Additional Learning Materials","text":""},{"location":"WP07/Portal/","title":"Portal","text":""},{"location":"WP07/Portal/#general-description","title":"General Description","text":"<p>The Portal is the main website entry point to the ZDZW platform and its applications and it is based on the ZDMP Portal. It displays the applications that can be accessed as icons and users can navigate to them through the portal. </p> <p>The Portal will allow for organisation and users registration providing the single sign on functionality and incorporating the security aspect of the ZDZW platform using Keycloak and its users and RBAC functionality. </p> <p>The Portal also includes the Dash Button, a web component that needs to be integrated in all ZDZW solutions to provide an interface to the portal for session and JWT token management and allow users to navigate between ZDZW applications and provide support to the single sign on.</p>"},{"location":"WP07/Portal/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>UI main platform entry point: provides a UI that is the main entry point to the platform</li> <li>Display list of available apps: displays the list available apps to be able to navigate from the portal to a ZDZW app</li> <li>Display information on available apps: displays the status of the available apps as installed or not installed, and a link to the management UI in order to install the application if not installed</li> <li>Register an organisation and admin user: allows for organisation registration and admin user of the organisation in keycloak</li> <li>User management: allows to create additional users for an organisation</li> <li>Role Management: allows to create and assign roles to users</li> <li>Dash Button: provides a web component for zdzw security integration and easy navigation between zdzw applications</li> <li>JWT Management: provides a web component for token management</li> <li>Security Realm: provides management of security realms</li> </ol>"},{"location":"WP07/Portal/#architecture-diagram","title":"Architecture Diagram","text":"<p>This Figure represents a high level architecture diagram of the ZDZW Portal </p> <p>The Portal solution has the following components:</p> <ul> <li> <p>Portal UI: this is the main ui to allow access to the platform and the different ZDZW applications, providing single sign on and the list of available apps</p> </li> <li> <p>Portal Backend: the backend component of the portal, being the responsible for getting the list of apps and status from the Platform, and also act as the interface with the security component Keycloak</p> </li> <li> <p>Portal API: the API of the Portal Backend to allow communication from the Portal UI and the Dash Button  </p> </li> <li> <p>Dash Button: web component integrated into ZDZW UI apps that allow communication with the Portal and the security component </p> </li> <li> <p>Keycloak: open source software for security management</p> </li> </ul>"},{"location":"WP07/Portal/#image-overview","title":"Image Overview","text":""},{"location":"WP07/Portal/#hardware-components","title":"Hardware Components","text":"<p>The Portal does not have any hardware component.</p>"},{"location":"WP07/Portal/#computation-requirements","title":"Computation Requirements","text":"<p>The deployment of the Portal on top of ZDZW Platform, these are the minimum requirements:</p> <ul> <li> <p>1 CPU</p> </li> <li> <p>1 GB RAM</p> </li> <li> <p>2 GB Storage</p> </li> </ul> <p>These can be increased depending on the number of apps, users and organisations.</p>"},{"location":"WP07/Portal/#installation-procedure","title":"Installation Procedure","text":"<p>This section describes how to deploy the Portal on the ZDZW Kubernetes Platform and/or miniZDZW. It also describes how to integrate the Dash Button in a zwApp.</p> <p>First, clone the latest repository:</p> <pre><code>git clone https://github.com/zdzw-eu/Portal.git\n</code></pre> <p>Next, navigate to the portal-api directory and configure the environment variables.    Create a .env file and add the following options, replacing the placeholder values with your preferred settings:</p> <pre><code>KEYCLOAK_URL=https://keycloak-zdzw.cloud.zdzw-project.com\nREALM_NAME=zdzw\nCLIENT_ID=testapp\nCLIENT_SECRET=W1b720sjCZ4qB3ecAqatkMsrCd67pARy\n</code></pre> <p>Then, install the required npm modules and start the application. Run the following commands:</p> <p><pre><code>npm install\nnpm run start\n</code></pre>    That\u2019s it! You have successfully started the Portal backend application.</p> <p>Now, you can start the Portal frontend application. Open a new terminal window and navigate to the portal directory:</p> <pre><code>Next, open the **portal/src/environments/environment.ts** file and configure the environment variables according to your requirements.\n\n```\nexport const environment = {\n    \"KEYCLOAK_URL\":\"http://localhost:30400\",\n    \"PORTAL_API\":\"http://localhost:3000\",\n    \"REDIRECT_URL\":\"http://localhost:4200/dashboard\",\n    \"CLIENT_ID\":\"testbtn\",\n    \"REALM\":\"master\",\n    \"APP_ID\":\"\",\n    \"PORTAL_URL\":\"http://localhost:4200\",\n    \"MARKETPLACE_URL\":\"https://marketplace-zdzw.cloud.zdzw-project.com\",\n    \"PLM_URL\":\"https://productlicensemanager-zdzw.cloud.zdzw-project.com\",\n    \"SHOW_POST_LOGIN_TEXT\":\"true\",\n    \"POST_TEXT_DELAY_DURATION\": \"\"\n};\n```\n\nTo run the Portal frontend application, first install the required npm dependencies and then start the application.\n</code></pre> <p>Run the following commands:</p> <pre><code>```\nnpm install\nnpm start\n```\n\nNavigate to **http://localhost:4200/** to access the Portal application.\n\n\n#### 2. Helm chart installation\n\nIf you don't need certain developer features, you can simply start the Portal application using the prebuilt Helm chart.\n\nFirst, clone the ZDZW Catalog repository by running the following command:\n\n```\ngit clone https://github.com/zdzw-eu/zdzwcatalog.git\n```\nNext, navigate to the /charts/portal directory.\nIn this directory, you will find the latest Helm chart version for the Portal application.\n\nBefore starting the Portal application, configure the environment variables.\n\nTo do this, open the **values.yaml** file in the selected chart version.\nYou will see various configuration options while setting up the **local installation**, so configure the values as you wish.\n\nFinally, run the Helm chart using the following command:\n\n```\nhelm install portal .\n```\n\nFinally, you can access the application using your configured settings.\nThe default port for the Portal application is 80.\n\nNavigate to **http://localhost/** to access the Portal welcome page.\n\n&gt; **_NOTE:_**  You can use the same Helm chart to run the application via Rancher. In this case, you don't need to manually configure the options.\n</code></pre>"},{"location":"WP07/Portal/#portal_1","title":"Portal","text":"<p>The Portal can be installed on the ZDZW Kubernetes Platform or miniZDZW with the helm charts and the Rancher UI as a regular zwApp, once the zdzwcatalog repository has been registered as per the ZDZW Kubernetes Platform instructions and following the instructions on how to install an app.</p> <p>The Portal application consists of two main components: a backend API (built with the Nest framework) and a frontend (developed with Angular).</p> <p>Before running the Portal, you must first install the backend API application.</p> <p>There are two installation methods available:</p> <ol> <li> <p>Local installation \u2013 Set up the application on your local environment by running a few simple commands.</p> </li> <li> <p>Helm chart installation \u2013 Deploy the application quickly and efficiently using a Helm chart.</p> </li> </ol>"},{"location":"WP07/Portal/#1-local-installation","title":"1. Local installation","text":""},{"location":"WP07/Portal/#dash-button","title":"Dash Button","text":"<p>The Dash-button web component provides Keycloak-based authentication with Single Sign-On (SSO) features and requires minimal configuration to secure any frontend application. Based on the Stencil.js framework, it ensures consistent support across all modern frontend frameworks with minimal configurations.</p> <p>To install the Dash-button web component, you need to import the following JavaScript library in your HTML file:</p> <pre><code>&lt;script type=\"module\" src=\"https://unpkg.com/dash-button-web@0.0.12/dist/esm/web-component.js\"&gt;&lt;/script&gt;\n</code></pre> <p>After installation, you can place the Dash-button component anywhere in your web application. For minimal configuration, you need to pass the keycloak-uri, realm, and client-id attributes as shown below:</p> <pre><code>&lt;dash-button keycloak-uri=\"HTTPS://KEYCLOAK_URL\" realm=\"REALM\" client-id=\"CLIENT_ID\" show-post-login-text=\"false\"&gt;&lt;/dash-button&gt;\n</code></pre> <p>After that, you can get an output similar to this:</p> <p></p> <p>For developers with more specific requirements, the Dash-button component supports additional configuration options.</p> Property Attribute Description Type Default <code>appId</code> <code>app-id</code> <code>string</code> <code>\"\"</code> <code>authMethod</code> <code>auth-method</code> <code>string</code> <code>\"check-sso\"</code> <code>clientId</code> <code>client-id</code> <code>string</code> <code>\"\"</code> <code>keycloakUri</code> <code>keycloak-uri</code> <code>string</code> <code>\"http://localhost:8080\"</code> <code>marketplaceUrl</code> <code>marketplace-url</code> <code>string</code> <code>\"https://marketplace-zdzw.cloud.zdzw-project.com\"</code> <code>plmUrl</code> <code>plm-url</code> <code>string</code> <code>\"https://productlicensemanager-zdzw.cloud.zdzw-project.com\"</code> <code>portalUrl</code> <code>portal-url</code> <code>string</code> <code>\"\"</code> <code>postTextDelayDuration</code> <code>post-text-delay-duration</code> <code>number</code> <code>undefined</code> <code>realm</code> <code>realm</code> <code>string</code> <code>\"\"</code> <code>redirectUri</code> <code>redirect-uri</code> <code>string</code> <code>undefined</code> <code>showPostLoginText</code> <code>show-post-login-text</code> <code>boolean</code> <code>false</code> <code>showUnauthorizedModal</code> <code>show-unauthorized-modal</code> <code>boolean</code> <code>false</code> <code>silentCheckSso</code> <code>silent-check-sso</code> <code>boolean</code> <code>false</code> <code>usageTrackingUrl</code> <code>usage-tracking-url</code> <code>string</code> <code>\"https://usage-tracking-ui-zdzw.cloud.zdzw-project.com\"</code> <code>menuLinks</code> <code>menu-links</code> <code>Add new links for the menu</code> <code>string</code> <code>[{\"name\": \"\", \"url\": \"\"}]</code>"},{"location":"WP07/Portal/#theme-configuration-options","title":"Theme Configuration options","text":"Property Attribute Description Type Default <code>primaryColor</code> <code>primary-color</code> <code>Set primary colour</code> <code>string</code> `` <code>accentColor</code> <code>accent-color</code> <code>Set secondary or accent color</code> <code>string</code> ``"},{"location":"WP07/Portal/#how-to-use","title":"How To Use","text":""},{"location":"WP07/Portal/#portal_2","title":"Portal","text":"<p>To use the portal, first navigate to https://portal-frontend-zdzw.cloud.zdzw-project.com. After that, you will see the welcome page.</p> <p></p> <p>Next, you need to create a new organization account. To do this, click the \"Create an account\" option.</p> <p>Then, fill out all necessary information and click the \"Register\" option. Make sure the organization name does not contain the character '-'.</p> <p></p> <p>Once you have successfully created your account, you can log in to the portal and easily navigate between installed applications. When you first log in, you will see an empty applications list because you haven't purchased any applications yet.</p> <p></p> <p>Once the application is installed, the dashboard has two main sections: Cloud Applications and Other Applications. Cloud Applications are accessible through the portal, while Other Applications are deployable, downloadable, or locally licensed and cannot be accessed via the portal.</p> <p></p>"},{"location":"WP07/Portal/#organization-user-management","title":"Organization User Management","text":"<p>Now, an admin user can manage their organization's users. They can:</p> <ul> <li>Create new users with different roles</li> <li>Update existing users</li> <li>Delete users</li> </ul> <p>The following is the main page for managing users.</p> <p></p> <p>At the top-right corner, there is a \"Create New User\" button. Clicking it opens a popup dialog where you can enter the new user's details.</p> <p>While creating a user, you can Set a temporary password, which the user must reset upon their first login and Assign the desired roles to the user.</p> <p></p>"},{"location":"WP07/Portal/#api-key","title":"API KEY","text":"<p>To authenticate a third-party application with minimal configuration, you need a valid API Key. First, log in to the Portal application and navigate to the Developer page, which you can find at the bottom of the left-side navigation bar. On this page, you will see a section displaying your Organization ID along with your API Key.</p> <p></p> <p>Now you have a valid Organization ID and API Key. Therefore, to authenticate your application, simply send an API call to obtain a valid bearer token. Your API call should be as follows. Please replace your Organization ID and API Key with the appropriate values.</p> <pre><code>curl --location 'https://portal-api-zdzw.cloud.zdzw-project.com/developer/token' \\\n    --header 'org-name: \"YOUR_ORG_ID\"' \\\n    --header 'x-api-key: \"YOUR_API_KEY\"'\n</code></pre>"},{"location":"WP07/Portal/#additional-learning-materials","title":"Additional Learning Materials","text":""},{"location":"WP07/Usage-Traceability/","title":"Usage Traceability","text":""},{"location":"WP07/Usage-Traceability/#1-general-description","title":"1. General Description","text":"<p>The Usage Traceability represents the central communication layer between the Marketplace, the Assets (applications users) and the ZDZW Blockchain. It provides the following main functions:</p> <ul> <li>Provides zApps with a connection to the blockchain through the Traceability Gateway and the zApp usage tracking UI.</li> <li>Provides the marketplace, Traceability Gateway and the zApp usage tracking UI with the required backend to interact directly with the blockchain through an API.</li> <li>Manages smart contracts to track how much a ZDZW Inspection Solution has been used.</li> <li>Implements business logic to enable traceability of usage data and monetisation management.</li> <li>Stores on the ZDZW Blockchain the terms of the smart contract.</li> <li>Provides information to the Marketplace to trigger payments according to the terms implemented in the smart contract.</li> <li>Tracks and stores the usage of ZDZW applications by end users on the Blockchain (BaaS).</li> </ul>"},{"location":"WP07/Usage-Traceability/#2-top-ten-functionalities","title":"2. Top Ten Functionalities","text":"<ol> <li> <p>Establish a secure &amp; distributed database: The solution will store information regarding the acquisition, installation (if required), use and decommission of the zApps by different users in a distributed and secure manner. DLT-based technologies will be exploited for this purpose.</p> </li> <li> <p>Blockchain network management, deployment: The solution shall deploy and manage the chosen Blockchain platform.</p> </li> <li> <p>Blockchain integration with zApps and Marketplace: The solution will integrate the Marketplace with the traceability system, linking the Marketplace's zApps acquisition process with the Blockchain. It will also enable the Traceability Gateway to connect the installation and usage processes of the zApps with the Blockchain seamlessly. These integrations ensure secure storage and retrieval of usage data, creating a cohesive link between acquiring zApps and their traceability on the Blockchain.</p> </li> <li> <p>Integration flow runtime: The solution will enable a streamlined and dynamic integration flow runtime within the Traceability Gateway, allowing developers to manage data ingestion, processing, and Blockchain registration efficiently.</p> </li> <li> <p>Data ingestion, data transformation, and Blockchain registration functions: The solution will empower efficient data ingestion, seamless data transformation, and reliable Blockchain registration functions within the Traceability Gateway, ensuring a cohesive and effective integration process.</p> </li> <li> <p>Function palette management: The solution will facilitate comprehensive function palette management within the Traceability Gateway, offering developers a versatile toolkit to customise and optimise integration flows for zApps traceability.</p> </li> <li> <p>Integration flow management: The solution will enable effective integration flow management within the Traceability Gateway, allowing developers to efficiently organise and oversee the data flow for seamless zApps traceability.</p> </li> <li> <p>Integration flow edition user interface: The solution will provide an intuitive user interface for editing integration flows within the Traceability Gateway, ensuring a user-friendly experience for developers to customise and optimise the data flow for zApps traceability.</p> </li> <li> <p>Function palette management UI: The solution will feature a user-friendly interface for managing the function palette within the Traceability Gateway, offering developers a seamless experience in customising and optimising integration flows for zApps traceability.</p> </li> <li> <p>Provide Smart Contract Templates: The solution shall provide the templates for the deployed smart contracts that will manage the storage of zApps usage data.</p> </li> <li> <p>Manage Smart Contracts: The solution shall manage the smart contracts involved in the storage and retrieval of zApps data from the Blockchain platform. This includes their deployment, initialisation and querying.</p> </li> <li> <p>Storage Blockchain transactions: The solution shall store the zApps' usage data in transactions within the Blockchain platform so that it can be queried at a later stage.</p> </li> <li> <p>Request and Usage registration: The solution shall store information regarding when a zApp was acquired and under what conditions. It will also record data on when and where it is installed (if required), the dates and frequency of use, and when the zApp is decommissioned.</p> </li> <li> <p>Application Usage Tracking Visualisation (Every zApp a user owns) (Figure 2): Enables users to visually track and analyse the usage patterns and frequency of each zApp they own.</p> </li> <li> <p>Application Usage Tracking Visualisation (Specific zApp) (Figure 3): Offers a dedicated interface displaying detailed analytics and usage metrics of a particular zApp, aiding users in understanding its performance through interactive visual representations.</p> </li> </ol>"},{"location":"WP07/Usage-Traceability/#3-architecture","title":"3. Architecture","text":""},{"location":"WP07/Usage-Traceability/#31-diagram","title":"3.1. Diagram","text":"<p>Figure 1. Solution Architecture</p> <p>The solution requires data from other modules created in ZDZW, like the Marketplace. These modules (in grey in Figure 1) are external to those created in T7.4. However, they are represented in the figure to facilitate the understanding of how the T7.4 modules will be integrated with the rest of the ZDZW platform. Thus, the architecture of this task can be divided into three main subgroups:</p> <ul> <li>The zApp - Blockchain communication.</li> <li>The graphical interface.</li> <li>The backend manages the direct interaction with the Blockchain.</li> </ul> <p>zApp - Blockchain communication</p> <p>The Zapps use these components to store information about the installation (if necessary), usage and decommissioning of the apps. It consists of:</p> <ul> <li>Traceability Gateway: created by UPV. It is one of the modules with which the zApps interact directly. This component enables the integration of the modules designed in T7.4 with the Marketplace and the zApps. It provides Software Development Kits (SDKs) that developers can use in their backend solutions to integrate with the traceability solution, and a dedicated interoperability solution based on Node-Red. This traceability solution allows zApps developers to easily edit and manage integration flows to register zApp backend data into the Blockchain, using a dedicated integration flow runtime component. Integration flows normally combine data ingestion functions, data processing functions, and a Blockchain storage function to register new data in the Blockchain. Data processing functions allow ingesting data from backend services such as database services (relational or non-relational database), file systems (e.g. CSV or XML files), or messaging services (e.g. MQTT or AMQP brokers). Data transformation functions support the Blockchaintion of data to the specific JSON formatted data that the zApp will use to trace usability data. Finally, the Blockchain storage function facilitates the connection to the API Blockchain component.</li> <li>The API gateway, created by SAG. This module is external to the T7.4 task and its use is 'invisible' to the zapps. It manages user authentication, ensuring users can only access their organisation's data.</li> </ul> <p>Graphical interface</p> <ul> <li>The zApp usage tracking: This component, the 'visualisation' of usage data, is developed by AIMEN.</li> </ul> <p>Back end</p> <p>This component is the backend; it manages the data coming from the traceability gateway and the Marketplace, and it stores them in the Blockchain. It also delivers the data to the frontend for visualisation. This component is pure backend, and its use is only intended for the Marketplace, the Zapp usage tracking (UI) and the traceability gateway.</p> <ul> <li>Blockchain API: This service allows other modules to interact with the Blockchain, including all the necessary services for managing Smart Contracts and interacting with the services provided by AWS BaaS. Therefore, it will offer the necessary endpoints to the Marketplace to generate Smart Contracts for each purchase of a zApp. In addition, the API must also provide the necessary endpoints to store the transactions produced by the installation and/or use of a zApp. Finally, it must also handle requests coming from the zApp Traceability Monitoring.</li> <li>Smart Contract Management: This service manages Smart Contracts. It will store different types of Smart Contracts according to the conditions of use of the zApp. In addition, it will install, instantiate and execute a Smart Contract, as well as finish once the execution condition has expired.</li> <li>Traceability Data Management: This service manages the provisioning and storage of usage data for traceability. Whenever a zApp is used based on the usage condition selected in the Marketplace, this service will store the transaction in the Blockchain, and all requests for zApp usage will also be made through this module.</li> <li>Blockchain Network: The Blockchain service stores zApp usage information and Smart Contracts for each zApp purchase.</li> </ul>"},{"location":"WP07/Usage-Traceability/#32-smartcontract-life-cycle","title":"3.2. SmartContract Life Cycle","text":"<p>This section explains the SmartContract life cycle process and, for each phase, the sequence diagram between the different modules of the architecture. The life cycle of a SmartContract is directly correlated with the life cycle phases of an application available on the MarketPlace.</p> <p>The modules developed in this task work closely to trace the app's purchase, installation, use and decommission. Thus, to use the following modules correctly, it is crucial to understand the defined lifecycle for the purchased apps through the smart contracts IDs.</p> <p></p> <p>Figure 2. Application Life Cycle - SmartContract Life Cycle</p> <p>As the image shows, the different steps in the lifecycle of a purchased app are:</p> <ol> <li>Purchase. It must be done through the Marketplace.</li> <li>If on-premise, it must be installed. Uninstalled apps cannot be used, and if not installed, the pay-per-period business model cannot provide the Expiration Timestamp.</li> <li>Use.</li> <li>Renewal: This step is under development.</li> <li>Decommission. A decommissioned app cannot be used.</li> </ol> <p>Furthermore, in the pay-per-period model, there is an additional step invisible to the user called \"Activation\". If the app is on-premise, activation happens when the app is installed. If the app is on the cloud, activation happens when the app is used for the first time. The Activation step defines when the apps start to be used; thus, the purchased time starts running. This is when the Expiration Timestamp is also calculated.</p> <p>The compulsory phases to be able to use the applications are the following:</p> <ul> <li>On-premise application: purchase, installation, use, decommissioning.</li> <li>Cloud application: purchase, use, decommissioning.   The Renewal phase is an optional phase that can be taken when the application is still in use and the user/company wants to continue using it.</li> </ul> <p>The sequence diagram for each of the above phases has been further defined in the next sections.</p>"},{"location":"WP07/Usage-Traceability/#321-create-smartcontract","title":"3.2.1. Create SmartContract","text":"<p>The first phase is the purchase of the application, at which point the SmartContract associated with the purchase is created. A SmartContractID is also generated for its identification, which is used to access the contract data throughout its lifecycle. The sequence diagram of the SmartContract creation process is as follows:</p> <p> Figure 3. Create SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#322-install-smartcontract","title":"3.2.2. Install SmartContract","text":"<p>This phase differs depending on whether the application is purchased to run on-premise or in the cloud.</p> <ul> <li>If the Application is on-premise, the exact machine on which it will be installed is defined in this phase. In addition, if the app has been purchased under a pay-per-period, this phase is also the moment when it will be activated. Both the time of installation and activation are recorded on the Blockchain.</li> <li>This phase is unnecessary if the application is in the cloud. If the application has been purchased as a pay-per-period, its activation occurs during the first use.</li> </ul> <p></p> <p>Figure 4. Install SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#323-invoke-smartcontract","title":"3.2.3. Invoke SmartContract","text":"<p>Each time the application is used, the usage is stored in order to obtain a trace. For this purpose, the SmartContract must have been created and the application installed. If, in addition, the application is on-premise and is a pay-per-period, it has also been activated. If it is on-cloud, it will be activated during the first invoke.</p> <p>Each time an invoke is performed, in addition to the usage data (i.e. how many uses or when they happened), the timestamp of when that information has been stored in the blockchain is also recorded.</p> <p>In terms of how the invokes take place, if the application is automatic ( i.e., without user intervention), the Traceability Gateway is responsible for querying and sending the registration request to the Blockchain API. The other option is for the user to have a \u2018dash button\u2019 in their application. This button will send the registration request to the Blockcahin through the Traceability Gateway.</p> <p>The sequence diagram of the SmartContract invocation is as follows.</p> <p></p> <p>Figure 5. Invoke SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#324-query-smartcontract","title":"3.2.4. Query SmartContract","text":"<p>Once the application is running, there is the option to query the SmartContract to find out how many uses are registered, how many uses are left before the end of the contract or how many days are left before the contract expires. The sequence diagram for querying the SmartContract is as follows.</p> <p></p> <p>Figure 6. Query SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#325-renew-smartcontract","title":"3.2.5. Renew SmartContract","text":"<p>In the lifecycle of an application, the renewal phase is an optional phase that the user can perform to extend the lifecycle of the SmartContract. To do so, this renewal will be activated from the Marketplace. The terms and conditions of the renewal contract remain unchanged. For example, suppose that the initial contract had 50 uses; the renewal will be for an additional 50 uses, and if the contract was for 30 days, the renewal will be for another 30 days.</p> <p>The sequential diagram of the SmartContract renewal process is as follows.</p> <p></p> <p>Figure 7. Renew SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#326-block-smartcontract","title":"3.2.6. Block SmartContract","text":"<p>Once the contract expires, the application must block its runtime and notify that the contract is no longer in force. The Traceability gateway application will send the request to the Blockchain API to block the Smartcontract. This will indicate that, officially, the contract is no longer in force.</p> <p>However, this does not prevent users from using the application; instead, the application itself must block users from using it. If it does not do so, the Blockchain will register the uses, and the Marketplace will be able to bill these uses at the price set for this case. The sequence diagram of the SmartContract blockchain process is as follows:</p> <p></p> <p>Figure 8. Block SmartContract sequence diagram</p>"},{"location":"WP07/Usage-Traceability/#4-image-overview","title":"4. Image Overview","text":"<p>The usage tracking system interface is a tool designed to monitor and analyze the usage of smart contract-based applications in ZDZW. With a user-friendly interface, this system provides an intuitive overview of application usage, enabling users to gain actionable insights at a glance.</p> <p>Users can track the usage of the various applications they have purchased from the ZDZW Marketplace. The platform offers a summary of usage data, highlighting the most frequently utilized applications. By presenting this information visually, users can easily identify trends and prioritize their resources effectively.</p> <p></p> <p>Figure 9. Initial page for unauthenticated user</p>"},{"location":"WP07/Usage-Traceability/#41-traceability-gateway","title":"4.1. Traceability Gateway","text":"<p>The Traceability Gateway offers a user-friendly interface through Node-RED, providing a visual and intuitive way to configure integration flows for zApps traceability. Follow these steps to effectively use the Traceability Gateway:</p> <ol> <li> <p>Access the Node-RED Interface:    Open a web browser and navigate to <code>http://localhost:1880</code> or the specified host and port where Node-RED is running. This grants access to the Node-RED user interface.</p> </li> <li> <p>Explore the Node Palette:    On the left side of the interface, you'll find the node palette containing various nodes representing different functionalities tailored for different smart contract types.</p> </li> <li> <p>Drag and Drop Nodes:    Build integration flows by dragging nodes from the palette and dropping them onto the editing area. This allows you to visually design the flow of data for traceability within the ZDZW platform.</p> </li> <li> <p>Interconnect Nodes:    Connect nodes by drawing links between them to define the logical sequence of data processing. This interconnection forms the integration flow, ensuring a smooth transition of data from one node to another.</p> </li> <li> <p>Configure Nodes:    Double-click on each node to configure its parameters according to your specific use case. Configure settings such as connection details, data transformations, and other parameters required for traceability.</p> </li> <li> <p>Deploy Integration Flows:    Save your configured integration flows within Node-RED, and click the \"Deploy\" button. This action activates the changes and makes your integration flows operational, ready to handle zApps traceability data.</p> </li> <li> <p>Monitor Execution:    Use the Node-RED interface to monitor the execution of integration flows. The interface provides real-time feedback on the status of nodes, ensuring transparency in the data processing pipeline.</p> </li> <li> <p>Troubleshoot and Debug:    In case of issues, utilize the Node-RED interface to troubleshoot and debug integration flows. Examine logs, inspect node statuses, and make adjustments as needed to ensure smooth operation.</p> </li> <li> <p>Iterate and Improve:    Continuously iterate on your integration flows based on evolving requirements. Use the flexibility of the Node-RED interface to make improvements, add new nodes, or modify existing configurations for enhanced traceability.</p> </li> <li> <p>Save and Export Flows (Optional):     Save your integration flows as a project within Node-RED, allowing for easy retrieval and modification. Optionally, export flows for sharing with other developers or for backup purposes.</p> </li> </ol> <p>By following these steps, you can effectively use the Traceability Gateway through Node-RED, enabling seamless integration and management of zApps traceability within the ZDZW platform. Adjust configurations as necessary to meet specific traceability requirements.</p> <p>Although the Traceability Gateway is a backend module, it also incorporates an interface. Figure 11 shows the user interface of the traceability Gateway. The tool provides a toolkit of nodes that can be used to integrate backend functions. Some of the nodes include MQTT clients, TCP/IP clients, HTTP clients or servers, relational and non-relational database clients, CSV file readers, etc. Through the interface, users can drag a node and drop it in the edition area, and then interconnect nodes to build the integration logic with the Blockchain traceability nodes as a flow.</p> <p></p> <p>Figure 11. Traceability Gateway</p> <p>For example, users can integrate Node-RED with the Traceability Gateway and a SQL database, enabling them to orchestrate a robust and customizable workflow for efficient management of zApp usage data within the ZDZW platform. The visual representation of the flow not only simplifies the design process but also facilitates easy monitoring and maintenance of intricate integration processes. As depicted in Figure 12, the interconnected nodes and logical sequence provide a clear overview, empowering users to visualize and optimize their data processing pipeline effortlessly.</p> <p></p> <p>Figure 12. Traceability Gateway</p>"},{"location":"WP07/Usage-Traceability/#5-hardware-components","title":"5. Hardware Components","text":"<p>This does not apply to T7.4.</p>"},{"location":"WP07/Usage-Traceability/#6-computation-requirements","title":"6. Computation Requirements","text":"<p>The minimum and recommended CPU, RAM and storage requirements are as follows.</p>"},{"location":"WP07/Usage-Traceability/#61-traceability-gateway","title":"6.1. Traceability Gateway","text":"<p>The deployment of the Traceability Gateway is containerized using Docker, providing a convenient and isolated environment for efficient execution. Below are the specific computation requirements for the Traceability Gateway within a Dockerized deployment:</p> <ul> <li> <p>Processor (CPU): The Traceability Gateway Docker container is optimized for containerized environments and adapts well to varying CPU resources. A quad-core or higher processor is recommended for handling increased workloads and concurrent integration flows.</p> </li> <li> <p>Random Access Memory (RAM): Allocate a minimum of 8GB of RAM to the Docker container hosting the Traceability Gateway.</p> </li> <li> <p>Storage: Docker containers benefit from efficient storage utilization. Ensure the host system provides sufficient disk space for Docker images and containers. A minimum of 20GB of available disk space is recommended to accommodate configuration files, logs, and temporary data within the Traceability Gateway container.</p> </li> <li> <p>Operating System Compatibility: Docker containers offer platform-agnostic deployment. The Traceability Gateway Docker image is compatible with various operating systems. Users can deploy the Docker container on Linux, Windows, or macOS systems that support Docker. Ensure that the host system has Docker installed and configured.</p> </li> </ul> <p>By considering these computation requirements in a Dockerized environment, users can optimize the Traceability Gateway deployment, leveraging containerization's benefits for efficient integration and management of zApps traceability within the ZDZW platform.</p>"},{"location":"WP07/Usage-Traceability/#62-usage-tracking-visualization","title":"6.2. Usage tracking Visualization","text":"<p>The Usage Tracking Visualization is a web application that uses the Angular framework to display data and charts. It runs inside a Docker container, which makes it easy to deploy and manage. To run the Usage Tracking Visualization, a server with Docker installed will be needed, as well as hardware of at least 2 CPU cores and 4 GB of RAM for optimal performance.</p>"},{"location":"WP07/Usage-Traceability/#63-blockchain-platform","title":"6.3. Blockchain Platform","text":"<p>These computation requirements for the blockchain pertain to those needed for its deployment during the development phase of ZDZW. They do not apply to production or the computational requirements for partners using solutions created in T7.4.</p> <p>The BAAS platform chosen is the one provided by AWS. Using AWS to deploy a Blockchain network requires combining several of its products. Therefore, it must be ensured that all of them are available in the AWS region being used. We will use Ireland, <code>eu-west-1</code>, which ensures that the data is on EU soil.</p> <p>Thus, Amazon Managed Blockchain (AMB) has been leveraged to create a private Blockchain network based on Hyperdledger Fabric. AMB can be used to create the Hyperledger network, the members, and their peers. However, this service needs Fabric clients to interact with the network (created using the AWS service EC2), connection management and traffic control (created using the AWS VPC). An overview of the configuration is presented in Figure 13.</p> <p></p> <p>Figure 13. AWS Hyperledger Deployment</p> <p>For this configuration to be successful, there are minimum requirements that both the peer nodes and the client fabric must meet.</p> <ul> <li>The Blockchain instance type of the peer node must be at least of type <code>bc.t3.small</code>.</li> <li> <p>The EC2 instance containing the Fabric Client must be at least of type <code>t3.medium</code> and must be given a storage capacity of at least 20 GiB. Furthermore, when configuring the EC2 instance, the Amazon Machine Image (AMI) must be chosen, which, in the case of the instance for the Fabric client, must be Amazon Linux. Moreover, among the available images, Amazon Linux 2023 AMI 2023.1.20230825.0 x86_64 HVM kernel-6.1 and 64-bit architecture have been chosen. Finally, to finish configuring the EC2 instance, it is necessary to ensure that the EC2 instance has all the necessary packages, such as Docker, Docker-compose, or Golang. The required versions of those packages are:</p> </li> <li> <p>Docker\u201317.06.2-ce or later</p> </li> <li> <p>Docker-compose\u20131.14.0 or later</p> </li> <li> <p>Go\u20131.14.x</p> </li> </ul> <p>Note: The Deployment Annex provides more information and details about the requirements.</p>"},{"location":"WP07/Usage-Traceability/#7-installation-procedure","title":"7. Installation Procedure","text":"<p>Step by step on how to install the application:</p> <ul> <li>Standalone</li> <li>In the Kubernetes platform using helm charts: description of the different options</li> </ul>"},{"location":"WP07/Usage-Traceability/#71-traceability-gateway","title":"7.1. Traceability Gateway","text":"<p>To deploy the Traceability Gateway using Docker Compose from the provided Git repository and Helm charts for Kubernetes (to be released in the future), follow these steps:</p> <ol> <li>Clone the Git Repository:</li> </ol> <pre><code>git clone https://github.com/zdzw-eu/traceability-gateway.git\n</code></pre> <ol> <li>Navigate to the Repository Directory:</li> </ol> <pre><code>cd traceability-gateway\n</code></pre> <ol> <li> <p>Configure Docker Compose (Optional):    Modify the <code>docker-compose.yml</code> file if specific configurations are required, such as adjusting ports or volumes.</p> </li> <li> <p>Build and Start the Docker Containers:</p> </li> </ol> <pre><code>docker-compose up -d\n</code></pre> <p>This command builds and starts the Traceability Gateway Docker containers in detached mode.</p> <ol> <li> <p>Access the User Interface:    Open a web browser and navigate to <code>http://localhost:1880</code> to access the Node-RED user interface.</p> </li> <li> <p>Configure Integration Flows:    Utilize the Node-RED interface to design and manage integration flows. Customize nodes, interconnect them, and configure each node based on your integration requirements.</p> </li> <li> <p>Save and Deploy Flows:    Save your integration flows within Node-RED, and click the \"Deploy\" button to activate the changes. This ensures that your configured flows are ready for execution.</p> </li> <li> <p>Monitor Logs:    Monitor the container logs for any potential issues or debug information. Use the following command to view logs:</p> </li> </ol> <pre><code>docker-compose logs -f\n</code></pre> <ol> <li>Shutdown the Containers:    When needed, stop and remove the Traceability Gateway containers:</li> </ol> <pre><code>docker-compose down\n</code></pre> <p>By following these steps with Docker Compose, you can deploy the Traceability Gateway from the specified Git repository, facilitating seamless integration and management of zApps traceability within the ZDZW platform. Adjust configurations as necessary for your specific deployment environment and requirements.</p> <p>*Note for Kubernetes Users: Helm charts for deploying the Traceability Gateway on Kubernetes are currently under development and will be released in the future. Stay tuned for updates on Helm chart availability. Adjust configurations as necessary for your specific deployment environment and requirements.*</p>"},{"location":"WP07/Usage-Traceability/#72-usage-tracking-visualization","title":"7.2. Usage tracking Visualization","text":"<p>To deploy the Tracking Web Application, a Helm chart has been configured for a simplified installation process. The Helm chart facilitates the deployment and management of the application on Kubernetes, ensuring that all necessary resources, such as services, pods, and ingress configurations, are correctly set up. Once the Helm chart is applied, the application will be accessible, allowing users to securely track their smart contract usage.</p>"},{"location":"WP07/Usage-Traceability/#73-blockchain-platform","title":"7.3. Blockchain Platform","text":"<p>This installation procedure for the blockchain pertains to that needed for its deployment during the development phase of ZDZW. It does not apply to production or any installation required for partners using solutions created in T7.4.</p> <p>Once the minimum configuration explained in section 6.3 has been set up, connections to the Blockchain network can be established. For the first connection, the following are required:</p> <ul> <li>A Blockchain network.</li> <li>A channel within this network.</li> <li>An EC2 instance.</li> <li>The security zones explained in section 6.1 to be correctly configured.</li> </ul> <p>For a successful first connection from a local computer, it is necessary to have:</p> <ul> <li>The private key used during the creation of the VPCs.</li> <li>The public IP of the computer from which we are connecting.</li> <li>The public DNS of the instance.</li> </ul> <p>To control incoming traffic to the EC2 instance, the public IP of the local machine will be permitted to connect to the VPC. Once permissions are granted, using SSH and the public DNS of the instance, it is possible to connect to the instance remotely.</p> <p>Once on the instance, make sure the Docker container containing the fabric client is running:</p> <pre><code>docker-compose -f docker-compose-cli.yaml up -d\n</code></pre> <p>Once the fabric client is up, packages can be installed and uninstalled in the instance like in a regular Ubuntu machine. As far as the installation and deployment of Smart contracts are concerned, this is done via dockerized .go scripts. A detailed explanation can be found in the Annex.</p>"},{"location":"WP07/Usage-Traceability/#8-how-to-use","title":"8. How To Use","text":""},{"location":"WP07/Usage-Traceability/#81-traceability-gateway","title":"8.1. Traceability Gateway","text":"<p>Traceability Gateway Project is used to demonstrate the integration of different systems in a single gateway. It enables the use of different data protocols, databases and technologies together under the same framework.</p> <p>The integration architecture is depicted in Figure 14 for the solution provider partners. It shows the different data pipeline possibilities that enable seamless integration with each zApp solution by considering their working technology and provide connection to the existing Blockchain technology deployed for traceability purposes.</p> <p></p> <p>Figure 14. Keycloack API Keys</p>"},{"location":"WP07/Usage-Traceability/#811-keycloack-authentication-nodes","title":"8.1.1 Keycloack Authentication Nodes","text":"<p>Before using the Traceability Gateway, the Keycloak authentication flow must be run first. This flow will enable developers to authenticate their organization for future Smart Contract usage, installation and Blockchain use.</p> <p>To properly configure this flow, the user must first:</p> <ul> <li> <p>Access the Web Portal and Log In or Create an Account if you don't have any: https://portal-frontend-zdzw.cloud.zdzw-project.com</p> </li> <li> <p>Once successfully logged in, access the dashboard and click the developer tab on the bottom left part of the screen.   The following API keys are used to validate your profile in the Node-RED microservice in order to enable access to the Blockchain traceability functions.</p> </li> </ul> <p></p> <p>Figure 15. Keycloack API Keys</p> <p>Once we have our API Key values, the authentication flow in Node-RED needs to be configured. This flow will enable access to the token variable globally. For that purpose, our flow will make the request via HTTP and store the variable as <code>global.token</code></p> <p></p> <p>Figure 16. Keycloack Node-RED Authentication Flow</p> <p>The HTTP request needs to be done with the following configuration:</p> <pre><code>URL: https://portal-api-zdzw.cloud.zdzw-project.com/developer/token\norg-name: 'Prueba'\nx-api-key: '143883a3ec5b269cece6bc3672e202c9a3f55a213095ef8ce2b6b193751af05d'\n</code></pre> <p>Note: <code>org-name</code> and <code>x-api-key</code> are values provided for each organization successfully registered (as in Figure 17)</p> <p></p> <p>Figure 17. Keycloack HTTP Request</p> <p>Once the HTTP request is configured, the <code>msg.payload</code>, which acts as the token variable, needs to be assigned, saved and stored as <code>global.token</code>. This makes the variable fully accessible in the Node-RED microservice.</p> <p></p> <p>Figure 18. Keycloack 'set.global.token' configuration</p> <p>For recurrent use, the variable can be easily accessed by using the 'Read Token Global' node. This node will provide the global variable as a <code>msg.payload</code>. Users can confirm that the token is successfully stored and accessed using the proposed flow.</p> <p></p> <p>Figure 19. Keycloack 'Read Token Global' configuration</p> <p>That's it, your microservice is now properly configured and linked to your organization.</p>"},{"location":"WP07/Usage-Traceability/#82-blockchain-nodes","title":"8.2. Blockchain Nodes","text":"<p>Custom Blockchain nodes have been prepared based on ZDZW zApp and Marketplace. These nodes will enable ZDZW zApps to communicate with Smartcontracts and Blockchain service providers. For that purpose, a series of nodes have been created to communicate with the Blockchain. Based on this premise, the nodes have been created according to the parameters described in the Blockchain Platform description in Section 8.1. All Blockchain nodes are already generated and installed by default in the Node-RED microservice. The nodes can be seen on the left side of the menu in Figure 20 and Figure 21, and the return information is visualized in the debug right part of the screen in Figure 20 and Figure 21, providing a success message when the request has been performed correctly.</p> <p></p> <p>Figure 20. Blockchain Nodes Pipeline and Node RED UI</p> <p>It must be noted that two types of nodes (GET for reading and INVOKE for writing) are included in this microservice:</p> <ul> <li>GET Nodes: These nodes allow reading operations on the Blockchain provider to obtain information from specific Smart Contracts (Figure 22) or zApps (Figure 23)</li> </ul> <p></p> <p>Figure 21. Smart Contract Blockchain Nodes</p> <p></p> <p>Figure 22. zApp Blockchain Nodes</p> <p>Depending on the GET Smart Contract node selected certain Input Data (Figure 23 and Figure 24) will be required (<code>SmartContract ID</code>, <code>User ID</code>, <code>Machine ID</code>...). This information is readily available in the smart contract once the purchase has been executed from ZDZW Marketplace.</p> <p></p> <p>Figure 23. Smart Contract ID Input Data</p> <p></p> <p>Figure 24. User ID Input Data</p> <p>It works similarly when reading zApp Blockchain information. Input Data will be needed in order to receive a true response from our nodes (Figure 25)</p> <p></p> <p>Figure 25. zApp Input Data</p> <ul> <li>INVOKE Nodes: These nodes allow writing operations on the Blockchain provider to update, set or create new data related to specific Smart Contracts or zApps.</li> </ul> <p>When using nodes for creating new Smart-Contracts the node can be used as seen in Figure 26:</p> <p></p> <p>Figure 26. Smart Contract Creation</p> <p>Note that the Input Value <code>Functionalities</code> must be provided when creating a new Pay Per Use (PPU) Smart Contract, and the Input Value <code>Days</code> must be provided when creating a new Pay Per Period (PPP) Smart Contract:</p> <ul> <li><code>Invoke Init</code> Node is typically used when needing to INSTALL a zApp on a custom-name industrial equipment.</li> <li><code>Invoke Info</code> Node is used to register/update uses of certain custom-name equipment in the Blockchain.</li> </ul> <p>When the Input information required (Figure 27,Figure 28 ) is correct, <code>true</code> data response for usage registration or <code>initTrue</code> when initializing the app will be shown as in Figure 29.</p> <p></p> <p>Figure 27. zApp Invoke Input Data (1)</p> <p></p> <p>Figure 28. zApp Invoke Input Data (2)</p> <p></p> <p>Figure 29. zApp Invoke Nodes</p>"},{"location":"WP07/Usage-Traceability/#821-blockchain-pay-per-volume-ppv-example","title":"8.2.1 Blockchain Pay Per Volume (PPV) Example","text":"<p>This section describes the Node-RED flow and Gateway Nodes for managing the Pay Per Volume (PPV) use case when using Blockchain-based smart contracts.</p> <p>If the Smart Contract is CLOUD based, it does NOT need to be initialized/installed on factory equipment. The GetUserInfo and GetAllInfo nodes will provide this information so:</p> <ul> <li>MachineID: <code>unknow</code>, needs to be initialized on industrial equipment by providing a MachineID (i.e. Custom_Inspection_Equipment)   [Include an image with the result]</li> <li>MachineID: <code>cloud</code>, it is ready to be used.   [Include an image with the result]</li> </ul> <p>The following flow examples include retrieving information about the current state of a purchased Smart Contract, installing a Smart Contract on a specific machine and registering uses associated with the Smart Contract in the Blockchain. The flow structure is divided into three main sections:</p> <ol> <li>Retrieving Smart Contract State Information</li> <li>Initializing and Installing a zApp Smart Contract on a factory Machine</li> <li>Registering Uses on the PPV Smart Contract</li> </ol> <p></p> <p>Figure 30. Pay Per Volume Example</p> <p>1. Retrieving Smart Contract State Information</p> <p>This section contains nodes that retrieve user information and smart contract details, allowing for a comprehensive view of the current contract state. Nodes Involved:</p> <ul> <li>Get User Info: Retrieves the user information associated with the contract.</li> <li>Get All Info: Gathers all relevant data related to the smart contract.</li> <li>Get Init Info: Provides the initial information for the contract.</li> </ul> <p>Flow Execution for this operation:</p> <ul> <li>Each node is triggered by a timestamp node to manually start the process and obtain information regarding the subcontract.</li> <li>This flow will provide the main information, whther it is already installed and the usage it has been subject to.</li> </ul> <p></p> <p>Figure 31. Pay Per Volume zApp Usage Registration</p> <p>2. Initializing and Installing a zApp on a Machine</p> <p>This section configures and installs a zApp on a designated machine by associating it with a unique Machine ID on the smart contract. Nodes Involved:</p> <ul> <li>Get User Info: Retrieves the necessary user information for installing the zApp.</li> <li>Invoke Init: Initializes the zApp Smart Contract installation on the machine.</li> </ul> <p>Flow Execution for this operation:</p> <ul> <li>The zApp initialization on the machine completes by registering the Machine ID with the smart contract ID.</li> </ul> <p></p> <p>Figure 32. Pay Per Volume zApp Installation on Machine</p> <p>3. Registering Usage on the Pay Per Volume Smart Contract</p> <p>This section registers each usage instance of the zApp on the Blockchain under the Pay Per Volume model. Nodes Involved:</p> <ul> <li>Invoke Info: Invokes information regarding registered usage on the Blockchain.</li> </ul> <p>Flow Execution for this operation:</p> <ul> <li>Both Invoke Info are activated through a timestamp node (could be activated by an inspection result, material consumption or length run).</li> <li>The output is sent to notification nodes (Discount Uses and Init Message) to confirm successful registration on the Blockchain.</li> </ul> <p></p> <p>Figure 33. Pay Per Volume zApp Usage Registration</p>"},{"location":"WP07/Usage-Traceability/#822-blockchain-pay-per-use-ppu","title":"8.2.2 Blockchain Pay Per Use (PPU)","text":"<p>This section describes the Node-RED flow and Gateway Nodes for managing the Pay Per Use (PPU) use case when using Blockchain-based smart contracts.</p> <ul> <li>The first Block provides general information regarding a Smart Contract, such as Functionalities available, initialization information and usage registration.</li> <li>Second block provides information regarding the zApp Smart Contract installation on industrial equipment.</li> <li>Third block is an example of the Usage registration for a certain functionality.</li> </ul> <p></p> <p>Figure 34. Pay Per Use Example</p> <p>Due to the nature of Pay Per Use, the Functionality of the usage must be provided for adequate billing. The functionality is defined on the Smart Contract; when using the <code>GetInitInfo</code> Node, the user will obtain information regarding acceptable uses for traceability purposes. As can be seen in Figure 35, the functionalities accepted by this Smart Contract are 'ANALYSIS', 'PREDICTION' and 'MODEL'.</p> <p></p> <p>Figure 35. Pay Per Use (PPU) Functionalities Available</p> <p><code>Invoke Init</code> node is used for zApp initialization. They need the arguments <code>SmartContract ID</code>, <code>MachineID</code> (i.e. Custom Industrial equipment name) and <code>InitTime</code> (in UTC format).</p> <p>Figure 36. Smart Contract Example 'HSO_Aero_VisualAnalysis_v0.2_ppu_2' is installed in the 'Custom_MachineName_4' equipment:</p> <p></p> <p>Figure 36. Pay Per Use (PPU) zApp Initialization on a Machine</p> <p><code>Invoke Info</code> nodes for zApp usage registration need the arguments <code>SmartContract ID</code>, <code>Uses Count</code>, <code>InitTime</code> (in UTC format), and <code>FunctionalityName</code> to be included. In the previous example, the Smart Contract functionalities are 'ANALYSIS', 'PREDICTION' and 'MODEL'. An 'ANALYSIS' use is registered in the Smart Contract as can be seen in Figure 37.</p> <p></p> <p>Figure 37. Pay Per Use (PPU) zApp Invoke Init Node Usage</p> <p>When the Invoke function has been successfully deployed, a confirmation <code>true</code> message will be received by the user. This payload confirms that the Blockchain insertion has been performed correctly as can be seen in Figure 38.</p> <p></p> <p>Figure 38. Pay Per Use (PPU) zApp Invoke Info Node Usage</p> <p>Note: In case the Smart Contract is CLOUD based, it does NOT need to be initialized/installed on factory equipment.</p> <p>The following flow examples include simple operations such as:</p> <ol> <li>Retrieving information about the current state of a purchased Smart Contract.</li> <li>Installation of a Smart Contract on a specific machine.</li> <li>Blockchain use registration associated with the PPU Smart Contract.</li> </ol> <p>1. Retrieving information about the current state of a purchased Smart Contract.</p> <p>For retrieveing information about a PPU Smart Contract, the <code>GetInit</code> Node is used. Note that <code>GetAllInfo</code> and <code>GetUserInfo</code> Nodes are NOT available for this PPU use-case. For Usage monitoring, there are specific nodes: <code>Get All Info Functionality</code> and <code>Get Period Functionality</code>.</p> <p>The first one, <code>Get All Info Functionality</code>, provides all the historical data of a Smart Contract Usage registration for a certain Functionality and a certain period of time. As can be seen in the flow below, the historical data regarding the 'ANALYSIS' functionality is provided (Figure 39.)</p> <p></p> <p>Figure 39. Pay Per Use (PPU) zApp Get All Info Functionality Node Usage</p> <p>The second node, <code>Get Period Functionality</code>, provides only the last USE information regarding a certain functionality and for a certain period of time. In Figure 40. can be seen the Input data required and the output message with the information regarding the ANALYSIS functionality.</p> <p></p> <p>Figure 40. Pay Per Use (PPU) zApp Get Period Functionality Node Usage</p> <p>Both of these Nodes <code>Get All Info Functionality</code> and <code>Get Period Functionality</code> provide the information based on the functionality type. For instance, considering the previously used Smart Contract, historical data for the 'ANALYSIS', 'PREDICTION' or 'MODEL' can be provided as can be seen in Figure 41.</p> <p></p> <p>Figure 41. Pay Per Use (PPU) zApp Functionality Uses</p> <p>The <code>GetInit</code> Node should provide a message with the initialization information that specifies the installation (or purchase date if not installed yet) of a Smart Contract, as shown in Figure 42.</p> <p></p> <p>Figure 42. Pay Per Use (PPU) zApp Get Init Node Usage</p> <p>In case the Smart Contract is not installed yet, and the user is trying to access it, the following error is returned as in Figure 43. This error <code>app is not installed yet</code> indicates that the SmartContract needs to be installed on a MachineID in order to start using it according to the flow in section 2 below.</p> <p></p> <p>Figure 43. Pay Per Use (PPU) zApp Init Error</p> <p>2. Installation of a Smart Contract on a specific machine</p> <p>By using the <code>Invoke Init</code> Node and passing the arguments <code>SmartContract ID</code> and <code>MachineID</code> (i.e. Custom_MachineName_4) the Smart Contract is initialized in the equipment (Figure 44.)</p> <p></p> <p>Figure 44. Pay Per Use (PPU) zApp Init Parameters</p> <p>When the SC is successfully initialized, a confirmation message is returned <code>initTrue</code> (Figure 45.)</p> <p></p> <p>Figure 45. Pay Per Use (PPU) zApp Init Confirmation message</p> <p>Our SC is ready to be used in the 'Custom_MachineName_4'. For confirmation, please check with the <code>GetInit</code> Node the SC status. Both activation date and functionalities are returned. In the example below the Pay Per Use (PPU) functionality alternatives available are: 'ANALYSIS', 'PREDICTION' and 'MODEL' and the <code>Operation</code> field is confirmed as <code>Installation</code> on the <code>MachineID</code> selected (Figure 46.).</p> <p></p> <p>Figure 46. Pay Per Use (PPU) zApp Installation Confirmation</p> <p>3. Blockchain use registration associated with the PPU Smart Contract .</p> <p>In order to use the Pay Per Use (PPU) Smart Contract, the functionality field must be provided. For a certain use registration, the node Invoke Info is used.</p> <p>Considering the previous example, the functionality to be provided will be one of the fields mentioned: 'ANALYSIS', 'PREDICTION' or 'MODEL'.</p> <p></p> <p>Figure 47. Pay Per Use (PPU) zApp Functionality Parameters</p> <p>In case the User Registration has been successfully integrated into the Blockchain registry, the following confirmation message will appear.</p> <p></p> <p>Figure 48. Pay Per Use (PPU) zApp Use Registration Confirmation</p> <p>In case the functionality provided is not available/wrong for the purchased SC, the component will provide the following error message:</p> <p></p> <p>Figure 49. Pay Per Use (PPU) zApp Use Registration Error</p>"},{"location":"WP07/Usage-Traceability/#823-blockchain-pay-per-period-ppp","title":"8.2.3 Blockchain Pay Per Period (PPP)","text":"<p>This section describes the Node-RED flow and Gateway Nodes for managing the Pay Per Period (PPP) use case when using Blockchain-based smart contracts.</p> <ul> <li>These contracts provide unlimited usage of a certain zApp for a limited amount of time that is expressed in days.</li> <li> <p>The number of Uses registered is accumulated per each iteration with the SC and registered in the variable 'AccumUses'.</p> </li> <li> <p>The first Block provides general information regarding a Smart Contract, such as Functionalities available, initialization information and usage registration.</p> </li> <li>Second block provides information regarding the zApp Smart Contract installation and usage on industrial equipment.</li> </ul> <p></p> <p>Figure 50. Pay Per Period (PPP) zApp Basic Blocks</p>"},{"location":"WP07/Usage-Traceability/#8231-cloud-zapp-pay-per-period-ppp","title":"8.2.3.1 Cloud zApp Pay Per Period (PPP)","text":"<p>In case the Smart Contract is CLOUD based, it does NOT need to be initialized/installed on factory equipment. The <code>GetAllInfo</code> node will provide all the SC information:</p> <ul> <li>MachineID: <code>cloud</code>, it is ready to be used.</li> </ul> <p>The <code>GetInitInfo</code> node will send an error indicating it cannot be installed due to its CLOUD nature. </p> <p>Figure 51. Pay Per Period (PPP) CLOUD zApp response</p> <ul> <li>MachineID: <code>cloud</code>, it is ready to be used.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8232-onprem-zapp-pay-per-period-ppp","title":"8.2.3.2 Onprem zApp Pay Per Period (PPP)","text":"<p>In case the Smart Contract is deployed as ONPREM, it does NEED to be initialized/installed on factory equipment.</p> <p>The <code>GetAllInfo</code> node will provide all the SC information:</p> <ul> <li>MachineID: <code>unknow</code>, needs to be initialized on industrial equipment by providing a <code>MachineID</code> (i.e. Custom_Inspection_Equipment)</li> </ul> <p>The <code>GetInitInfo</code> node will send an error indicating it cannot be installed due to its ONPREM nature. An error indicating that the equipment needs to be initialized is returned by GetInitInfo node.</p> <p></p> <p>Figure 52. Pay Per Period (PPP) ONPREM zApp response</p> <p>To avoid this error, user must INSTALL the Smart Contract to a factory equipment by assigning a Machine ID to it as shown in Figure: 53:</p> <p></p> <p>Figure 53. Pay Per Period (PPP) ONPREM zApp Machine Installation</p> <p>After the SC has been successfully installed on the Device (i.e.: MIROCT_3D) a initTrue message shsould appear as shown in Figure: 54</p> <p></p> <p>Figure 54. Pay Per Period (PPP) Success Initialization Message</p> <p>Now the <code>GetInitInfo</code> node will provide the information regarding the installation as shown on Figure: 55 This information contains details about the installation date as well as the Machine ID to which the SC has been installed.</p> <p></p> <p>Figure 55. Pay Per Period (PPP) Get Init Info Message</p> <p>Now our Smart Contract is ready to be used and to track some usage. When user invokes the <code>InvokeInfo</code> node, data is saved in the Blockchain and a 'true' message as shown in Figure 56 will be shown.</p> <p></p> <p>Figure 56. Pay Per Period (PPP) Sucess Usage Message</p> <p>NOTE: When the period has expried, the <code>InvokeInfo</code> node porvidesthe folowing message indicating that the data has been stored but the contract is no longer active as can be seen in Figure 57.</p> <p></p> <p>Figure 57. Pay Per Period (PPP) Expired SC Usage Message</p>"},{"location":"WP07/Usage-Traceability/#83-traceability-gateway-use-case-nodes","title":"8.3. Traceability Gateway Use Case Nodes","text":"<p>In the ZDZW project, there are several zApps that encompass different data communication and connection methods, including TCP/IP, MQTT, OPC-UA, and custom-based APIs. Also, the data storage is different according to the selected solution and use-case application, including relational and non-relational databases that are located locally or in the cloud. Several ZDZW zApp use cases are presented to developers to clarify and enlighten the potential Node-RED can have on data management.</p>"},{"location":"WP07/Usage-Traceability/#831-av-ai-based-qc-zapp","title":"8.3.1 AV AI-based QC zApp","text":"<p>In the ZDZW framework of action our Artificial Vision Artificial Intelligence Quality Control is based upon custom computer vision models that are easily deployed in industrial facilities. This zApp tool will help to tailor-made vision algorithms for custom inspection services. By implementing this zApp, Users will gain control to customize state-of-the-art models that will ease and optimize the inspection process during QA/QC procedures.</p> <p>For that purpose, the AV AI-based QC zApp solution relies on image inference for anomaly detection. Batch images are sent to the zApp for anomaly detection, the inference result is saved in a non-realtional database which is MongoDB that is located locally or in the cloud. This data is typically saved in JSON format:</p> <pre><code>{\n  \"_id\": {\n    \"$oid\": \"665f2a5da771ee83d31a96ee\"\n  },\n  \"_cls\": \"InferenceDocument.InferenceDetectionDocument\",\n  \"name\": \"Inference 2024-06-04\",\n  \"created\": {\n    \"$date\": \"2024-06-04T14:53:17.441Z\"\n  },\n  \"modified\": {\n    \"$date\": \"2024-06-04T14:51:03.205Z\"\n  },\n  \"company\": \"VSYS\",\n  \"user\": \"mdelpin\",\n  \"training\": {},\n  \"status\": {\n    \"state\": \"COMPLETED\",\n    \"metrics\": {\n      \"total_time\": 87.80523338720177,\n      \"avg_preprocess_time\": 2.101826365625368,\n      \"avg_inference_time\": 32.55792443797048,\n      \"avg_postprocess_time\": 0.41774154704422317,\n      \"avg_img_time\": 33.30982760065764\n    }\n  },\n  \"images\": [\n    {\n      \"_cls\": \"InferenceDetectionImageDocument\",\n      \"name\": \"167612_3754_20240105_223025_028.jpg\",\n      \"processed\": true,\n      \"results\": [\n        {\n          \"class_index\": 0,\n          \"confidence\": 0.6938128689144347,\n          \"x\": 0.4442461876577044,\n          \"y\": 0.170319901118551,\n          \"w\": 0.7542081040197404,\n          \"h\": 0.7598171420591529\n        },\n        {\n          \"class_index\": 0,\n          \"confidence\": 0.9486363012441077,\n          \"x\": 0.10568511120992286,\n          \"y\": 0.1907250650376784,\n          \"w\": 0.1497690740691806,\n          \"h\": 0.791912658254414\n        }\n      ]\n    }\n  ],\n  \"parameters\": {\n    \"_cls\": \"InferenceDetectionParametersDocument\",\n    \"mode\": \"best\",\n    \"size\": 640,\n    \"max_detections\": 100\n  },\n  \"results_meta\": {\n    \"class_names\": [\n      \"Hole\",\n      \"Septum\"\n    ],\n    \"class_colours\": [\n      \"#f4cd92\",\n      \"#61b4d8\"\n    ]\n  }\n}\n</code></pre> <p>Our Node-RED microservice allows developers to easily connect to the local/cloud non-relational database to store the inference result of the images. For that purpose, the Node-RED microservice contains MongoDB nodes that can be configured in each scenario for a seamless connection. To enable the connection on this node for data insertion, it must be configured according to Figure 41. and Figure 42.</p> <p>In Figure 41, the connection string to the database must be specified, the mode or operation type (collection or database operation), the collection or database name upon which this operation will be performed, and the operation to be performed in the pipeline. The example provided specifies the inference of an on-poem device performing inferences on an industrial scenario. The <code>insertOne</code> operation has been selected as an example for that purpose.</p> <p>Common collection operations are <code>find</code>, <code>findOne</code>, <code>insertOne</code>, <code>insertMany</code>, <code>updateOne</code>, <code>updateMany</code>, <code>deleteOne</code>, <code>deleteMany</code>, <code>aggregate</code> and more.</p> <p></p> <p>Figure 50. MongoDB Node Camera Inference Connection</p> <p>Our Figure 50 shows advanced options in the MongoDB node. These options relate to the user management on the local/cloud database and help provide limited Read/Write access to certain users when developing new pipelines in the Node-RED microservice.</p> <p></p> <p>Figure 51. MongoDB Node Input Data</p> <p>Once our Camera Inference Pipeline is ready, our zApp application will allow us to save/read/write data in our local/cloud non-relational database. If the camera communication protocol changes from default, the pipeline can be easily updated by importing any widely used protocol nodes (TCP/IP, OPC-UA or MQTT) to the flow.</p> <p>When the database connection is set, and the equipment is connected, it is time to implement and deploy the Blockchain nodes that provide traceability to the process. For that purpose, the proposed pipeline will provide robustness mechanisms against data corruption. The pipeline shown in Figure 43 provides a mechanism that checks whether new data have been inserted into the non-relational database (new uses or inspections have taken place); in case new uses are registered, the Blockchain is updated with the date, time and number of uses are discounted from the total. This tool can help to provide robustness in inspection operations when no internet connection (or connection is lost) with the inspection equipment.</p> <p></p> <p>Figure 52. MongoDB and Blockchain robustness mechanism</p> <p>Figure 53 and Figure 54 show both scenarios in the pipeline, scenarios in which new uses are detected and inserted in the Blockchain and when NO new uses are detected by the pipeline, respectively. Considering this pipeline, both INVOKE (writing) and GET (read) Blockchain nodes are included in the pipeline. The pipeline can be set to be run periodically, providing custom needs in terms of Blockchain traceability.</p> <p></p> <p>Figure 53. New Uses detected</p> <p></p> <p>Figure 54. No New Uses detected</p> <p>The pipeline shown above is only an example of the mechanisms that can be easily integrated into our AV AI-based QC zApp. This tool can help developers to gain valuable insights, develop new robustness pipelines and ensure Blockchain traceability integration with the specific zApp connection methods.</p>"},{"location":"WP07/Usage-Traceability/#8311-welding-inspector-zapp","title":"8.3.1.1 Welding Inspector zApp","text":"<p>The Welding Inspector zApp relies on the information provided by the Electro-Magnetic Acoustic Transducer (E-MAT) equipment. Our Node-RED microservice comes preconfigured to enable communication with the equipment according to the protocols defined by Innserpec.</p> <p>There are two main modes in which the equipment communication with the microservice can be carried out which are via TCP/IP protocol and through the custom API provided by Innerspec. Both methods are already preconfigured in our Node-RED microservice with the port configuration (for TCP/IP protocol) and API calls (for the custom API) according to Innerspec documentation.</p> <ul> <li>TCP/IP: The communication relies on the client/server configuration depending on the Inspection mode selected.   All the ports can be customized to be in the range of 1000 to 65535 (expect ports 3000, 4000, 7001, 8000, 9000 and 9001).</li> </ul> <p>There are three (3) modes by default on the E-MAT equipment. Test mode (testing purposes) is by default on port 5000, Scan mode (calibration purposes) in port 2000 and Inspection mode (pay per use mode) in port 1000. The connection with these ports on the local host can be achieved as shown in the following Figure 55. and Figure 56</p> <p></p> <p>Figure 55. E-MAT Client/Server TCP/IP addresses for testing and scanning</p> <p></p> <p>Figure 56. E-MAT Client/Server TCP/IP addresses for inspection</p> <p>Once the connection is established with the E-MAT equipment via TCP/IP protocol, the information regarding the inspection batch is displayed on the debug window as shown in Figure 48 and according to the following JSON structure.</p> <pre><code>{\n  \"inspectionType\": \"object\", // Defines the inspection mode in whihc the sysem is operating\n  \"3\": \"INSPECTION\", // it can be Test, Scan or Inspection mode\n  \"getInspectionJob\": \"4568\", // Provides the inspectionJob ID\n  \"start\": 1720610016391, // Starting time in UNIX format\n  \"stop\": 1720610016613, // End time in UNIX format\n  \"insp_time\": 222, // Duration time\n  \"recordNumber\": 1, // recordID number\n  \"tag\": { // Wave parameters registered by E-MAT euipment\n    \"CH#_GATE#_AMPLITUDE (%)\": 50,\n    \"CH#_GATE#_THICKNESS (mm)\": 10,\n    \"CH#_GATE#_TOF (\u00b5s)\": 100\n  },\n  \"version\": 2,\n  \"disposition\": 2\n}\n</code></pre> <p></p> <p>Figure 57. E-MAT Debug Inspection Information</p> <ul> <li>Custom API: The communication relies on client/server requests via HTTP protocol. For the custom API, the port configured for the communication is the 7001.   This port is set by default and cannot be changed. Thus, it is not available in TCP/IP communication protocol. The API provides the information via HTTP protocol, so the nodes to be configured will be HTTP nodes, as can be seen in Figure 49, which shows all the nodes available to configure HTTP requests and the connection on port 7001.</li> </ul> <p></p> <p>Figure 58. E-MAT Debug Inspection Information</p> <p>Several API calls can be used with Innerspec API that provide the last inspection performed Figure 50 (/api/inspection/last), request for the number of records in an interval of time Figure 51 (/api/inspection/from/{startDate}/to/{endDate}), request based on a certain tag Figure 52 (/api/inspection/by-tag/{tag}) and a request based on a certain <code>recordNumber</code> Figure 53 (/api/inspection/{recordNumber}).</p> <p></p> <p>Figure 59. E-MAT Last Inspection API Call</p> <p></p> <p>Figure 60. E-MAT {startDate}/to/{endDate} API Call</p> <p></p> <p>Figure 61. E-MAT {tag} API Call</p> <p></p> <p>Figure 62. E-MAT {recordNumber} API Call</p> <p>All the API requests based on HTTP protocol are available, accessible and easily integrated with the Blockchain nodes for traceability purposes. The proposed pipeline in Figure 54 provides the integration of API HTTP requests with the Blockchain nodes so new undetected uses can be easily registered thanks to the pipeline continous checks.</p> <p>First part of the Pipeline (marked in red), checks remaining uses and read current E-MAT equipment use. The second part of the pipeline (marked in blue) checks whether new unregistered uses have been detected, and lastly, the third part of the pipeline (marked in green) updates the Blockchain in case any new uses have been registered.</p> <p></p> <p>Figure 63 E-MAT Blockchain Pipeline</p> <p>This pipeline is only an example of the different mechanisms that can be used to relate Welding Inspector zApp with the technology of Blockchain in order to create and integrate new mechanisms that avoid data loss and data corruption under industrial scenarios. Developers can customize their own pipelines based on traceability restrictions for each customer.</p>"},{"location":"WP07/Usage-Traceability/#832-visual-inspector-zapp","title":"8.3.2 Visual Inspector zApp","text":"<p>Within ZDZW Marketplace Visual Inspector zApp can be found. This zApp provides single-piece-flow analysis based on a 6-camera inference system. The data gathered by the cameras is stored in a local instance in MySQL Database.</p>"},{"location":"WP07/Usage-Traceability/#833-node-red-dependencies","title":"8.3.3 Node-RED Dependencies","text":"<p>Our Node-RED microservice has the capability of connecting to this local MySQL instance thanks to the use of custom Node-RED libraries, on this example node-red-node-mysql library was used to enable the connection and operations with the local MySQL instance database.</p> <p>For that purpose new libraries can be added in the 'Manage Palette' options shown on Figure 55 where developers can install different nodes for other relational and non-relational databases.</p> <p></p> <p>Figure 64. Palette Options Node-RED</p> <p>In Figure 65 it can be seen all the dependencies and versions that are currently installed. New or existing nodes can be updated, installed or removed as pleased by developers, allowing flexibility for new database connections or database migrations.</p> <p></p> <p>Figure 65. Dependencies Install Node-RED</p>"},{"location":"WP07/Usage-Traceability/#8331-mysql-local-instance","title":"8.3.3.1 MySQL Local Instance","text":"<p>To connect and interact with the MySQL Local Database it is needed to have a Local MySQL instance up in the device where the Node-RED pipeline is configured. In Figure 66, it can be seen the pre-configured MySQL connection to a local instance in port 3306.</p> <p></p> <p>Figure 66. MySQL Local Database Instance Connection</p> <p>This local database instance contains the inference information gathered by the Visual Inspector zApp cameras. The database architecture is summarized in Figure 58 where the Table database structure is presented.</p> <p></p> <p>Figure 67. MySQL Local Database Architecture</p>"},{"location":"WP07/Usage-Traceability/#8332-blockchain-pipeline","title":"8.3.3.2 Blockchain Pipeline","text":"<p>To ensure robustness in the use of zApp during the inspection procedure, pipelines such as the one shown in Figure 59 can be implemented to ensure correct Blockchain data insertion. In the first part of the pipeline, the number of remaining uses is read to grant access to the inspection zApp and allow image inference on the equipment. The second part of the pipeline connects with the local MySQL instance to check whether new uses have been registered in the database but not in the Blockchain. Depending on the result of this logic, the Blockchain information will be updated according to the new uses registered.</p> <p></p> <p>Figure 68. Blockchain Pipeline</p> <p>This pipeline is only an example of the multiple mechanisms that can be deployed by using the Node-RED microservice combined with local database instances and Blockchain nodes. Based on node traceability requirements, pipelines can be updated to enhance robustness, prevent data leakages and ensure process traceability. In order to enable the database connection with Node-RED microservice, MySQL node must be configured with the local database instance information.</p> <p>In case multiple databases are being used, all the database connection strings can be stored in the node for easier and enhanced accessibility Figure 60. In our use-case, the database connection contains the parameters upon which it is based MySQL local instance (Host, Port, User, Password and Database), as can be seen in Figure 61.</p> <p></p> <p>Figure 69. MySQL Database Selection</p> <p></p> <p>Figure 70. MySQL Node Configuration</p>"},{"location":"WP07/Usage-Traceability/#84-usage-tracking-visualization","title":"8.4. Usage Tracking Visualization","text":"<p>The Usage Tracking Visualization tool allows users to monitor and analyze smart contract usage data through an intuitive web application. To access the tool, users must enter the application's URL in their browser and log in using valid credentials.</p> <p>Upon accessing the application, users are redirected to the Keycloak login page for authentication, as shown in Figure 71. After successful authentication, users are redirected back to the application to begin tracking their smart contract usage.</p> <p></p> <p>Figure 71. Login page</p>"},{"location":"WP07/Usage-Traceability/#smart-contract-selection-and-overview","title":"Smart Contract Selection and Overview","text":"<p>Figure 72. Smart contracts list</p> <p>The interface includes a dropdown menu labeled \"Smart Contracts,\" allowing users to select a specific smart contract. Each contract is displayed with its name, version, and payment model (e.g., PayPerVolume, PayPerUse, or PayPerPeriod). This feature simplifies the process of identifying and managing contracts, ensuring efficient access to usage data and insights for each contract.</p>"},{"location":"WP07/Usage-Traceability/#common-components-across-views","title":"Common Components Across Views","text":"<p>All smart contract views share the following components: - CompanyID, MachineID, and ProviderID: Identifiers for the company, machine, and service provider associated with the contract. - Contract Type: Displays the payment model (e.g., PayPerVolume). - Lifecycle Details: Includes purchase date, installation timestamp, and decommissioning status. - Version Management: Displays the current version of the contract, with a \"Versions\" button to view a list of all versions. - Smart Contract Info Button: Provides a detailed view of the smart contract's content and signing details.</p> <p></p> <p>Figure 73. Data details</p> <p></p> <p>Figure 74. Versions list details</p>"},{"location":"WP07/Usage-Traceability/#smart-contract-details-and-signing-information","title":"Smart Contract Details and Signing Information","text":"<p>Figure 75. Smart contract raw content</p> <p>Users can view the raw content of their smart contracts, including detailed code and transaction history, for transparency and in-depth analysis.</p> <p></p> <p>Figure 76. Smart contract data</p> <p>Additionally, the application visualizes data related to when each smart contract was signed, including the date, time, involved parties, and transaction details.</p>"},{"location":"WP07/Usage-Traceability/#interactive-timeline-charts","title":"Interactive Timeline Charts","text":"<p>All timeline charts include a menu with the following options: - Date Range Selection: Allows users to filter data by specific timeframes. - Download Image: Exports the chart as a <code>.png</code> file. - Restore Data: Resets the chart to its original data sources. - Image Data View: Displays a table with the chart's data. - Zoom Area and Restore Zoom: Enables zooming into specific areas and resetting the zoom level.</p> <p></p> <p>Figure 77. Range selection</p> <p></p> <p>Figure 78. Range column grouping</p> <p></p> <p>Figure 79. Chart Menu</p> <p></p> <p>Figure 80. Downloaded image example</p> <p></p> <p>Figure 81. Chart data view</p>"},{"location":"WP07/Usage-Traceability/#paypervolume-model-view","title":"PayPerVolume Model View","text":"<p>When a PayPerVolume smart contract is selected, the application provides a comprehensive overview, as illustrated in Figure 8.67. Key features include:</p> <ul> <li>Usage Overview: A donut chart visually representing the proportion of consumed and remaining units, offering a quick snapshot of the contract's usage status.</li> <li>Usage Timeline: A line chart displaying usage trends over time, with smart contract versions clearly labeled in the background for context. An inline zoom slider allows users to filter and focus on specific data ranges effortlessly.</li> </ul> <p></p> <p>Figure 82. Pay Per Volume</p> <p>Interactive features, such as date selection and buttons for viewing detailed contract information, refreshing data, and checking the last usage, enhance the user experience.</p>"},{"location":"WP07/Usage-Traceability/#payperuse-model-view","title":"PayPerUse Model View","text":"<p>For PayPerUse smart contracts, users must first select a specific functionality associated with the contract. This ensures focused tracking of individual features or services.</p> <p></p> <p>Figure 83. Pay Per Use functionalities</p> <p>After selecting a functionality, the interface displays usage details, including: - Timeline Section: A column chart showing usage counts for the selected functionality over specific time intervals. An inline zoom slider allows users to filter and focus on specific data ranges effortlessly.</p> <p></p> <p>Figure 84. Pay Per Use view</p>"},{"location":"WP07/Usage-Traceability/#payperperiod-model-view","title":"PayPerPeriod Model View","text":"<p>For PayPerPeriod smart contracts, the interface provides the following features:</p> <ul> <li>Timeline Section: A column chart that visually represents usage counts over specific time intervals, allowing users to track and analyze their usage patterns effectively.</li> <li>Period Banner: A prominent banner at the top of the interface displaying the number of days remaining in the current subscription period, ensuring users are aware of their subscription status.</li> <li>Days Bought Banner: A banner indicating the total number of days purchased for the subscription, providing a clear overview of the subscription duration.</li> </ul> <p></p> <p>Figure 85. Pay Per Period view</p> <p>Additionally, the interface includes a visual alert system to notify users as their subscription nears expiration: - When more than 10 days remain, the \"Expires In\" banner is displayed in green, indicating that the subscription is currently valid and no immediate action is required. - When fewer than 10 days remain, the \"Expires In\" banner is displayed in yellow, signaling a warning to the user. - When fewer than 3 days remain, the \"Expires In\" banner changes to red, indicating an urgent alert.</p> <p></p> <p>Figure 86. Valid subscription</p> <p></p> <p>Figure 87. Subscription nearing expiration</p> <p></p> <p>Figure 88. Subscription expiration imminent</p>"},{"location":"WP07/Usage-Traceability/#85-blockchain-platform","title":"8.5. Blockchain Platform","text":"<p>This backend is only intended for the marketplace, the traceability gateway, and the usage tracking visualization. If, however, you decide to use this API, you will need to manage the authentication process that is usually handled by the node red. Otherwise, this API will not work for you.</p> <p>The Blockchain data storage and retrieval services are provided through a Blockchain API, as shown in Figure 1. This API exposes the Blockchain services to the Traceability Gateway and the zApp Usage Tracking to facilitate the integration of all the modules that make up T7.4.</p> <p>This API is deployed on the AWS instance, as the Computation Requirements section explains. The connection to this API is made through HTTPS and the <code>api.zdzw-blockchain.com</code> portal, for which an IP-based access control has been configured. Therefore, access privileges have been given to the Traceability Gateway, the Marketplace and the zApp Usage Tracking. This access control using security groups ensures the privacy of the solution, guaranteeing control over the conditions under which they interact with the Blockchain platform.</p> <p>Depending on the business model of each zApp, the smart contract will be different. Three smart contract models have been defined: Pay per Volume, Pay per Use and Pay per Period (Time subscription).</p> <p>The API provides usage information in JSON format for all three cases, although the structure varies slightly.</p> <p>For Pay per Volume:</p> <pre><code>{\n   \"MachineID\": \"CoolingTank_125-23\",\n   \"MaxUses\": 500,\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"A\",\n   \"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\",\n   \"UserID\": \"ZDZW-API\",\n   \"ZappID\": \"ThermalAnalysis\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-18 17:00:00 UTC\",\n         \"Operation\": \"decommission\",\n         \"TransTS\": \"2024-09-25 06:36:46\",\n         \"UsesLeft\": -989898\n      },\n      {\n         \"EndTime\": \"2024-09-17 12:45:00 UTC\",\n         \"InitTime\": \"2024-09-17 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-09-25 06:35:44\",\n         \"UsesLeft\": 100\n      },\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-09-25 06:34:09\",\n         \"UsesLeft\": 500\n      },\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-09-25 06:31:22\",\n         \"UsesLeft\": 500\n      }\n   ]\n}\n</code></pre> <p>For Pay per Use:</p> <pre><code>{\n   \"Functionalities\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"MachineID\": \"CoolingTank_XG500K\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"B\",\n   \"SmartContractId\": \"ZDZWEurope_ThermalControl_ppu_2\",\n   \"UserID\": \"ZDZWEurope\",\n   \"ZappID\": \"ThermalControl\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE\",\n         \"InitTime\": \"2024-09-17 16:30:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-03 14:18:40\",\n         \"UsesCount\": 30\n      },\n      {\n         \"EndTime\": \"2024-09-17 12:45:00 UTC\",\n         \"FunctionalityName\": \"MEASURE\",\n         \"InitTime\": \"2024-09-17 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-03 14:18:16\",\n         \"UsesCount\": 10\n      },\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-10-03 14:18:10\",\n         \"UsesCount\": 0\n      },\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-03 14:17:53\",\n         \"UsesCount\": 0\n      }\n   ]\n}\n</code></pre> <p>For Pay per Period:</p> <pre><code>{\n   \"ActivationTS\": \"2024-09-18 10:30:00 UTC\",\n   \"ExpirationTS\": \"2024-12-07 10:30:00 UTC\",\n   \"MachineID\": \"WingInspector_27\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"C\",\n   \"SmartContractId\": \"ZDZWAsia_Hardness_Inspector_v2.1X_ppp_1\",\n   \"SubscribedDays\": 80,\n   \"UserID\": \"ZDZWAsia\",\n   \"ZappID\": \"Hardness_Inspector_v2.1X\",\n   \"Info\": [\n      {\n         \"AccumUses\": 11,\n         \"EndTime\": \"2024-09-19 12:45:00 UTC\",\n         \"InitTime\": \"2024-09-19 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-17 10:00:55 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-18 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-10-17 09:59:45 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"2024-12-07 10:30:00 UTC\",\n         \"InitTime\": \"2024-09-18 10:30:00 UTC\",\n         \"Operation\": \"activation\",\n         \"TransTS\": \"2024-10-16 13:56:56 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-16 13:49:51 UTC\"\n      }\n   ]\n}\n</code></pre> <p>Leveraging this data model, the Blockchain API facilitates the storage of lifecycle information in a Blockchain network, ensuring robust traceability. In addition, the API includes several visualisation functions to improve the representation and understanding of the data.</p> <p>For this purpose, the following milestones in the lifecycle of a smart contract have been identified:</p> <ul> <li>Creation of the smart contract during the acquisition of the zApp.</li> <li>Activation of the subscription for the Pay per Period model.</li> <li>Installation of the zApp if it is on-premise.</li> <li>Use of the zApp.</li> <li>Decommissioning of the zApp.</li> </ul> <p>For this purpose, functionalities have been created in the API that allow these tasks to be carried out. In addition, the API also offers a multitude of endpoints to obtain data for visualisation. In the following, the endpoints' example statements are given.</p> <p>When using the API, it is important to consider certain aspects:</p> <ul> <li>The API is case-sensitive.</li> <li>All timestamps must be in UTC and in the following format: YYYY-MM-DD hh:mm:ss. It is up to the user to pass the appropriate time format. Failure to do so may lead to errors in the traceability of the information.</li> <li>Optional values must still include the tags. E.g., <code>\"InitTime\"=\"\"</code> or <code>\"EndTime\"=\"\"</code></li> <li>Inputs may not contain special characters.</li> <li>If successful, the output of the API may vary, but if unsuccessful, the API will return:</li> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li>Other error messages, depending on the requested endpoint.</li> </ul> <p>However, a more detailed description, defining inputs, outputs, as well as the response of the endpoints both in case of correct operation and error, is given in the Annex.</p>"},{"location":"WP07/Usage-Traceability/#851-application-purchase","title":"8.5.1. Application Purchase","text":"<p>Each time a User purchases a zApp, the Marketplace uses this functionality to store that application's purchase conditions. The endpoint for this action is <code>/createSmartContractZapp</code>.</p> <p>The input parameters for this endpoint are as follows. All of them must be defined (i.e., there are no optional parameters). Failing to do so will cause the API to be unpredictable, and data traceability may be lost.</p>"},{"location":"WP07/Usage-Traceability/#8511-inputs","title":"8.5.1.1. Inputs","text":"<ul> <li>MarketPlaceID: The Marketplace identifier, it is a case-sensitive string.</li> <li>MarketPlaceIP: The Marketplace IP. This value is requested in case it might be necessary to manage the API security groups in the future.</li> <li>ProviderID: The Provider identifier, a case-sensitive string.</li> <li>ProviderIP: The provider IP. This value is requested in case it might be necessary to manage the API security groups in the future.</li> <li>UserID: The User identifier (i.e., the company that buys the zApp), a case-sensitive string.</li> <li>UserIP: The user IP. This value is requested in case it might be necessary to manage the API security groups in the future.</li> <li>SCType: The business model chosen by the User. It is case-sensitive.</li> <li>For pay-per-volume this field must always be an <code>A</code>.</li> <li>For pay-per-use, it must always be a <code>B</code>.</li> <li>For pay-per-period, it must be a <code>C</code>.</li> <li>ZAppID: The zApp identifier, a case-sensitive string.</li> <li>OnPremise: A boolean value passed as string.</li> <li>It is <code>true</code> if the app will be on-premise.</li> <li>It will be <code>false</code> if the app is on the cloud.</li> <li>InitTime: The timestamp of when the zApp was purchased. It must be provided in UTC.</li> </ul> <p>Furthermore, the following inputs will be added depending on the PayType, and they are mandatory for each PayType:</p> <ul> <li>MaxUses: This value must be provided only for the pay-per-volume. An int value passed as string. Contains the max uses defined for the zApp according to the User's purchase.</li> <li>FunctionalityIDs: This value must be provided only for the pay-per-use. A string containing all the purchased functionalities, separated by commas and with no whitespaces between commas and functionalities. For example, <code>measure,evaluation,graphs,prediction</code>.</li> <li>Days: This value must be provided only for the pay-per-period. An int value passed as string. It contains the number of days the user has purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8512-outputs","title":"8.5.1.2. Outputs","text":"<p>If successful, the API will return:</p> <ul> <li><code>200</code></li> <li>The unique identifier of the contract created for that sale. For example: <code>ZDZW-API_ThermalAnalysis_ppv_1</code>.</li> </ul> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no smart contract found for SCType: &lt;SCType&gt;</code>: SCType must be <code>A</code>, <code>B</code> or <code>C</code>.</li> <li>Pay-Per-Volume can also return:</li> <li><code>maxUses is required for SCType: A</code>: MaxUses is a mandatory input for pay-per-volume.</li> <li><code>maxUses cannot be negative for SCType: A</code>: MaxUses cannot be a negative number.</li> <li>Pay-Per-Use can also return:</li> <li><code>functionlityIds is required for SCType: B</code>: This input is mandatory for pay-per-use.</li> <li>Pay-Per-Period can also return:</li> <li><code>days is required for SCType: C</code>: Days is a mandatory input for pay per period.</li> <li><code>days cannot be negative or zero for SCType: C</code>: Days cannot be a negative number or zero.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8513-examples","title":"8.5.1.3. Examples","text":"<p>Creating a pay-per-volume Smart Contract:</p> <pre><code>curl https://api.zdzw-blockchain.com/createSmartContractZapp --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"MarketPlaceID\": \"ZDZW_API_Example\", \"MarketPlaceIP\": \"172.16.100.23\", \"ProviderID\":\"Provider_Example\", \"ProviderIP\":\"165.18.120.13\", \"UserID\":\"ZDZW-API\", \"UserIP\": \"185.23.154.53\", \"SCType\":\"A\", \"ZAppID\": \"ThermalAnalysis\", \"OnPremise\":true, \"MaxUses\":\"500\",\"InitTime\":\"2024-09-17 8:00:00\"}'\n</code></pre> <p>Creating a pay-per-use Smart Contract.</p> <pre><code>curl https://api.zdzw-blockchain.com/createSmartContractZapp --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"MarketPlaceID\": \"ZDZWStore\", \"ProviderID\":\"Provider2\", \"ProviderIP\":\"185.28.103.28\", \"UserID\":\"ZDZWAmerica\", \"UserIP\": \"170.58.133.53\", \"SCType\":\"B\", \"ZAppID\": \"ThermalControl\", \"OnPremise\":true, \"FunctionalityIDs\":\"measure,evaluation,graphs,prediction\", \"InitTime\":\"2024-09-17 8:00:00\"}'\n</code></pre> <p>Creating a pay-per-period Smart Contract.</p> <pre><code>curl https://api.zdzw-blockchain.com/createSmartContractZapp --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"MarketPlaceID\": \"ZDZWStore\", \"MarketPlaceIP\": \"172.16.100.23\", \"ProviderID\":\"Provider1\", \"ProviderIP\":\"165.18.120.13\", \"UserID\":\"ZDZWAsia\", \"UserIP\": \"185.23.154.53\", \"SCType\":\"C\", \"ZAppID\": \"Hardness_Inspector_v2.1X\", \"OnPremise\":true, \"Days\":\"80\",\"InitTime\":\"2024-09-17 8:00:00\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#852-installation-of-the-application-on-a-machine","title":"8.5.2. Installation of the Application on a Machine","text":"<p>If the application is on-premise, the user must specify which machine it has been installed on. This information must be recorded in the Blockchain, creating the ledger where the usage information will be stored later. The endpoint for this action is <code>/invokeInit</code>.</p> <p>This functionality must not be used if the application runs on cloud. The API will throw an error.</p>"},{"location":"WP07/Usage-Traceability/#8521-inputs","title":"8.5.2.1. Inputs","text":"<p>The input parameters for this endpoint are the following, all of which are mandatory. Failing to provide an input will cause the API to be unpredictable, and data traceability may be lost.</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>MachineID: The Machine identifier, a case-sensitive string.</li> <li>InitTime: The timestamp for when the zApp was installed. It must be provided in UTC.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8522-outputs","title":"8.5.2.2. Outputs","text":"<p>If successful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li><code>init true</code></li> </ul> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>machine ID is required</code>: The MachineID was not passed as input.</li> <li><code>app is on cloud</code>: Cloud apps cannot be installed on-premise.</li> <li><code>app already installed in the defined machine</code>: Cannot be installed twice.</li> <li><code>app already installed in another machine</code>: App already installed in another machine. One SmartContractID implies one machine.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: The introduced SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8523-example","title":"8.5.2.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/invokeInit --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\", \"MachineID\":\"CoolingTank_125-23\", \"InitTime\":\"2024-09-17 10:30:00\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#853-application-usage","title":"8.5.3. Application Usage","text":"<p>Whenever an application is used, information about that use is stored on the blockchain network. The endpoint for this action is <code>/invokeInfo</code>.</p> <ul> <li>In the pay-per-volume model, this data can be used to track whether a user is trying to exceed their purchased uses or how many uses they have left.</li> <li>The pay-per-use model provides information about how many times the app has been used. This endpoint must be called for each functionality in pay-per-use.</li> <li>The pay-per-period model provides information about how many times the app has been used in the allotted time.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8531-inputs","title":"8.5.3.1. Inputs","text":"<p>All input parameters for this endpoint (listed below) are mandatory except EndTime.</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>UsesCount: An int value, passed as a string, reflecting the number of uses accumulated over a given time or starting at a given timestamp.</li> <li>InitTime: The timestamp reflecting when the uses specified in UsesCount started. It must be provided in UTC.</li> <li>EndTime: This value is optional, but the tag should be included, e.g., <code>\"EndTime\":\"\"</code>. It is the timestamp marking the end of the uses specified in UsesCount. It must be provided in UTC.</li> </ul> <p>Furthermore, for pay-per-use user must also provide:</p> <ul> <li>FunctionalityName: This input is mandatory in pay-per-use. A string identifying a single functionality. If, for example, during the purchase, the purchased list of functionalities was <code>measure,evaluation,graphs,prediction</code>, the <code>FunctionalityName</code> can be <code>measure</code>. Uses for non-purchased functionalities cannot be accumulated.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8532-outputs","title":"8.5.3.2. Outputs","text":"<p>If successful, the API will return:</p> <ul> <li><code>200</code></li> </ul> <p>And one of the following strings:</p> <ul> <li><code>true</code>: Everything went OK.</li> <li><code>app blocked: data stored but inaccurate due to the app being blocked, leading to incorrect user metrics and data</code>: Usage successfully stored in the Blockchain, but the app is supposedly decommissioned.</li> <li><code>data stored, but more than one use with the same begin and end time</code>: the provided InitTime and EndTime are the same for more than one UsesCount. This will generate issues for visualization.</li> <li>Additionally, for pay-per-period, it can also return:</li> <li><code>data stored, but expiration date surpassed</code>: The usage was successfully stored in the Blockchain, but the uses happened after the expiration date. This warning only exists for pay-per-period.</li> <li>And for pay-per-volume, it can return:</li> <li><code>data stored, but purchased uses exceeded</code>: Usage successfully stored in the Blockchain, but the purchased maximum uses have been exceeded. This warning only exists for pay-per-volume.</li> </ul> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>failed to store data in the blockchain</code>: It was not possible to store usage data in the Blockchain.</li> <li><code>usesCount is required</code>: UsesCount is mandatory as input.</li> <li><code>cannot load negative uses</code>: UsesCount must be positive.</li> <li><code>app not installed</code>: The app is identified as on-premise but has not been installed. It must be installed before being used.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: The introduced SmartContractID does not exist.</li> <li>Pay-Per-Use can also return:</li> <li><code>only one functionality is allowed</code>: This error is present in pay-per-use. More than one functionality was loaded in <code>FunctionalityName</code> when only one was expected.</li> <li><code>functionality &lt;FunctionalityName&gt; not purchased or available for SmartContractID: &lt;SmartContractID&gt;</code>: Tried to load uses for a functionality not purchased.</li> <li>Pay-Per-Period can also return:</li> <li><code>app not activated</code>: This error is present in pay-per-period. It happens when the app has not been activated. On-premise apps are activated when installation takes place. In cloud apps, the activation occurs when the first use is to be stored.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8533-example","title":"8.5.3.3. Example","text":"<p>For pay-per-volume and pay per period:</p> <pre><code>curl https://api.zdzw-blockchain.com/invokeInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\", \"UsesCount\":\"400\", \"InitTime\":\"2024-09-17 12:00:00\", \"EndTime\":\"2024-09-17 12:45:00\"}'\n</code></pre> <p>For pay-per-use the usage of each functionality is mapped individually, so the FunctionalityName should only contain one functionality:</p> <pre><code>curl https://api.zdzw-blockchain.com/invokeInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"Ikerlan_Thermal_Analysis_v3_ppv_1\", \"UsesCount\":\"10\", \"InitTime\":\"2024-09-17 12:00:00\", \"EndTime\":\"2024-09-17 12:45:00\", \"FunctionalityName\":\"measure\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#854-application-renewal","title":"8.5.4. Application Renewal","text":"<p>For pay-per-period and pay-per-volume, users and companies buy the right to use an application for a limited amount of uses or a limited amount of days. Users may want to continue using the app without creating a new contact when reaching the usage limit. That is, they may wish to renew it.</p> <p>In this case, this endpoint allows them to do so; by allowing them to use the same SmartContractID, they can renew it under the same conditions. E.g., Suppose originally the zApp was purchased for a maximum use of 30 uses, and the user renews it when there were 5 uses left. In that case, it will automatically be renewed for the right of an additional 30 uses, resulting in a new maximum use of 38.5.6. The same approach is used for days that will be added to the expiration timestamp.</p>"},{"location":"WP07/Usage-Traceability/#8541-inputs","title":"8.5.4.1. Inputs","text":"<p>The input parameters for this endpoint are as follows:</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>Time: The timestamp of when the SmartContract is renewed, must be provided un UTC.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8542-outputs","title":"8.5.4.2. Outputs","text":"<p>If successful, the API will return:</p> <ul> <li><code>200</code></li> <li><code>\"New version is &lt;version number&gt;</code></li> </ul> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>smartContractID is required</code>: Passing a smartContractID as input is mandatory.</li> <li><code>time is required</code>: Passing a timestamp as input is mandatory.</li> <li><code>the zApp has not been installed yet. cannot renew</code>: When the app is on-premise, it can only be renewed after it has been installed.</li> <li><code>this endpoint is not allowed for pay per use</code>: The endpoint cannot be used for Pay-per-Use.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: The introduced SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8543-example","title":"8.5.4.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/renewSmartContractZapp -include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\": \"SecondTestMarch_TestApp02_ppp_1\",\"Time\":\"2025-03-31 9:00:00\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#855-application-decommissioning","title":"8.5.5. Application Decommissioning","text":"<p>When an application reaches the end of its usage, its allotted time or the service is cancelled, the contract must also be decommissioned. This endpoint indicates that the contract has been decommissioned but keeps the information stored up to that moment accessible. The endpoint for this action is <code>/blockUser</code>.</p>"},{"location":"WP07/Usage-Traceability/#8551-inputs","title":"8.5.5.1. Inputs","text":"<p>The input parameters for this endpoint are as follows:</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>Time: The timestamp of when the SmartContract is decommissioned, must be provided un UTC.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8552-outputs","title":"8.5.5.2. Outputs","text":"<p>If successful, the API will return:</p> <ul> <li><code>200</code></li> <li><code>block true</code></li> </ul> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>time is required</code>: Passing a timestamp as input is mandatory.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: The introduced SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8553-example","title":"8.5.5.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/blockUser --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\", \"Time\":\"2024-09-18 17:00:00\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#856-get-all-the-contracts-owned-by-a-company","title":"8.5.6. Get all the Contracts owned by a Company","text":"<p>This functionality displays all the Smart Contracts owned by a marketplace user. The endpoint for this action is <code>/getCompanySmartContracts</code>.</p>"},{"location":"WP07/Usage-Traceability/#8561-inputs","title":"8.5.6.1. Inputs","text":"<p>The input parameters for this endpoint are as follows:</p> <ul> <li>UserID: The User identifier, a case-sensitive string.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8562-outputs","title":"8.5.6.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing a list of all smart contracts owned by that user, alongside the application they are related to and the pay type. For example:</li> </ul> <pre><code>{\n   \"List\":[\n      {\n         \"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\",\n         \"ZAppID\":\"ThermalAnalysis\",\n         \"FunctionalityName\":\"pay per volume, no functionalities\",\n         \"Version\": \"00\",\n         \"VersionTS\": \"2025-01-29 08:00:00 UTC\",\n         \"SCType\":\"PayPerVolume\"\n      },\n      {\n         \"SmartContractID\": \"ZDZW-API_ThermalControl_ppu_1\",\n         \"ZAppID\": \"ThermalControl\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"Version\": \"04\",\n         \"VersionTS\": \"2025-03-21 09:00:00 UTC\",\n         \"SCType\": \"PayPerUse\"\n      },\n      {\n         \"SmartContractID\": \"ZDZW-API_VisualInspector_ppp_1\",\n         \"ZAppID\": \"VisualInspector\",\n         \"FunctionalityName\": \"pay per period, no functionalities\",\n         \"Version\": \"01\",\n         \"VersionTS\": \"2025-03-21 09:00:00 UTC\",\n         \"SCType\": \"PayPerPeriod\"\n      },\n      {\n         \"SmartContractID\": \"HSO_Aero_SurfaceInspector_v1.12_ppp_1\",\n         \"ZAppID\": \"SurfaceInspector_v1.12\",\n         \"FunctionalityName\": \"pay per period, no functionalities\",\n         \"Version\": \"00\",\n         \"VersionTS\": \"2024-11-21 09:00:00 UTC\",\n         \"SCType\": \"PayPerPeriod\"\n      },\n      {\n         \"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_2\",\n         \"ZAppID\":\"ThermalAnalysis\",\n         \"FunctionalityName\":\"pay per volume, no functionalities\",\n         \"Version\": \"02\",\n         \"VersionTS\": \"2025-03-31 09:00:00 UTC\",\n         \"SCType\":\"PayPerVolume\"\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>No apps found for user ID &lt;UserID&gt;</code>: The provided UserID is incorrect.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8563-example","title":"8.5.6.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getCompanySmartContracts --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"UserID\":\"ZDZW-API\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#857-get-the-metadata-of-a-smart-contract","title":"8.5.7. Get the Metadata of a Smart Contract","text":"<p>This functionality displays all Smart Contracts owned by a marketplace user. The endpoint for this action is <code>/getSmartContractMetaData</code>.</p>"},{"location":"WP07/Usage-Traceability/#8571-inputs","title":"8.5.7.1. Inputs","text":"<p>The input parameters for this endpoint are as follows:</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8572-outputs","title":"8.5.7.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing all the metadata for the specified contract.</li> </ul> <p>For example, the following JSON is the metadata for a pay-per-volume application on-premise, which has been purchased, installed, and decommissioned.</p> <pre><code>{\n   \"CompanyID\": \"ZDZW-API\",\n   \"DecommissionTS\": \"2024-09-18 17:00:00 UTC\",\n   \"InstallTS\": \"2024-09-17 10:30:00 UTC\",\n   \"MachineID\": \"CoolingTank_125-23\",\n   \"MaxUses\": 500,\n   \"ProviderID\": \"Provider_Example\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"PayPerVolume\",\n   \"Version\": \"00\",\n   \"zAppID\": \"ThermalAnalysis\"\n}\n</code></pre> <p>Meanwhile, this is the output for the pay-per-use application, which has been purchased, installed, and is still in use.</p> <pre><code>{\n   \"CompanyID\": \"ZDZWEurope\",\n   \"DecommissionTS\": \"still in use\",\n   \"FunctionalityIDs\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"InstallTS\": \"2024-09-17 10:30:00 UTC\",\n   \"MachineID\": \"CoolingTank_XG500K\",\n   \"ProviderID\": \"Provider1\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"PayPerUse\",\n   \"Version\": \"00\",\n   \"zAppID\": \"ThermalControl\"\n}\n</code></pre> <p>Finally, this is the output for the pay-per-period application, which has been purchased, activated, installed, and decomissioned.</p> <pre><code>{\n   \"zAppID\": \"Thermal_Control_v0.2\",\n   \"CompanyID\": \"IKERLAN\",\n   \"ProviderID\": \"LocalProvider_01\",\n   \"SCType\": \"PayPerPeriod\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"MachineID\": \"CoolingTank_125-01\",\n   \"InstallTS\": \"2024-09-17 10:30:00 UTC\",\n   \"DecommissionTS\": \"still in use\",\n   \"ActivationTS\": \"2024-09-17 10:30:00 UTC\",\n   \"ExpirationTS\": \"2024-12-06 10:30:00 UTC\",\n   \"Version\": \"00\",\n   \"SubscribedDays\": 80\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: The introduced SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8573-example","title":"8.5.7.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getSmartContractMetaData --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#858-get-purchase-data-about-an-application","title":"8.5.8. Get purchase data about an application","text":"<p>This functionality provides information about the conditions under which a specific app was purchased. The endpoint for this action is <code>/getInitInfoSmartContractZapps</code></p>"},{"location":"WP07/Usage-Traceability/#8581-inputs","title":"8.5.8.1. Inputs","text":"<p>The input parameters for this endpoint are as follows:</p> <ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8582-outputs","title":"8.5.8.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the purchase information. For example, in the case of pay-per-volume:</li> </ul> <pre><code>{\n   \"MachineID\": \"unknown\",\n   \"MaxUses\": 650,\n   \"PurchaseTS\": \"2024-09-29 08:00:00 UTC\",\n   \"SCType\": \"A\",\n   \"SmartContractId\": \"ZDZW-API_3D_Visualization_v01.12b_ppv_1\",\n   \"UserID\": \"ZDZW-API\",\n   \"ZappID\": \"3D_Visualization_v01.12b\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-29 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-04 07:28:15\",\n         \"UsesLeft\": 650\n      }\n   ]\n}\n</code></pre> <ul> <li>For example, in the case of pay-per-use:</li> </ul> <pre><code>{\n   \"Functionalities\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"MachineID\": \"unknown\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"B\",\n   \"SmartContractId\": \"ZDZWEurope_ThermalControl_ppu_2\",\n   \"UserID\": \"ZDZWEurope\",\n   \"ZappID\": \"ThermalControl\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-03 14:17:53\",\n         \"UsesCount\": 0\n      }\n   ]\n}\n</code></pre> <ul> <li>And in the case of pay-per-period:</li> </ul> <pre><code>{\n   \"ActivationTS\": \"\",\n   \"ExpirationTS\": \"\",\n   \"Info\": [\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-11-11 14:29:40 UTC\"\n      }\n   ],\n   \"MachineID\": \"unknown\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"C\",\n   \"SmartContractId\": \"IKERLAN_Thermal_Control_v0.2_ppp_1\",\n   \"SubscribedDays\": 80,\n   \"UserID\": \"IKERLAN\",\n   \"ZappID\": \"Thermal_Control_v0.2\"\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8583-example","title":"8.5.8.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getInitInfoSmartContractZapps --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#859-get-installation-data-about-an-application","title":"8.5.9. Get installation data about an application","text":"<p>If the application is on-premise and has already been installed, this endpoint shows the installation data, including the machine on which the app was installed. The endpoint for this action is <code>/getInitInfo</code>.</p>"},{"location":"WP07/Usage-Traceability/#8591-inputs","title":"8.5.9.1. Inputs","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8592-outputs","title":"8.5.9.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the installation information. For example, in pay-per-use:</li> </ul> <pre><code>{\n   \"MachineID\":\"CoolingTank_125-23\",\n   \"MaxUses\":500,\n   \"PurchaseTS\":\"2024-09-17 08:00:00 UTC\",\n   \"SCType\":\"A\",\n   \"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\",\n   \"UserID\":\"ZDZW-API\",\n   \"ZappID\":\"ThermalAnalysis\",\n   \"Info\":[\n      {\n         \"EndTime\":\"\",\n         \"InitTime\":\"2024-09-17 10:30:00 UTC\",\n         \"Operation\":\"installation\",\n         \"TransTS\":\"2024-09-25 06:34:09\",\n         \"UsesLeft\":500\n      }\n   ]\n}\n</code></pre> <ul> <li>And in pay-per-volume:</li> </ul> <pre><code>{\n   \"MachineID\": \"CoolingTank_XG500K\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"B\",\n   \"SmartContractId\": \"ZDZWEurope_ThermalControl_ppu_1\",\n   \"UserID\": \"ZDZWEurope\",\n   \"ZappID\": \"ThermalControl\",\n   \"Functionalities\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-10-03 12:56:03\",\n         \"UsesCount\": 0\n      }\n   ]\n}\n</code></pre> <ul> <li>And in pay-per-period:</li> </ul> <pre><code>{\n  \"ActivationTS\": \"2024-09-17 10:30:00 UTC\",\n  \"ExpirationTS\": \"2024-12-06 10:30:00 UTC\",\n  \"Info\": [\n    {\n      \"AccumUses\": 0,\n      \"EndTime\": \"\",\n      \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n      \"Operation\": \"installation\",\n      \"TransTS\": \"2024-11-11 14:30:06 UTC\"\n    }\n  ],\n  \"MachineID\": \"CoolingTank_125-01\",\n  \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n  \"SCType\": \"C\",\n  \"SmartContractId\": \"IKERLAN_Thermal_Control_v0.2_ppp_1\",\n  \"SubscribedDays\": 80,\n  \"UserID\": \"IKERLAN\",\n  \"ZappID\": \"Thermal_Control_v0.2\"\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>app is on cloud, cannot be installed</code>: If the zApp is purchased to be on cloud, it cannot be installed.</li> <li><code>app not installed yet</code>: The app was purchased to be installed on-premise, but this has not happened yet.</li> <li><code>no records found for identifier: &lt;identifier&gt;</code>: SmartContractID does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#8593-example","title":"8.5.9.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getInitInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8510-get-usage-information-from-a-zapp-for-pay-per-volume-and-pay-per-period","title":"8.5.10. Get usage information from a zApp (for Pay per Volume and Pay per Period)","text":"<p>All information related to the use of an application can be retrieved. The endpoint for this action is <code>/getAllInfo</code>.</p>"},{"location":"WP07/Usage-Traceability/#85101-inputs","title":"8.5.10.1. Inputs","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>InitTime: This parameter is optional, but the tag should be included, e.g., <code>\"InitTime\":\"\"</code>. It allows to delimit the information's time range, defining the timestamp from which the information will be obtained. If not defined, it will return from the oldest stored data. It must be provided in UTC.</li> <li>EndTime: This parameter is optional, but the tag should be included, e.g., <code>\"EndTime\":\"\"</code>; It allows to delimit the time range of information to be obtained, defining the timestamp limit from which you wish to obtain the information. It will return all the information until the newest input if it is not defined. It must be provided in UTC.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85102-outputs","title":"8.5.10.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the usage information. For example for pay-per-volume:</li> </ul> <pre><code>{\n   \"MachineID\": \"CoolingTank_125-23\",\n   \"MaxUses\": 500,\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"A\",\n   \"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\",\n   \"UserID\": \"ZDZW-API\",\n   \"ZappID\": \"ThermalAnalysis\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-18 17:00:00 UTC\",\n         \"Operation\": \"decommission\",\n         \"TransTS\": \"2024-09-25 06:36:46\",\n         \"UsesLeft\": -989898\n      },\n      {\n         \"EndTime\": \"2024-09-17 12:45:00 UTC\",\n         \"InitTime\": \"2024-09-17 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-09-25 06:35:44\",\n         \"UsesLeft\": 100\n      },\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-09-25 06:34:09\",\n         \"UsesLeft\": 500\n      },\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-09-25 06:31:22\",\n         \"UsesLeft\": 500\n      }\n   ]\n}\n</code></pre> <ul> <li>And for pay-per-period:</li> </ul> <pre><code>{\n   \"ActivationTS\": \"2024-09-18 10:30:00 UTC\",\n   \"ExpirationTS\": \"2024-12-07 10:30:00 UTC\",\n   \"MachineID\": \"WingInspector_27\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"C\",\n   \"SmartContractId\": \"ZDZWAsia_Hardness_Inspector_v2.1X_ppp_1\",\n   \"SubscribedDays\": 80,\n   \"UserID\": \"ZDZWAsia\",\n   \"ZappID\": \"Hardness_Inspector_v2.1X\",\n   \"Info\": [\n      {\n         \"AccumUses\": 54,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-27 17:00:00 UTC\",\n         \"Operation\": \"decommission\",\n         \"TransTS\": \"2024-10-17 10:01:18 UTC\"\n      },\n      {\n         \"AccumUses\": 54,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-26 17:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-17 10:01:12 UTC\"\n      },\n      {\n         \"AccumUses\": 34,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-24 11:50:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-17 10:01:08 UTC\"\n      },\n      {\n         \"AccumUses\": 16,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-19 16:30:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-17 10:01:03 UTC\"\n      },\n      {\n         \"AccumUses\": 11,\n         \"EndTime\": \"2024-09-19 12:45:00 UTC\",\n         \"InitTime\": \"2024-09-19 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-17 10:00:55 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-18 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-10-17 09:59:45 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"2024-12-07 10:30:00 UTC\",\n         \"InitTime\": \"2024-09-18 10:30:00 UTC\",\n         \"Operation\": \"activation\",\n         \"TransTS\": \"2024-10-16 13:56:56 UTC\"\n      },\n      {\n         \"AccumUses\": 0,\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-16 13:49:51 UTC\"\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no records found for identifier: &lt;SmartContractID&gt;\"</code>: SmartContractID was not found. This can happen when calling a SmartContractID that does not exist.</li> <li><code>this endpoint cannot be used for pay per use</code>: SmartContractID was identified as pay-per-use; thus, this endpoint cannot be used.</li> <li><code>no smart contract found for SCType: &lt;payType&gt;</code>: SCType are either <code>A</code>, <code>B</code> or <code>C</code>. Anything else will throw an error.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85103-example","title":"8.5.10.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getAllInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\", \"InitTime\":\"\", \"EndTime\":\"\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8511-get-functionality-usage-information-from-a-zapp-only-for-pay-per-use","title":"8.5.11. Get functionality usage information from a zApp (only for Pay per Use)","text":"<p>All information related to the use of an application functionality can be retrieved. The endpoint for this action is <code>/getAllInfoFunctionality</code>.</p>"},{"location":"WP07/Usage-Traceability/#85111-inputs","title":"8.5.11.1. Inputs","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>InitTime: This parameter is optional, but the tag should be included, e.g., <code>\"InitTime\":\"\"</code>. It allows to delimit the information's time range, defining the timestamp from which the information will be obtained. If not defined, it will return from the oldest stored data. It must be provided in UTC.</li> <li>EndTime: This parameter is optional, but the tag should be included, e.g., <code>\"EndTime\":\"\"</code>; It allows to delimit the time range of information to be obtained, defining the timestamp limit from which you wish to obtain the information. It will return all the information until the newest input if it is not defined. It must be provided in UTC.</li> <li>FunctionalityName: A string identifying a single functionality. Mandatory.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85112-outputs","title":"8.5.11.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the usage information. For example:</li> </ul> <pre><code>{\n   \"Functionalities\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"MachineID\": \"CoolingTank_XG500K\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"B\",\n   \"SmartContractId\": \"ZDZWEurope_ThermalControl_ppu_2\",\n   \"UserID\": \"ZDZWEurope\",\n   \"ZappID\": \"ThermalControl\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE\",\n         \"InitTime\": \"2024-09-17 16:30:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-03 14:18:40\",\n         \"UsesCount\": 30\n      },\n      {\n         \"EndTime\": \"2024-09-17 12:45:00 UTC\",\n         \"FunctionalityName\": \"MEASURE\",\n         \"InitTime\": \"2024-09-17 12:00:00 UTC\",\n         \"Operation\": \"use\",\n         \"TransTS\": \"2024-10-03 14:18:16\",\n         \"UsesCount\": 10\n      },\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"InitTime\": \"2024-09-17 10:30:00 UTC\",\n         \"Operation\": \"installation\",\n         \"TransTS\": \"2024-10-03 14:18:10\",\n         \"UsesCount\": 0\n      },\n      {\n         \"EndTime\": \"\",\n         \"FunctionalityName\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n         \"InitTime\": \"2024-09-17 08:00:00 UTC\",\n         \"Operation\": \"purchase\",\n         \"TransTS\": \"2024-10-03 14:17:53\",\n         \"UsesCount\": 0\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>functionality is required</code>: FunctionalityName is a mandatory input.</li> <li><code>only one functionality is allowed</code>: More than one functionality has been loaded in <code>FunctionalityName</code>.</li> <li><code>no records found for identifier: &lt;SmartContractID&gt;\"</code>: SmartContractID was not found. This can happen when calling a SmartContractID that does not exist.</li> <li><code>this endpoint is only for pay per use</code>: tried to use this endpoint with a SmartContractID that is not pay-per-use.</li> <li><code>functionality &lt;FunctionalityName&gt; not purchased or available for SmartContractID: &lt;SmartContractID&gt;</code>: Tried to load uses for a functionality not purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85113-example","title":"8.5.11.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getAllInfoFunctionality --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZWEurope_ThermalControl_ppu_2\", \"InitTime\":\"\", \"EndTime\":\"\", \"FunctionalityName\":\"measure\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8512-get-the-last-usage-status-from-a-zapp","title":"8.5.12. Get the last usage status from a zApp","text":"<p>This endpoint provides information about the last registered state of an app. The API endpoint for this action is <code>/getUserInfo</code>.</p>"},{"location":"WP07/Usage-Traceability/#85121-inputs","title":"8.5.12.1. Inputs","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85122-outputs","title":"8.5.12.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the last transaction related to said SmartContractID. For example:</li> </ul> <pre><code>{\n   \"MachineID\": \"unknown\",\n   \"MaxUses\": 500,\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"A\",\n   \"SmartContractID\": \"ZDZW-API_ThermalAnalysis_ppv_1\",\n   \"UserID\": \"ZDZW-API\",\n   \"ZappID\": \"ThermalAnalysis\",\n   \"Info\": [\n      {\n         \"EndTime\": \"\",\n         \"InitTime\": \"2024-09-18 17:00:00 UTC\",\n         \"Operation\": \"decommission\",\n         \"TransTS\": \"2024-09-25 06:36:46\",\n         \"UsesLeft\": -989898\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>this endpoint is only for pay per volume</code>: The endpoint is being called for a SmartContractID that is not pay-per-volume.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85123-example","title":"8.5.12.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getUserInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"ZDZW-API_ThermalAnalysis_ppv_1\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8513-get-the-accumulated-uses-for-a-functionality-of-zapp-for-pay-per-use","title":"8.5.13. Get the accumulated uses for a functionality of zApp (for Pay per Use)","text":"<p>This function provides information on the accumulated uses for a given functionality in a given period of time. The endpoint for this action is <code>/getPeriodFunctionality</code>.</p>"},{"location":"WP07/Usage-Traceability/#85131-input","title":"8.5.13.1. Input","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> <li>FunctionalityName: A string identifying a single functionality.</li> <li>InitTime: This parameter is optional, but the tag should be included, e.g., <code>\"InitTime\":\"\"</code>. This parameter allows you to specify a starting point to delimit the time range of the data to be retrieved. Only data whose timestamp is after the defined date will be retrieved. For example, if a start date of <code>2024-05-24 12:00:00</code> is set, data from <code>2024-05-24 12:00:01</code>onwards will be retrieved, excluding data dated on or before <code>2024-05-24 12:00:00</code>. The oldest available data will be returned if no start date is provided. The date must be provided in UTC.</li> <li>EndTime: This parameter is optional, but the tag should be included, e.g., <code>\"EndTime\":\"\"</code>. This parameter allows you to delimit the time range of the data to be retrieved, establishing the limit to which you wish to obtain the information. Only data whose timestamp is before the defined date will be retrieved. For example, if an EndTime of <code>2023-01-01 00:00:00</code> is set, data up to <code>2022-12-31 23:59:59</code> will be retrieved, excluding data with a date equal to or after <code>2023-01-01 00:00:00</code>. Data up to the most recent entry shall be returned if not defined. The date must be provided in UTC.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85132-outputs","title":"8.5.13.2. Outputs","text":"<p>If succesful, the API will return:</p> <ul> <li><code>200 OK</code></li> <li>A JSON containing the purchase information. For example:</li> </ul> <pre><code>{\n   \"Functionalities\": \"MEASURE,EVALUATION,GRAPHS,PREDICTION\",\n   \"MachineID\": \"CoolingTank_XG500K\",\n   \"PurchaseTS\": \"2024-09-17 08:00:00 UTC\",\n   \"SCType\": \"B\",\n   \"SmartContractId\": \"ZDZWEurope_ThermalControl_ppu_2\",\n   \"UserID\": \"ZDZWEurope\",\n   \"ZappID\": \"ThermalControl\",\n   \"Info\": [\n      {\n         \"EndTime\": \"2024-09-17 08:00:00 UTC\",\n         \"FunctionalityName\": \"GRAPHS\",\n         \"InitTime\": \"2024-09-17 17:00:00 UTC\",\n         \"Operation\": \"\",\n         \"TransTS\": \"\",\n         \"UsesCount\": 13\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>functionality is required</code>: FunctionalityName is a mandatory input.</li> <li><code>only one functionality is allowed</code>: More than one functionality has been loaded in <code>FunctionalityName</code>.</li> <li><code>no records found for identifier: &lt;SmartContractID&gt;\"</code>: SmartContractID was not found. This can happen when calling a SmartContractID that does not exist.</li> <li><code>this endpoint is only for pay per use</code>: tried to use this endpoint with a SmartContractID that is not pay-per-use.</li> <li><code>functionality &lt;FunctionalityName&gt; not purchased or available for SmartContractID: &lt;SmartContractID&gt;</code>: Tried to load uses for a functionality not purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85133-example","title":"8.5.13.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getUserInfo --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"Ikerlan_Thermal_Analysis_v3_ppv_1\", \"InitTime\":\"2024-05-24 12:01:33\", \"EndTime\":\"2024-05-27 12:01:33\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8514-get-all-the-smart-contract-a-company-owns-for-a-specific-zapp","title":"8.5.14. Get all the Smart Contract a Company owns for a specific zApp","text":"<p>This function provides a list of all the Smart Contracts owned by a company for a specific zApp. The endpoint for this action is <code>/getCompanyAppIDs</code>.</p>"},{"location":"WP07/Usage-Traceability/#85141-inputs","title":"8.5.14.1. Inputs","text":"<ul> <li>ZAppID: The zApp identifier, a case-sensitive string.</li> <li>UserID: The User identifier (i.e., the company that buys the zApp), a case-sensitive string.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85142-outputs","title":"8.5.14.2. Outputs","text":"<p>If succesful, the API will return:</p> <pre><code>{\n    \"List\": [\n        {\n            \"SCType\": \"PayPerVolume\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppv_2\",\n            \"Status\": \"Blocked\",\n            \"Version\": \"00\"\n        },\n        {\n            \"SCType\": \"PayPerVolume\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppv_1\",\n            \"Status\": \"Active\",\n            \"Version\": \"00\"\n        },\n        {\n            \"SCType\": \"PayPerVolume\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppu_1\",\n            \"Status\": \"Blocked\",\n            \"Version\": \"00\"\n        },\n        {\n            \"SCType\": \"PayPerPeriod\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppp_3\",\n            \"Status\": \"Active\",\n            \"Version\": \"00\"\n        },\n        {\n            \"SCType\": \"PayPerPeriod\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppp_1\",\n            \"Status\": \"Active\",\n            \"Version\": \"00\"\n        },\n        {\n            \"SCType\": \"PayPerPeriod\",\n            \"SmartContractID\": \"CompanyA_VisualInspector_ppp_2\",\n            \"Status\": \"Active\",\n            \"Version\": \"00\"\n        }\n    ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no records found for identifier: &lt;SmartContractID&gt;</code>: SmartContractID was not found. This can happen when calling a SmartContractID that does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85143-example","title":"8.5.14.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getCompanyAppIDs --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"UserID\":\"CompanyA\", \"ZAppID\":\"VisualInspector\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#8515-get-all-the-versions-for-a-specific-smartcontract","title":"8.5.15. Get all the versions for a specific SmartContract","text":"<p>This function provides a list of all the Smart Contracts owned by a company for a specific zApp. The endpoint for this action is <code>/getContractVersions</code>.</p>"},{"location":"WP07/Usage-Traceability/#85151-inputs","title":"8.5.15.1. Inputs","text":"<ul> <li>SmartContractID: The Smart Contract identifier, a case-sensitive string. This parameter is created when the zApp is purchased.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85152-outputs","title":"8.5.15.2. Outputs","text":"<p>If succesful, the API will return:</p> <pre><code>{\n   \"List\": [\n      {\n         \"Version\": \"02\",\n         \"VersionTS\": \"2025-03-31 09:00:00 UTC\"\n      },\n      {\n         \"Version\": \"01\",\n         \"VersionTS\": \"2025-03-21 09:00:00 UTC\"\n      },\n      {\n         \"Version\": \"00\",\n         \"VersionTS\": \"2025-02-21 09:00:00 UTC\"\n      }\n   ]\n}\n</code></pre> <p>If unsuccessful, the API can return any of the following:</p> <ul> <li><code>400</code>: The input data does not have the correct format.</li> <li><code>500</code>: The API has failed.</li> <li><code>no records found for identifier: &lt;SmartContractID&gt;</code>: SmartContractID was not found. This can happen when calling a SmartContractID that does not exist.</li> </ul>"},{"location":"WP07/Usage-Traceability/#85153-example","title":"8.5.15.3. Example","text":"<pre><code>curl https://api.zdzw-blockchain.com/getContractVersions --include --header \"Content-Type: application/json\" --request \"POST\" --data '{\"SmartContractID\":\"VisualInspector\"}'\n</code></pre>"},{"location":"WP07/Usage-Traceability/#9-additional-material","title":"9. Additional Material","text":""},{"location":"WP07/Usage-Traceability/#91-additional-learning-material","title":"9.1. Additional Learning Material","text":"<p>HyperLedged Fabric https://www.hyperledger.org/projects/fabric</p> <p>Amazon Managed Blockchain https://aws.amazon.com/es/managed-blockchain/</p>"},{"location":"WP07/Usage-Traceability/#92-anexes","title":"9.2. Anexes","text":"<p>Amazon Managed Blockchain Deployment https://github.com/zdzw-eu/UsageTraceability/blob/main/docs/annex/ZDZW_AmazonManagedBlockhainDeployment_ANNEX.pdf Blockchain Selection Analysis https://github.com/zdzw-eu/Usage-Traceability/blob/main/docs/annex/ZDZW-Blockchain_Justification.pdf API Documentation https://github.com/zdzw-eu/Usage-Traceability/blob/main/docs/annex/ZDZW_API_Blockchain_documentation.md</p>"},{"location":"WP07/Valuechain-App-Store/","title":"Valuechain AppStore","text":""},{"location":"WP07/Valuechain-App-Store/#general-description","title":"General Description","text":"<p>The Valuechain AppStore is part of Valuechain's Network Portal platform. Network Portal is a dynamic networking platform that offers cluster and network management. insights. and streamlined communications. The portal captures intelligence and promotes collaboration with easy two-way communications features. Its AppStore will make various applications avialble to its users/cpmpanies/clusters to help improve productivity and efficiency. </p> <p>The Valuechain AppStore will interlink with ZDZW (and its marketplace). adding value to extend ZDZW to Valuechain's existing commercialised platform where manufacturing companies and industry associations were already using the platform on day-to-day basis. It will allow end-users to utilise the unique offerings (services/tools/applications/products) from both Valuechain and ZDZW seamlessly. </p>"},{"location":"WP07/Valuechain-App-Store/#top-ten-functionalities","title":"Top Ten Functionalities","text":"<ol> <li>Integration of the Stripe </li> <li>Integration with ZDZW marketplace.</li> <li>API to interlink with ZDZW marketplace</li> <li>Create/upload/link/edit/de-activate/delist a product/tool/service/application in AppStore </li> <li>List and filter the products in the Valuechain AppStore by categories</li> <li>Search in Valuechain AppStore</li> <li>Allow supplier(seller) add/edit company information to the Valuechain AppStore as interested buyers/customers may want to check their public information. Similar for the customer who want to buy. they can add company information to VLC Marketplace which might help them find what they need via VLC network portal's recommendation engine.</li> <li>Admin review (approve/reject) workflow support</li> <li>Provide VLC AppStore documentation and instructions to help users with the product creation/upload workflow</li> <li>Log transactions/app vistits and show My App Dashboard reports/analytics</li> </ol> <p>note: Marketplace and AppStore are interchangeable in terms of the WP7 marketplace development</p>"},{"location":"WP07/Valuechain-App-Store/#architecture-diagram","title":"Architecture Diagram","text":"<p>The high level Architecture diagram from the Sofware Specification document  Figure 1</p> <p>The indicative work flow (based on different user role) on Valuechain's Network Portal.   Figure 2</p> <p>The following digram demonstrates the workflow of app publisher and app admin respectively.  Figure 3</p>"},{"location":"WP07/Valuechain-App-Store/#image-overview","title":"Image Overview","text":"<p>The following are the new UI (for normal user and admin user respectively).</p> <p> Figure 4</p> <p> Figure 5</p> <p>The following is the integration of Apps from ZDZW marketplace in to AppStore (allowing App to be featured/promoted, and discovered from Valuechain's commercial platform).  Figure 6</p> <p>The following is the API provided by Valuechain AppStore (allowing apps in Valuechain's platform to be accessed and integrated with other thrid party).  Figure 7</p>"},{"location":"WP07/Valuechain-App-Store/#hardware-components","title":"Hardware Components","text":"<p>N/A as Valuechain AppStore is deployed on Miscrosoft Azure along with its commerical platform</p>"},{"location":"WP07/Valuechain-App-Store/#computation-requirements","title":"Computation Requirements","text":"<p>N/A as Valuechain AppStore is deployed on Miscrosoft Azure along with its commerical platform</p>"},{"location":"WP07/Valuechain-App-Store/#installation-procedure","title":"Installation Procedure","text":"<p>Valuechain's AppStore is delpyed with Valuechain Network Portal on the cloud server serving as SaaS based application. </p>"},{"location":"WP07/Valuechain-App-Store/#how-to-use","title":"How To Use","text":"<p>note: details on how to access the AppStore will be added later once UI implementation is completed * For accessing Valuechain Network Portal directly:   * Testing Environment https://test.valuechain.com/Login   * Production Environment https://my.valuechain.com/Login</p> <ul> <li>For interlinking in the backend, the following APIs are used. Corresding API access document has been shared with WP7 partners (task T7.2 and T7.3).</li> <li>Testing Environment https://testapi.valuechain.com</li> <li>Production Environment https://api.valuechain.com</li> </ul>"},{"location":"WP07/Valuechain-App-Store/#additional-learning-materials","title":"Additional Learning Materials","text":"<p>Links to other learning materials like youtube tutorials or work from WP10</p>"}]}